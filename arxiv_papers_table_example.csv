2507.07258,FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning,"Rami Darwish, Mahmoud Abdelsalam, Sajad Khorsandroo, Kaushik Roy","As IoT ecosystems continue to expand across critical sectors, they have become prominent targets for increasingly sophisticated and large-scale malware attacks. The evolving threat landscape, combined with the sensitive nature of IoT-generated data, demands detection frameworks that are both privacy-preserving and resilient to data heterogeneity. Federated Learning (FL) offers a promising solution by enabling decentralized model training without exposing raw data. However, standard FL algorithms such as FedAvg and FedProx often fall short in real-world deployments characterized by class imbalance and non-IID data distributions -- particularly in the presence of rare or disjoint malware classes. To address these challenges, we propose FedP3E (Privacy-Preserving Prototype Exchange), a novel FL framework that supports indirect cross-client representation sharing while maintaining data privacy. Each client constructs class-wise prototypes using Gaussian Mixture Models (GMMs), perturbs them with Gaussian noise, and transmits only these compact summaries to the server. The aggregated prototypes are then distributed back to clients and integrated into local training, supported by SMOTE-based augmentation to enhance representation of minority malware classes. Rather than relying solely on parameter averaging, our prototype-driven mechanism enables clients to enrich their local models with complementary structural patterns observed across the federation -- without exchanging raw data or gradients. This targeted strategy reduces the adverse impact of statistical heterogeneity with minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset under realistic cross-silo scenarios with varying degrees of data imbalance.","Оскільки екосистеми Інтернету речей продовжують розширюватися в критично важливих секторах, вони стають важливими цілями для все більш витончених і масштабних атак зловмисного програмного забезпечення. Еволюція ландшафту загроз у поєднанні з чутливим характером даних, що генеруються Інтернетом речей, вимагає систем виявлення, які одночасно захищають конфіденційність і є стійкими до гетерогенності даних. Федеративне навчання (Federated Learning, FL) пропонує багатообіцяюче рішення, дозволяючи децентралізовано навчати моделі, не розкриваючи вихідні дані. Однак стандартні алгоритми FL, такі як FedAvg і FedProx, часто не справляються з розгортанням в реальних умовах, що характеризуються дисбалансом класів і розподілом даних не за ідентифікатором - особливо при наявності рідкісних або розрізнених класів шкідливого програмного забезпечення. Для вирішення цих проблем ми пропонуємо FedP3E (Privacy-Preserving Prototype Exchange), новий фреймворк FL, який підтримує непрямий обмін представленнями між клієнтами, зберігаючи при цьому конфіденційність даних. Кожен клієнт будує прототипи для кожного класу за допомогою моделей гауссових сумішей (GMM), обурює їх гауссовим шумом і передає на сервер лише ці компактні зведення. Агреговані прототипи потім розсилаються клієнтам та інтегруються в локальне навчання, підтримуване доповненням на основі SMOTE для покращення репрезентативності малих класів шкідливого програмного забезпечення. Замість того, щоб покладатися лише на усереднення параметрів, наш механізм, заснований на прототипах, дозволяє клієнтам збагачувати свої локальні моделі додатковими структурними моделями, що спостерігаються в усій федерації - без обміну необробленими даними або градієнтами. Ця цілеспрямована стратегія зменшує негативний вплив статистичної неоднорідності з мінімальними комунікаційними витратами. Ми оцінюємо FedP3E на наборі даних N-BaIoT в реалістичних сценаріях міжсилосного обміну з різним ступенем дисбалансу даних.",231,Cryptography and Security (cs.CR),https://arxiv.org/abs/2507.07258,https://arxiv.org/pdf/2507.07258.pdf,true
2507.07274,LinguaMark: Do Multimodal Models Speak Fairly? A Benchmark-Based Evaluation,"Ananya Raval, Aravind Narayanan, Vahid Reza Khazaie, Shaina Raza","Large Multimodal Models (LMMs) are typically trained on vast corpora of image-text data but are often limited in linguistic coverage, leading to biased and unfair outputs across languages. While prior work has explored multimodal evaluation, less emphasis has been placed on assessing multilingual capabilities. In this work, we introduce LinguaMark, a benchmark designed to evaluate state-of-the-art LMMs on a multilingual Visual Question Answering (VQA) task. Our dataset comprises 6,875 image-text pairs spanning 11 languages and five social attributes. We evaluate models using three key metrics: Bias, Answer Relevancy, and Faithfulness. Our findings reveal that closed-source models generally achieve the highest overall performance. Both closed-source (GPT-4o and Gemini2.5) and open-source models (Gemma3, Qwen2.5) perform competitively across social attributes, and Qwen2.5 demonstrates strong generalization across multiple languages. We release our benchmark and evaluation code to encourage reproducibility and further research.","Великі мультимодальні моделі (БММ), як правило, навчаються на великих масивах даних зображення-текст, але часто обмежені в лінгвістичному охопленні, що призводить до упереджених і несправедливих результатів для різних мов. Хоча в попередніх роботах досліджувалося мультимодальне оцінювання, менше уваги приділялося оцінюванню багатомовних можливостей. У цій роботі ми представляємо LinguaMark, бенчмарк, розроблений для оцінювання найсучасніших LMM на багатомовному завданні з візуальної відповіді на запитання (VQA). Наш набір даних складається з 6 875 пар зображення-текст, що охоплюють 11 мов і п'ять соціальних атрибутів. Ми оцінюємо моделі за трьома ключовими метриками: Упередженість, Релевантність відповіді та Вірність. Наші результати показують, що моделі з закритим кодом, як правило, досягають найвищої загальної ефективності. Як моделі з закритим кодом (GPT-4o і Gemini2.5), так і моделі з відкритим кодом (Gemma3, Qwen2.5) демонструють конкурентоспроможні результати за соціальними атрибутами, а Qwen2.5 демонструє сильне узагальнення за кількома мовами. Ми випускаємо наш бенчмарк та оціночний код, щоб сприяти відтворюваності та подальшим дослідженням.",138,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07274,https://arxiv.org/pdf/2507.07274.pdf,true
2507.07853,Optimization Guarantees for Square-Root Natural-Gradient Variational Inference,"Navish Kumar, Thomas Möllenhoff, Mohammad Emtiyaz Khan, Aurelien Lucchi","Variational inference with natural-gradient descent often shows fast convergence in practice, but its theoretical convergence guarantees have been challenging to establish. This is true even for the simplest cases that involve concave log-likelihoods and use a Gaussian approximation. We show that the challenge can be circumvented for such cases using a square-root parameterization for the Gaussian covariance. This approach establishes novel convergence guarantees for natural-gradient variational-Gaussian inference and its continuous-time gradient flow. Our experiments demonstrate the effectiveness of natural gradient methods and highlight their advantages over algorithms that use Euclidean or Wasserstein geometries.","Варіаційне виведення з природним градієнтним спуском часто демонструє швидку збіжність на практиці, але його теоретичні гарантії збіжності було складно встановити. Це справедливо навіть для найпростіших випадків, які включають увігнуті лог-вірогідності і використовують гауссову апроксимацію. Ми показуємо, що цю проблему можна обійти для таких випадків, використовуючи параметризацію квадратного кореня для гауссової коваріації. Цей підхід встановлює нові гарантії збіжності для варіаційно-гауссового висновку з природним градієнтом та його градієнтного потоку в неперервному часі. Наші експерименти демонструють ефективність методів природного градієнта і підкреслюють їх переваги над алгоритмами, які використовують евклідову або васерштейнову геометрію.",93,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07853,https://arxiv.org/pdf/2507.07853.pdf,true
2507.07868,Alpay Algebra V: Multi-Layered Semantic Games and Transfinite Fixed-Point Simulation,"Bugra Kilictas, Faruk Alpay","This paper extends the self-referential framework of Alpay Algebra into a multi-layered semantic game architecture where transfinite fixed-point convergence encompasses hierarchical sub-games at each iteration level. Building upon Alpay Algebra IV's empathetic embedding concept, we introduce a nested game-theoretic structure where the alignment process between AI systems and documents becomes a meta-game containing embedded decision problems. We formalize this through a composite operator $\phi(\cdot, \gamma(\cdot))$ where $\phi$ drives the main semantic convergence while $\gamma$ resolves local sub-games. The resulting framework demonstrates that game-theoretic reasoning emerges naturally from fixed-point iteration rather than being imposed externally. We prove a Game Theorem establishing existence and uniqueness of semantic equilibria under realistic cognitive simulation assumptions. Our verification suite includes adaptations of Banach's fixed-point theorem to transfinite contexts, a novel $\phi$-topology based on the Kozlov-Maz'ya-Rossmann formula for handling semantic singularities, and categorical consistency tests via the Yoneda lemma. The paper itself functions as a semantic artifact designed to propagate its fixed-point patterns in AI embedding spaces -- a deliberate instantiation of the ""semantic virus"" concept it theorizes. All results are grounded in category theory, information theory, and realistic AI cognition models, ensuring practical applicability beyond pure mathematical abstraction.","Ця стаття розширює самореферентну структуру Alpay Algebra до багатошарової семантичної ігрової архітектури, де трансфінітна збіжність з фіксованою точкою охоплює ієрархічні підігри на кожному ітераційному рівні. Спираючись на концепцію емпатичного вбудовування Alpay Algebra IV, ми представляємо вкладену теоретико-ігрову структуру, в якій процес узгодження між системами ШІ та документами стає метагрою, що містить вбудовані проблеми прийняття рішень. Ми формалізуємо це за допомогою складеного оператора $\phi(\cdot, \gamma(\cdot))$, де $\phi$ керує основною семантичною конвергенцією, тоді як $\gamma$ вирішує локальні підігри. Отримана структура демонструє, що теоретико-ігрові міркування виникають природно з ітерацій з фіксованою точкою, а не нав'язуються ззовні. Ми доводимо теорему про ігри, яка встановлює існування та єдиність семантичних рівноваг за реалістичних припущень когнітивного моделювання. Наш верифікаційний набір включає адаптацію теореми Банаха про фіксовану точку до трансфінітних контекстів, нову $\phi$-топологію, засновану на формулі Козлова-Мазя-Россмана для обробки семантичних сингулярностей, а також тести категоріальної несуперечливості за допомогою леми Йонеди. Сама стаття функціонує як семантичний артефакт, призначений для розповсюдження своїх шаблонів з фіксованою точкою у просторах вбудовування ШІ - навмисне втілення концепції ""семантичного вірусу"", яку вона теоретизує. Всі результати ґрунтуються на теорії категорій, теорії інформації та реалістичних моделях пізнання ШІ, що забезпечує практичну застосовність, яка виходить за рамки чистої математичної абстракції.",193,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07868,https://arxiv.org/pdf/2507.07868.pdf,true
2507.05297,Fuzzy Classification Aggregation for a Continuum of Agents,Zijun Meng,"We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\ge 3$ objects into $2\le p\le m$ types must be a weighted arithmetic mean.","Доведено, що будь-яка оптимальна, незалежна та нульова одностайна функція агрегування нечіткої класифікації континууму індивідуальних класифікацій $m\ge 3$ об'єктів на $2\le p\le m$ типи має бути середньозваженою арифметичною.",34,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.05297,https://arxiv.org/pdf/2507.05297.pdf,true
2408.05798,Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences,"Zhaoze Wang, Ronald W. Di Tullio, Spencer Rooke, Vijay Balasubramanian","The vertebrate hippocampus is believed to use recurrent connectivity in area CA3 to support episodic memory recall from partial cues. This brain area also contains place cells, whose location-selective firing fields implement maps supporting spatial memory. Here we show that place cells emerge in networks trained to remember temporally continuous sensory episodes. We model CA3 as a recurrent autoencoder that recalls and reconstructs sensory experiences from noisy and partially occluded observations by agents traversing simulated rooms. The agents move in realistic trajectories modeled from rodents and environments are modeled as high-dimensional sensory experience maps. Training our autoencoder to pattern-complete and reconstruct experiences with a constraint on total activity causes spatially localized firing fields, i.e., place cells, to emerge in the encoding layer. The emergent place fields reproduce key aspects of hippocampal phenomenology: a) remapping (maintenance of and reversion to distinct learned maps in different environments), implemented via repositioning of experience manifolds in the network's hidden layer, b) orthogonality of spatial representations in different arenas, c) robust place field emergence in differently shaped rooms, with single units showing multiple place fields in large or complex spaces, and d) slow representational drift of place fields. We argue that these results arise because continuous traversal of space makes sensory experience temporally continuous. We make testable predictions: a) rapidly changing sensory context will disrupt place fields, b) place fields will form even if recurrent connections are blocked, but reversion to previously learned representations upon remapping will be abolished, c) the dimension of temporally smooth experience sets the dimensionality of place fields, including during virtual navigation of abstract spaces.","Вважається, що гіпокамп хребетних використовує реципрокні зв'язки в ділянці CA3 для підтримки епізодичної пам'яті на основі часткових сигналів. Ця ділянка мозку також містить клітини місця, чиї селективні до місцезнаходження вогневі поля реалізують карти, що підтримують просторову пам'ять. Тут ми показуємо, що клітини місця з'являються в мережах, навчених запам'ятовувати безперервні в часі сенсорні епізоди. Ми моделюємо CA3 як рекурентний автокодер, який запам'ятовує і реконструює сенсорний досвід з шумних і частково закритих спостережень агентів, що перетинають змодельовані кімнати. Агенти рухаються реалістичними траєкторіями, змодельованими на основі гризунів, а середовище моделюється як високорозмірні карти сенсорного досвіду. Навчання нашого автокодера заповнювати шаблони та реконструювати досвід з обмеженням на загальну активність призводить до того, що в шарі кодування з'являються просторово локалізовані вогневі поля, тобто клітини місця. Поля місця, що виникають, відтворюють ключові аспекти феноменології гіпокампу: а) ремапінг (підтримка і повернення до різних вивчених карт у різних середовищах), що реалізується через репозиціювання множин досвіду в прихованому шарі мережі, б) ортогональність просторових репрезентацій у різних областях, в) стійке виникнення поля місця в кімнатах різної форми, причому окремі одиниці демонструють кілька полів місця у великих або складних просторах, і г) повільний дрейф репрезентацій полів місця. Ми стверджуємо, що ці результати виникають тому, що безперервне переміщення простором робить чуттєвий досвід тимчасово безперервним. Ми робимо прогнози, які можна перевірити: а) швидка зміна сенсорного контексту порушує поля місця, б) поля місця формуються, навіть якщо рекурентні зв'язки заблоковані, але повернення до раніше засвоєних репрезентацій при перемапуванні скасовується, в) розмірність часово плавного досвіду задає розмірність полів місця, в тому числі під час віртуальної навігації в абстрактних просторах.",264,Neurons and Cognition (q-bio.NC),https://arxiv.org/abs/2408.05798,https://arxiv.org/pdf/2408.05798.pdf,true
2507.07257,Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery,"Licong Xu, Milind Sarkar, Anto I. Lonappan, Íñigo Zubeldia, Pablo Villanueva-Domingo, Santiago Casas, Christian Fidler, Chetana Amancharla, Ujjwal Tiwari, Adrian Bayer, Chadi Ait Ekiou, Miles Cranmer, Adrian Dimitrov, James Fergusson, Kahaan Gandhi, Sven Krippendorf, Andrew Laverick, Julien Lesgourgues, Antony Lewis, Thomas Meier, Blake Sherwin, Kristen Surrao, Francisco Villaescusa-Navarro, Chi Wang, Xueqing Xu, Boris Bolliet","We present a multi-agent system for automation of scientific research tasks, cmbagent. The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning & Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud.","Ми представляємо мультиагентну систему для автоматизації науково-дослідницьких завдань cmbagent. Система складається з близько 30 агентів на основі великої мовної моделі (LLM) і реалізує стратегію планування та контролю для організації робочого процесу агентів без участі людини на кожному етапі. Кожен агент спеціалізується на своєму завданні (виконання пошуку в наукових статтях і кодових базах, написання коду, інтерпретація результатів, критика результатів роботи інших агентів), а система здатна виконувати код локально. Ми успішно застосували cmbagent для виконання завдання з космології на рівні PhD (вимірювання космологічних параметрів за допомогою даних про наднові) і оцінили його продуктивність на двох наборах тестів, виявивши вищу продуктивність порівняно з найсучаснішими LLM. Вихідний код доступний на GitHub, також доступні демонстраційні відео, система розгорнута на HuggingFace і буде доступна в хмарі.",135,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07257,https://arxiv.org/pdf/2507.07257.pdf,true
2507.06952,What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models,"Keyon Vafa, Peter G. Chang, Ashesh Rambachan, Sendhil Mullainathan","Foundation models are premised on the idea that sequence prediction can uncover deeper domain understanding, much like how Kepler's predictions of planetary motion later led to the discovery of Newtonian mechanics. However, evaluating whether these models truly capture deeper structure remains a challenge. We develop a technique for evaluating foundation models that examines how they adapt to synthetic datasets generated from some postulated world model. Our technique measures whether the foundation model's inductive bias aligns with the world model, and so we refer to it as an inductive bias probe. Across multiple domains, we find that foundation models can excel at their training tasks yet fail to develop inductive biases towards the underlying world model when adapted to new tasks. We particularly find that foundation models trained on orbital trajectories consistently fail to apply Newtonian mechanics when adapted to new physics tasks. Further analysis reveals that these models behave as if they develop task-specific heuristics that fail to generalize.","Фундаментальні моделі ґрунтуються на ідеї, що передбачення послідовності може відкрити глибше розуміння предметної області, подібно до того, як передбачення Кеплера про рух планет пізніше призвели до відкриття ньютонівської механіки. Однак оцінка того, чи ці моделі справді відображають глибшу структуру, залишається складним завданням. Ми розробили методику оцінки фундаментальних моделей, яка досліджує, як вони адаптуються до синтетичних наборів даних, створених на основі певної постульованої моделі світу. Наша методика вимірює, чи збігається індуктивне зміщення моделі фундаменту з моделлю світу, і тому ми називаємо її зондом індуктивного зміщення. У різних сферах ми виявили, що фундаментальні моделі можуть успішно виконувати свої навчальні завдання, але не можуть розвинути індуктивне упередження щодо базової моделі світу, коли вони адаптуються до нових завдань. Зокрема, ми виявили, що фундаментальні моделі, навчені на орбітальних траєкторіях, постійно не застосовують ньютонівську механіку, коли їх адаптують до нових фізичних задач. Подальший аналіз показує, що ці моделі поводяться так, ніби вони розробляють евристики для конкретних задач, які не здатні до узагальнення.",159,Machine Learning (cs.LG),https://arxiv.org/abs/2507.06952,https://arxiv.org/pdf/2507.06952.pdf,true
2507.07115,Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation,"Javal Vyas, Mehmet Mercangoz","The increasing complexity of modern chemical processes, coupled with workforce shortages and intricate fault scenarios, demands novel automation paradigms that blend symbolic reasoning with adaptive control. In this work, we introduce a unified agentic framework that leverages large language models (LLMs) for both discrete fault-recovery planning and continuous process control within a single architecture. We adopt Finite State Machines (FSMs) as interpretable operating envelopes: an LLM-driven planning agent proposes recovery sequences through the FSM, a Simulation Agent executes and checks each transition, and a Validator-Reprompting loop iteratively refines invalid plans. In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25 states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path success within five reprompts-outperforming open-source LLMs in both accuracy and latency. In Case Study 2, the same framework modulates dual-heater inputs on a laboratory TCLab platform (and its digital twin) to maintain a target average temperature under persistent asymmetric disturbances. Compared to classical PID control, our LLM-based controller attains similar performance, while ablation of the prompting loop reveals its critical role in handling nonlinear dynamics. We analyze key failure modes-such as instruction following lapses and coarse ODE approximations. Our results demonstrate that, with structured feedback and modular agents, LLMs can unify high-level symbolic planningand low-level continuous control, paving the way towards resilient, language-driven automation in chemical engineering.","Зростаюча складність сучасних хімічних процесів у поєднанні з дефіцитом робочої сили та складними сценаріями несправностей вимагає нових парадигм автоматизації, які поєднують символьне мислення з адаптивним управлінням. У цій роботі ми представляємо уніфікований агентний фреймворк, який використовує великі мовні моделі (LLM) як для дискретного планування усунення несправностей, так і для безперервного управління процесом в рамках єдиної архітектури. Ми використовуємо скінченні автомати (FSM) як інтерпретовані операційні оболонки: агент планування, керований LLM, пропонує послідовності відновлення через FSM, агент моделювання виконує і перевіряє кожен перехід, а цикл валідатора-відповіді ітеративно вдосконалює невірні плани. У прикладі 1 на 180 випадково згенерованих FSM різного розміру (4-25 станів, 4-300 переходів) GPT-4o і GPT-4o-mini досягають 100% успіху на допустимих шляхах протягом п'яти відповідей, перевершуючи LLM з відкритим вихідним кодом як за точністю, так і за часом затримки. У тематичному дослідженні 2 та сама система модулює входи двох нагрівачів на лабораторній платформі TCLab (та її цифровому двійнику) для підтримання заданої середньої температури при постійних асиметричних збуреннях. Порівняно з класичним ПІД-регулюванням, наш контролер на основі LLM досягає подібної продуктивності, тоді як усунення контуру підказки виявляє його критичну роль в управлінні нелінійною динамікою. Ми проаналізували ключові режими збоїв, такі як пропуски команд і грубі апроксимації ОДУ. Наші результати демонструють, що завдяки структурованому зворотному зв'язку та модульним агентам LLM можуть об'єднати високорівневе символьне планування та низькорівневе безперервне керування, прокладаючи шлях до стійкої автоматизації хімічної інженерії, керованої мовою.",219,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07115,https://arxiv.org/pdf/2507.07115.pdf,true
2507.07134,BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks,"Mridula Vijendran, Shuang Chen, Jingjing Deng, Hubert P. H. Shum","The pervasive issue of bias in AI presents a significant challenge to painting classification, and is getting more serious as these systems become increasingly integrated into tasks like art curation and restoration. Biases, often arising from imbalanced datasets where certain artistic styles dominate, compromise the fairness and accuracy of model predictions, i.e., classifiers are less accurate on rarely seen paintings. While prior research has made strides in improving classification performance, it has largely overlooked the critical need to address these underlying biases, that is, when dealing with out-of-distribution (OOD) data. Our insight highlights the necessity of a more robust approach to bias mitigation in AI models for art classification on biased training data. We propose a novel OOD-informed model bias adaptive sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It addresses these challenges by dynamically adjusting temperature scaling and sampling probabilities, thereby promoting a more equitable representation of all classes. We evaluate our proposed approach to the KaoKore and PACS datasets, focusing on the model's ability to reduce class-wise bias. We further propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to assess class-wise separation and per-class bias reduction. Our method demonstrates the ability to balance high performance with fairness, making it a robust solution for unbiasing AI models in the art domain.","Поширена проблема упередженості в штучному інтелекті становить значну проблему для класифікації картин і стає дедалі серйознішою, оскільки ці системи дедалі більше інтегруються в такі завдання, як кураторство та реставрація творів мистецтва. Упередження, що часто виникають через незбалансовані набори даних, де домінують певні художні стилі, ставлять під сумнів справедливість і точність прогнозів моделі, тобто класифікатори менш точні щодо рідкісних картин. Хоча попередні дослідження досягли значних успіхів у покращенні ефективності класифікації, вони здебільшого ігнорували критичну необхідність усунення цих базових упереджень, тобто при роботі з даними, що не мають розподілу (OOD). Наше дослідження підкреслює необхідність більш надійного підходу до пом'якшення упереджень у моделях ШІ для художньої класифікації на упереджених навчальних даних. Ми пропонуємо новий метод адаптивної дискретизації моделі, що враховує зсув OOD, під назвою BOOST (Bias-Oriented OOD Sampling and Tuning - вибірка та налаштування з урахуванням зсуву). Він вирішує ці проблеми шляхом динамічного налаштування температурного масштабування та ймовірності вибірки, тим самим сприяючи більш справедливому представленню всіх класів. Ми оцінюємо запропонований нами підхід до наборів даних KaoKore та PACS, зосереджуючись на здатності моделі зменшувати зміщення між класами. Ми також пропонуємо нову метрику, Same-Dataset OOD Detection Score (SODC), призначену для оцінювання класового розділення та зменшення зміщення для кожного класу. Наш метод демонструє здатність балансувати між високою продуктивністю та справедливістю, що робить його надійним рішенням для неупереджених моделей ШІ в галузі мистецтва.",215,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07134,https://arxiv.org/pdf/2507.07134.pdf,true
2507.07203,State-Inference-Based Prompting for Natural Language Trading with Game NPCs,"Minkyung Kim, Junsik Kim, Hwidong Bae, Woongcheol Yang, Sangdon Park, Sohee Bae","Large Language Models enable dynamic game interactions but struggle with rule-governed trading systems. Current implementations suffer from rule violations, such as item hallucinations and calculation errors, that erode player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable trading through autonomous dialogue state inference and context-specific rule adherence. The approach decomposes trading into six states within a unified prompt framework, implementing context-aware item referencing and placeholder-based price calculations. Evaluation across 100 trading dialogues demonstrates >97% state compliance, >95% referencing accuracy, and 99.7% calculation precision. SIBP maintains computational efficiency while outperforming baseline approaches, establishing a practical foundation for trustworthy NPC interactions in commercial games.","Великі мовні моделі уможливлюють динамічну ігрову взаємодію, але борються з торговими системами, керованими правилами. Поточні реалізації страждають від порушень правил, таких як галюцинації предметів і помилки в розрахунках, які підривають довіру гравців. Підказки на основі висновків про стан (SIBP) уможливлюють надійну торгівлю завдяки автономному діалоговому висновку про стан і дотриманню правил, що залежать від контексту. Цей підхід розбиває торгівлю на шість станів в рамках єдиної системи підказок, реалізуючи контекстно-залежне посилання на товар і розрахунок ціни на основі заповнювачів. Оцінка 100 торгових діалогів демонструє >97% дотримання станів, >95% точності посилань і 99,7% точності розрахунків. SIBP зберігає обчислювальну ефективність, перевершуючи базові підходи, створюючи практичну основу для надійної взаємодії NPC у комерційних іграх.",101,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07203,https://arxiv.org/pdf/2507.07203.pdf,true
2507.07217,Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains,"Zili Wang, Frank Montabon, Kristin Yvonne Rozier","Supply chain networks are complex systems that are challenging to analyze; this problem is exacerbated when there are illicit activities involved in the supply chain, such as counterfeit parts, forced labor, or human trafficking. While machine learning (ML) can find patterns in complex systems like supply chains, traditional ML techniques require large training data sets. However, illicit supply chains are characterized by very sparse data, and the data that is available is often (purposely) corrupted or unreliable in order to hide the nature of the activities. We need to be able to automatically detect new patterns that correlate with such illegal activity over complex, even temporal data, without requiring large training data sets. We explore neurosymbolic methods for identifying instances of illicit activity in supply chains and compare the effectiveness of manual and automated feature extraction from news articles accurately describing illicit activities uncovered by authorities. We propose a question tree approach for querying a large language model (LLM) to identify and quantify the relevance of articles. This enables a systematic evaluation of the differences between human and machine classification of news articles related to forced labor in supply chains.","Мережі ланцюгів поставок - це складні системи, які важко аналізувати; ця проблема загострюється, коли в ланцюзі поставок задіяні незаконні дії, такі як підроблені деталі, примусова праця або торгівля людьми. Хоча машинне навчання (МН) може знаходити закономірності в таких складних системах, як ланцюги поставок, традиційні методи МН вимагають великих наборів навчальних даних. Однак незаконні ланцюги поставок характеризуються дуже рідкісними даними, а ті, що є, часто (навмисно) пошкоджені або недостовірні, щоб приховати характер діяльності. Ми повинні мати можливість автоматично виявляти нові патерни, які корелюють з такою незаконною діяльністю, на основі складних, навіть часових даних, не вимагаючи великих навчальних наборів даних. Ми досліджуємо нейросимволічні методи для виявлення випадків незаконної діяльності в ланцюгах поставок і порівнюємо ефективність ручного та автоматизованого вилучення ознак з новинних статей, які точно описують незаконну діяльність, викриту органами влади. Ми пропонуємо підхід на основі дерева запитань для запитів до великої мовної моделі (ВММ) для визначення та кількісної оцінки релевантності статей. Це дозволяє систематично оцінювати відмінності між людською та машинною класифікацією новинних статей, пов'язаних з примусовою працею в ланцюгах поставок.",190,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07217,https://arxiv.org/pdf/2507.07217.pdf,true
2507.07302,Application of LLMs to Multi-Robot Path Planning and Task Allocation,Ashish Kumar,"Efficient exploration is a well known problem in deep reinforcement learning and this problem is exacerbated in multi-agent reinforcement learning due the intrinsic complexities of such algorithms. There are several approaches to efficiently explore an environment to learn to solve tasks by multi-agent operating in that environment, of which, the idea of expert exploration is investigated in this work. More specifically, this work investigates the application of large-language models as expert planners for efficient exploration in planning based tasks for multiple agents.","Ефективне дослідження є добре відомою проблемою в глибокому навчанні з підкріпленням, і ця проблема загострюється в мультиагентному навчанні з підкріпленням через внутрішню складність таких алгоритмів. Існує декілька підходів до ефективного дослідження середовища для навчання розв'язування задач мультиагентами, що працюють у цьому середовищі, з яких ідея експертного дослідження досліджується в цій роботі. Більш конкретно, ця робота досліджує застосування широкомовних моделей як експертів-планувальників для ефективного дослідження в задачах, що базуються на плануванні для декількох агентів.",82,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07302,https://arxiv.org/pdf/2507.07302.pdf,true
2507.07306,ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning,"Yichen Lu, Wei Dai, Jiaen Liu, Ching Wing Kwok, Zongheng Wu, Xudong Xiao, Ao Sun, Sheng Fu, Jianyuan Zhan, Yian Wang, Takatomo Saito, Sicheng Lai","LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here: ","Перекладачі на рівні LLM досягають результатів перекладу, близьких до людських, і здатні обробляти довші та складніші контексти з більшою ефективністю. Однак, як правило, вони обмежені лише текстовими вхідними даними. У цій статті ми представляємо ViDove - систему перекладацьких агентів, призначену для мультимодального введення. Натхненна робочим процесом перекладачів-людей, ViDove використовує візуальну та контекстну довідкову інформацію для покращення процесу перекладу. Крім того, ми інтегрували мультимодальну систему пам'яті та модулі довгострокової і короткострокової пам'яті, збагачені знаннями про конкретну галузь, що дає змогу агенту працювати точніше й адаптивніше в реальних сценаріях. У результаті ViDove досягає значно вищої якості перекладу як при створенні субтитрів, так і при виконанні загальних перекладацьких завдань, покращуючи показники BLEU на 28%, а SubER - на 15% порівняно з попередніми базовими показниками. Крім того, ми представляємо DoveBench - новий бенчмарк для автоматичного субтитрування та перекладу довготривалих відео, який містить 17 годин високоякісних даних з людськими анотаціями. Наш код доступний тут:",152,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07306,https://arxiv.org/pdf/2507.07306.pdf,true
2507.07341,On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment,"Sarah Ball, Greg Gluch, Shafi Goldwasser, Frauke Kreuter, Omer Reingold, Guy N. Rothblum","With the increased deployment of large language models (LLMs), one concern is their potential misuse for generating harmful content. Our work studies the alignment challenge, with a focus on filters to prevent the generation of unsafe information. Two natural points of intervention are the filtering of the input prompt before it reaches the model, and filtering the output after generation. Our main results demonstrate computational challenges in filtering both prompts and outputs. First, we show that there exist LLMs for which there are no efficient prompt filters: adversarial prompts that elicit harmful behavior can be easily constructed, which are computationally indistinguishable from benign prompts for any efficient filter. Our second main result identifies a natural setting in which output filtering is computationally intractable. All of our separation results are under cryptographic hardness assumptions. In addition to these core findings, we also formalize and study relaxed mitigation approaches, demonstrating further computational barriers. We conclude that safety cannot be achieved by designing filters external to the LLM internals (architecture and weights); in particular, black-box access to the LLM will not suffice. Based on our technical results, we argue that an aligned AI system's intelligence cannot be separated from its judgment.","У зв'язку з дедалі ширшим впровадженням великих мовних моделей (ВММ) виникає занепокоєння щодо їхнього потенційного зловживання для створення шкідливого контенту. Наша робота присвячена дослідженню проблеми вирівнювання з акцентом на фільтрах для запобігання генерації небезпечної інформації. Дві природні точки втручання - це фільтрація вхідного запиту до того, як він потрапляє до моделі, і фільтрація вихідних даних після генерації. Наші основні результати демонструють обчислювальні проблеми при фільтрації як підказок, так і результатів. По-перше, ми показали, що існують ЛПМ, для яких не існує ефективних фільтрів підказок: можна легко сконструювати ворожі підказки, які викликають шкідливу поведінку, і які обчислювально не відрізняються від доброякісних підказок для будь-якого ефективного фільтра. Наш другий основний результат визначає природні умови, в яких фільтрація вихідних даних є нерозв'язною з точки зору обчислень. Всі наші результати розділення отримані за припущень про криптографічну стійкість. На додаток до цих основних висновків, ми також формалізували і дослідили більш м'які підходи до пом'якшення наслідків, продемонструвавши додаткові обчислювальні бар'єри. Ми дійшли висновку, що безпека не може бути досягнута шляхом розробки фільтрів, зовнішніх по відношенню до внутрішніх компонентів LLM (архітектури та ваг); зокрема, доступу до LLM за принципом ""чорного ящика"" буде недостатньо. Ґрунтуючись на наших технічних результатах, ми стверджуємо, що інтелект вирівняної системи ШІ не можна відокремити від її суджень.",198,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07341,https://arxiv.org/pdf/2507.07341.pdf,true
2507.07355,Supply Chain Optimization via Generative Simulation and Iterative Decision Policies,"Haoyue Bai, Haoyu Wang, Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haifeng Chen, Yanjie Fu","High responsiveness and economic efficiency are critical objectives in supply chain transportation, both of which are influenced by strategic decisions on shipping mode. An integrated framework combining an efficient simulator with an intelligent decision-making algorithm can provide an observable, low-risk environment for transportation strategy design. An ideal simulation-decision framework must (1) generalize effectively across various settings, (2) reflect fine-grained transportation dynamics, (3) integrate historical experience with predictive insights, and (4) maintain tight integration between simulation feedback and policy refinement. We propose Sim-to-Dec framework to satisfy these requirements. Specifically, Sim-to-Dec consists of a generative simulation module, which leverages autoregressive modeling to simulate continuous state changes, reducing dependence on handcrafted domain-specific rules and enhancing robustness against data fluctuations; and a history-future dual-aware decision model, refined iteratively through end-to-end optimization with simulator interactions. Extensive experiments conducted on three real-world datasets demonstrate that Sim-to-Dec significantly improves timely delivery rates and profit.","Висока швидкість реагування та економічна ефективність є критично важливими цілями в транспортуванні ланцюгів поставок, на які впливають стратегічні рішення щодо способу доставки. Інтегрована система, що поєднує ефективний симулятор з інтелектуальним алгоритмом прийняття рішень, може забезпечити спостережуване середовище з низьким рівнем ризику для розробки транспортної стратегії. Ідеальна система моделювання та прийняття рішень повинна (1) ефективно узагальнювати різні умови, (2) відображати дрібнозернисту динаміку перевезень, (3) інтегрувати історичний досвід з прогнозними оцінками і (4) підтримувати тісний зв'язок між зворотним зв'язком моделювання та уточненням політики. Ми пропонуємо фреймворк Sim-to-Dec, щоб задовольнити ці вимоги. Зокрема, Sim-to-Dec складається з модуля генеративного моделювання, який використовує авторегресійне моделювання для імітації безперервних змін стану, зменшуючи залежність від ручних правил, специфічних для конкретної галузі, та підвищуючи стійкість до коливань даних; та моделі прийняття рішень з подвійним розумінням історії та майбутнього, яка вдосконалюється ітеративно шляхом наскрізної оптимізації за допомогою симулятора взаємодії. Широкі експерименти, проведені на трьох реальних наборах даних, демонструють, що Sim-to-Dec значно покращує показники своєчасної доставки та прибутку.",147,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07355,https://arxiv.org/pdf/2507.07355.pdf,true
2507.07599,Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models,"Sedigh Khademi, Jim Black, Christopher Palmer, Muhammad Javed, Hazel Clothier, Jim Buttery, Gerardo Luis Dimaguila","This study evaluates fine-tuned Llama 3.2 models for extracting vaccine-related information from emergency department triage notes to support near real-time vaccine safety surveillance. Prompt engineering was used to initially create a labeled dataset, which was then confirmed by human annotators. The performance of prompt-engineered models, fine-tuned models, and a rule-based approach was compared. The fine-tuned Llama 3 billion parameter model outperformed other models in its accuracy of extracting vaccine names. Model quantization enabled efficient deployment in resource-constrained environments. Findings demonstrate the potential of large language models in automating data extraction from emergency department notes, supporting efficient vaccine safety surveillance and early detection of emerging adverse events following immunization issues.","Це дослідження оцінює доопрацьовані моделі Llama 3.2 для вилучення інформації, пов'язаної з вакцинами, із записів про сортування у відділенні невідкладної допомоги для підтримки нагляду за безпекою вакцин у режимі, близькому до реального часу. Оперативний інжиніринг був використаний для створення маркованого набору даних, який потім був підтверджений людьми-анотаторами. Було проведено порівняння ефективності моделей, створених за допомогою експрес-інженерії, доопрацьованих моделей та підходу, заснованого на правилах. Точно налаштована модель Llama з 3 мільярдами параметрів перевершила інші моделі за точністю вилучення назв вакцин. Квантування моделі дозволило ефективно розгортати її в умовах обмежених ресурсів. Результати дослідження демонструють потенціал великих мовних моделей для автоматизації вилучення даних із записів відділень невідкладної допомоги, підтримки ефективного нагляду за безпекою вакцин та раннього виявлення нових несприятливих подій, пов'язаних з імунізацією.",109,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07599,https://arxiv.org/pdf/2507.07599.pdf,true
2507.07426,"DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search","Zerui Yang, Yuwei Wan, Yinqiao Li, Yudai Matsuda, Tong Xie, Linqi Song","Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug discovery. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repurposing. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Without requiring domain-specific fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug discovery.","Нещодавні досягнення в галузі великих мовних моделей продемонстрували значний потенціал у таких наукових галузях, як розробка ліків. Однак їхня ефективність залишається обмеженою, коли міркування виходять за межі знань, набутих під час попереднього навчання. Традиційні підходи, такі як точне налаштування або генерація, доповнена пошуком, стикаються з обмеженнями, які полягають або у високих обчислювальних витратах, або у нездатності повною мірою використовувати структуровані наукові дані. Для подолання цих проблем ми пропонуємо DrugMCTS - новий фреймворк, який синергетично інтегрує RAG, мультиагентну взаємодію та пошук по дереву Монте-Карло для перепризначення лікарських засобів. Фреймворк використовує п'ять спеціалізованих агентів, завданням яких є пошук та аналіз молекулярної та білкової інформації, що дозволяє здійснювати структуровані та ітеративні міркування. Не вимагаючи тонкого налаштування для конкретної області, DrugMCTS дозволяє Qwen2.5-7B-Instruct перевершити Deepseek-R1 більш ніж на 20\%. Широкі експерименти на наборах даних DrugBank і KIBA демонструють, що DrugMCTS досягає значно вищого рівня запам'ятовування і надійності порівняно з універсальними LLM і базовими лініями глибокого навчання. Наші результати підкреслюють важливість структурованих міркувань, співпраці на основі агентів і механізмів пошуку зі зворотним зв'язком для вдосконалення застосувань LLM для пошуку ліків.",160,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07426,https://arxiv.org/pdf/2507.07426.pdf,true
2507.07445,StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley,"Weihao Tan, Changjiu Jiang, Yu Duan, Mingcong Lei, Jiageng Li, Yitian Hong, Xinrun Wang, Bo An","Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments.","Автономні агенти, які орієнтуються в людському суспільстві, повинні опанувати як виробничу діяльність, так і соціальну взаємодію, проте існуючі бенчмарки рідко оцінюють ці навички одночасно. Щоб заповнити цю прогалину, ми представляємо StarDojo - новий бенчмарк на основі Stardew Valley, розроблений для оцінки ШІ-агентів у відкритих симуляціях виробничого життя. У StarDojo агентам доручено виконувати основні види діяльності, такі як сільське господарство та ремесла, одночасно беручи участь у соціальних взаємодіях для налагодження стосунків у жвавій спільноті. StarDojo містить 1000 ретельно відібраних завдань у п'яти ключових сферах: фермерство, ремесло, розвідка, бойові дії та соціальна взаємодія. Крім того, ми надаємо компактну підгрупу зі 100 репрезентативних завдань для ефективного оцінювання моделі. Бенчмарк пропонує уніфікований, зручний інтерфейс, який усуває необхідність керування за допомогою клавіатури та миші, підтримує всі основні операційні системи та дозволяє паралельне виконання декількох екземплярів середовища, що робить його особливо придатним для оцінки найпотужніших фундаментальних агентів, що працюють на основі мультимодальних великих мовних моделей (MLLMs). Широке оцінювання найсучасніших агентів MLLMs демонструє суттєві обмеження: найефективніша модель, GPT-4.1, досягла лише 12,7% успішності, в першу чергу через проблеми з візуальним розумінням, мультимодальними міркуваннями та низькорівневими маніпуляціями. StarDojo, як зручне для користувача середовище і бенчмарк, має на меті сприяти подальшим дослідженням у напрямку створення надійних, відкритих агентів у складних виробничо-життєвих середовищах.",203,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07445,https://arxiv.org/pdf/2507.07445.pdf,true
2507.07544,Position: We Need An Algorithmic Understanding of Generative AI,"Oliver Eberle, Thomas McGee, Hamza Giaffar, Taylor Webb, Ida Momennejad","What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems.","Які алгоритми насправді вивчають і використовують для розв'язування задач студенти, що навчаються на рівні LLM? Дослідження, що розглядають це питання, нечисленні, оскільки дослідницькі пріоритети зосереджені на підвищенні продуктивності за рахунок масштабування, залишаючи теоретичну та емпіричну прогалину в розумінні нових алгоритмів. У цій аналітичній записці пропонується AlgEval: платформа для систематичного дослідження алгоритмів, які вивчають і використовують магістри. AlgEval має на меті виявити алгоритмічні примітиви, що відображаються в латентних уявленнях, увазі та обчисленнях часу виведення, а також їхній алгоритмічний склад для вирішення конкретних завдань. Ми висвітлюємо потенційні методологічні шляхи та наводимо практичний приклад для досягнення цієї мети, зосереджуючись на емерджентних алгоритмах пошуку. Наш кейс ілюструє як формування гіпотез про алгоритми-кандидати зверху вниз, так і висхідну перевірку цих гіпотез за допомогою аналізу патернів уваги та прихованих станів на рівні схем. Сувора, систематична оцінка того, як ШНМ насправді розв'язують задачі, є альтернативою ресурсномісткому масштабуванню, переорієнтовуючи галузь на принципове розуміння обчислень, що лежать в їх основі. Такі алгоритмічні пояснення пропонують шлях до зрозумілої для людини інтерпретації, що дозволяє зрозуміти внутрішні міркування моделі. Це, в свою чергу, може призвести до створення більш ефективних методів навчання і підвищення продуктивності, а також нових архітектур для наскрізних і мультиагентних систем.",190,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07544,https://arxiv.org/pdf/2507.07544.pdf,true
2507.07576,On Trustworthy Rule-Based Models and Explanations,"Mohamed Siala, Jordi Planes, Joao Marques-Silva","A task of interest in machine learning (ML) is that of ascribing explanations to the predictions made by ML models. Furthermore, in domains deemed high risk, the rigor of explanations is paramount. Indeed, incorrect explanations can and will mislead human decision makers. As a result, and even if interpretability is acknowledged as an elusive concept, so-called interpretable models are employed ubiquitously in high-risk uses of ML and data mining (DM). This is the case for rule-based ML models, which encompass decision trees, diagrams, sets and lists. This paper relates explanations with well-known undesired facets of rule-based ML models, which include negative overlap and several forms of redundancy. The paper develops algorithms for the analysis of these undesired facets of rule-based systems, and concludes that well-known and widely used tools for learning rule-based ML models will induce rule sets that exhibit one or more negative facets.","У машинному навчанні (ML) цікавим завданням є надання пояснень прогнозам, зробленим моделями ML. Крім того, у сферах, які вважаються високоризикованими, точність пояснень має першорядне значення. Дійсно, неправильні пояснення можуть і будуть вводити в оману людей, які приймають рішення. Як наслідок, навіть якщо інтерпретованість визнається невловимою концепцією, так звані інтерпретовані моделі повсюдно використовуються у сферах з високим рівнем ризику при застосуванні ML та інтелектуального аналізу даних (ІА). Це стосується моделей ML на основі правил, які включають дерева рішень, діаграми, множини та списки. Ця стаття пов'язує пояснення з добре відомими небажаними аспектами моделей ML на основі правил, які включають негативне перекриття і кілька форм надмірності. У статті розроблено алгоритми для аналізу цих небажаних аспектів систем, заснованих на правилах, і зроблено висновок, що відомі та широко використовувані інструменти для навчання моделей ML, заснованих на правилах, будуть індукувати набори правил, які демонструють один або більше негативних аспектів.",145,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07576,https://arxiv.org/pdf/2507.07576.pdf,true
2507.07595,Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs,"Zhixiang Su, Di Wang, Chunyan Miao","Recent investigations on the effectiveness of Graph Neural Network (GNN)-based models for link prediction in Knowledge Graphs (KGs) show that vanilla aggregation does not significantly impact the model performance. In this paper, we introduce a novel method, named Context Pooling, to enhance GNN-based models' efficacy for link predictions in KGs. To our best of knowledge, Context Pooling is the first methodology that applies graph pooling in KGs. Additionally, Context Pooling is first-of-its-kind to enable the generation of query-specific graphs for inductive settings, where testing entities are unseen during training. Specifically, we devise two metrics, namely neighborhood precision and neighborhood recall, to assess the neighbors' logical relevance regarding the given queries, thereby enabling the subsequent comprehensive identification of only the logically relevant neighbors for link prediction. Our method is generic and assessed by being applied to two state-of-the-art (SOTA) models on three public transductive and inductive datasets, achieving SOTA performance in 42 out of 48 settings.","Нещодавні дослідження ефективності моделей на основі графових нейронних мереж (ГНМ) для прогнозування зв'язків у графах знань (ГЗ) показали, що звичайне агрегування не має значного впливу на продуктивність моделі. У цій статті ми представляємо новий метод, названий контекстним об'єднанням (Context Pooling), для підвищення ефективності моделей на основі ГНМ для прогнозування зв'язків у графах знань. Наскільки нам відомо, Context Pooling є першою методологією, яка застосовує об'єднання графів у КГ. Крім того, Context Pooling вперше у своєму роді дозволяє генерувати специфічні для запиту графи для індуктивних умов, коли об'єкти тестування невидимі під час навчання. Зокрема, ми розробили дві метрики, а саме точність сусідства і відгук сусідів, для оцінки логічної релевантності сусідів щодо заданих запитів, тим самим дозволяючи подальшу всебічну ідентифікацію тільки логічно релевантних сусідів для прогнозування зв'язків. Наш метод є загальним і оцінюється шляхом застосування до двох найсучасніших (SOTA) моделей на трьох публічних трансдуктивних та індуктивних наборах даних, досягаючи продуктивності SOTA в 42 з 48 налаштувань.",155,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07595,https://arxiv.org/pdf/2507.07595.pdf,true
2507.07619,Towards conservative inference in credal networks using belief functions: the case of credal chains,"Marco Sangalli, Thomas Krak, Cassio de Campos","This paper explores belief inference in credal networks using Dempster-Shafer theory. By building on previous work, we propose a novel framework for propagating uncertainty through a subclass of credal networks, namely chains. The proposed approach efficiently yields conservative intervals through belief and plausibility functions, combining computational speed with robust uncertainty representation. Key contributions include formalizing belief-based inference methods and comparing belief-based inference against classical sensitivity analysis. Numerical results highlight the advantages and limitations of applying belief inference within this framework, providing insights into its practical utility for chains and for credal networks in general.","У цій статті досліджується виведення переконань у мережах довіри з використанням теорії Демпстера-Шейфера. Спираючись на попередні роботи, ми пропонуємо нову структуру для поширення невизначеності через підклас мереж довіри, а саме ланцюги. Запропонований підхід ефективно дає консервативні інтервали за допомогою функцій вірогідності та правдоподібності, поєднуючи швидкість обчислень з надійним представленням невизначеності. Основний внесок включає формалізацію методів виведення на основі переконань та порівняння виведення на основі переконань з класичним аналізом чутливості. Чисельні результати висвітлюють переваги та обмеження застосування висновку на основі переконань у цій структурі, надаючи уявлення про його практичну корисність для ланцюжків і для кредитних мереж загалом.",94,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07619,https://arxiv.org/pdf/2507.07619.pdf,true
2507.07644,PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations,"Fedor Rodionov, Abdelrahman Eldesokey, Michael Birsak, John Femiani, Bernard Ghanem, Peter Wonka","We introduce PlanQA, a diagnostic benchmark for evaluating geometric and spatial reasoning in large-language models (LLMs). PlanQA is grounded in structured representations of indoor scenes, such as kitchens, living rooms, and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The benchmark includes diverse question types that test not only metric and topological reasoning (e.g., distance, visibility, shortest paths) but also interior design constraints such as affordance, clearance, balance, and usability. Our results across a variety of frontier open-source and commercial LLMs show that while models may succeed in shallow queries, they often fail to simulate physical constraints, preserve spatial coherence, or generalize under layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they do not consistently reason about real-world layouts. We hope that this benchmark inspires new work on language models that can accurately infer and manipulate spatial and geometric properties in practical settings.","Представляємо PlanQA, діагностичний тест для оцінювання геометричного та просторового мислення у великомасштабних моделях (LLM). PlanQA ґрунтується на структурованих представленнях внутрішніх сцен, таких як кухні, вітальні та спальні, закодованих у символьному форматі (наприклад, JSON, XML-макети). Тест включає різноманітні типи запитань, які перевіряють не лише метричні та топологічні міркування (наприклад, відстань, видимість, найкоротші шляхи), але й обмеження дизайну інтер'єру, такі як доступність, простір, збалансованість та зручність використання. Наші результати, отримані на різноманітних прикордонних відкритих і комерційних LLM, показують, що хоча моделі можуть бути успішними в неглибоких запитах, вони часто не можуть імітувати фізичні обмеження, зберігати просторову узгодженість або узагальнювати при збуреннях макета. PlanQA виявляє чітку сліпу зону в сучасних LLM: вони не можуть послідовно міркувати про реальні макети. Ми сподіваємося, що цей бенчмарк надихне на нову роботу над мовними моделями, які можуть точно виводити та маніпулювати просторовими та геометричними властивостями в практичних умовах.",148,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07644,https://arxiv.org/pdf/2507.07644.pdf,true
2507.07723,Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization,"Chengtao Jian, Kai Yang, Ye Ouyang, Xiaozhou Ye","Direct Preference Optimization (DPO) has emerged as a popular and efficient alternative to reward modeling and reinforcement learning for aligning language models with human preferences. Despite its empirical success, the theoretical properties and intrinsic limitations of DPO remain underexplored. In this work, we first present a comprehensive analysis of DPO's dynamics from a probability evolution perspective. Our analysis reveals that DPO is highly sensitive to initialization. It also tends to misallocate probability mass, which can inadvertently shift probability toward irrelevant or undesired responses. This misallocation may unintentionally reinforce model bias, thereby compromising both the stability of model alignment and the consistency with intended preferences. Motivated by these theoretical findings, we propose a theoretically grounded bilevel optimization framework that tightly integrate supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference optimization. Our approach introduces a principled regularization scheme to explicitly encourage absolute probability improvement for preferred outputs, while maintaining stable optimization dynamics. Experiments on challenging reasoning and summarization benchmarks elucidate that our method consistently improves reasoning accuracy and better aligns output distributions with intended preferences, outperforming standard DPO. Stable preference optimization provides new insights into the design of preference-based alignment objectives and opens up new avenues towards more reliable and interpretable language model alignment.","Пряма оптимізація переваг (Direct Preference Optimization, DPO) стала популярною та ефективною альтернативою моделюванню винагороди та навчанню з підкріпленням для узгодження мовних моделей з людськими вподобаннями. Незважаючи на її емпіричний успіх, теоретичні властивості та внутрішні обмеження DPO залишаються недостатньо вивченими. У цій роботі ми вперше представляємо комплексний аналіз динаміки DPO з точки зору еволюції ймовірностей. Наш аналіз показує, що DPO дуже чутливий до ініціалізації. Він також має тенденцію до неправильного розподілу ймовірнісної маси, що може ненавмисно зміщувати ймовірність у бік нерелевантних або небажаних відповідей. Цей неправильний розподіл може ненавмисно посилити упередженість моделі, тим самим ставлячи під загрозу як стабільність вирівнювання моделі, так і узгодженість із запланованими вподобаннями. Спираючись на ці теоретичні висновки, ми пропонуємо теоретично обґрунтовану систему дворівневої оптимізації, яка тісно інтегрує контрольовану точну настройку з покращеною метою ОПР, так званою оптимізацією стабільних переваг. Наш підхід запроваджує принципову схему регуляризації, яка явно заохочує покращення абсолютної ймовірності для бажаних результатів, зберігаючи при цьому стабільну динаміку оптимізації. Експерименти на складних тестах міркувань та підбиття підсумків показують, що наш метод послідовно підвищує точність міркувань і краще узгоджує розподіл результатів із запланованими вподобаннями, перевершуючи стандартний DPO. Стабільна оптимізація вподобань дає нові уявлення про розробку цілей вирівнювання на основі вподобань і відкриває нові шляхи до більш надійного та інтерпретованого вирівнювання мовних моделей.",204,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07723,https://arxiv.org/pdf/2507.07723.pdf,true
2507.07743,Identification of Violin Reduction via Contour Lines Classification,"Philémon Beghin, Anne-Emmanuelle Ceulemans, François Glineur","The first violins appeared in late 16th-century Italy. Over the next 200 years, they spread across Europe and luthiers of various royal courts, eager to experiment with new techniques, created a highly diverse family of instruments. Around 1750, size standards were introduced to unify violin making for orchestras and conservatories. Instruments that fell between two standards were then reduced to a smaller size by luthiers. These reductions have an impact on several characteristics of violins, in particular on the contour lines, i.e. lines of constant altitude, which look more like a U for non reduced instruments and a V for reduced ones. While such differences are observed by experts, they have not been studied quantitatively. This paper presents a method for classifying violins as reduced or non-reduced based on their contour lines. We study a corpus of 25 instruments whose 3D geometric meshes were acquired via photogrammetry. For each instrument, we extract 10-20 contour lines regularly spaced every millimetre. Each line is fitted with a parabola-like curve (with an equation of the type y = alpha*abs(x)**beta) depending on two parameters, describing how open (beta) and how vertically stretched (alpha) the curve is. We compute additional features from those parameters, using regressions and counting how many values fall under some threshold. We also deal with outliers and non equal numbers of levels, and eventually obtain a numerical profile for each instrument. We then apply classification methods to assess whether geometry alone can predict size reduction. We find that distinguishing between reduced and non reduced instruments is feasible to some degree, taking into account that a whole spectrum of more or less transformed violins exists, for which it is more difficult to quantify the reduction. We also find the opening parameter beta to be the most predictive.","Перші скрипки з'явилися в Італії наприкінці 16 століття. Протягом наступних 200 років вони поширилися по всій Європі, і лютністи різних королівських дворів, які прагнули експериментувати з новими техніками, створили дуже різноманітне сімейство інструментів. Близько 1750 року для уніфікації виготовлення скрипок для оркестрів та консерваторій було запроваджено стандарти розмірів. Інструменти, які потрапляли між двома стандартами, потім зменшувалися до меншого розміру лютнями. Ці зменшення впливають на деякі характеристики скрипок, зокрема на контурні лінії, тобто лінії постійної висоти, які більше схожі на U для незменшених інструментів і на V для зменшених. Хоча такі відмінності спостерігаються експертами, вони не вивчалися кількісно. У цій статті представлено метод класифікації скрипок на редуковані та нередуковані на основі їхніх контурних ліній. Ми досліджуємо корпус з 25 інструментів, тривимірні геометричні сітки яких були отримані за допомогою фотограмметрії. Для кожного інструмента ми виділяємо 10-20 контурних ліній, які регулярно розташовані через кожен міліметр. Кожній лінії відповідає параболоподібна крива (з рівнянням типу y = alpha*abs(x)**beta), що залежить від двох параметрів, які описують, наскільки крива відкрита (бета) і наскільки вона розтягнута по вертикалі (альфа). Ми обчислюємо додаткові характеристики на основі цих параметрів, використовуючи регресії та підраховуючи, скільки значень потрапляє під певний поріг. Ми також маємо справу з викидами та нерівною кількістю рівнів, і зрештою отримуємо числовий профіль для кожного інструменту. Потім ми застосовуємо методи класифікації, щоб оцінити, чи може геометрія сама по собі передбачити зменшення розміру. Ми виявили, що розрізнення між зменшеними і незменшеними інструментами до певної міри можливе, беручи до уваги, що існує цілий спектр більш-менш трансформованих скрипок, для яких кількісно оцінити зменшення складніше. Ми також вважаємо, що параметр відкриття бета є найбільш передбачуваним.",295,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07743,https://arxiv.org/pdf/2507.07743.pdf,true
2507.07893,An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis,"Mingda Zhang, Na Zhao, Jianglong Qing, Qing xu, Kaiwen Pan, Ting luo","The rapid development of artificial intelligence has positioned large language models as fundamental components of intelligent legal systems. However, these models face significant limitations in legal dispute analysis, including insufficient legal knowledge representation, limited concept understanding, and reasoning deficiencies. This research proposes an enhanced framework integrating prompt engineering with multidimensional knowledge graphs. The framework introduces a three-stage hierarchical prompt structure comprising task definition, knowledge background, and reasoning guidance, supplemented by legal-specific reasoning templates and dynamic optimization mechanisms. A three-layer knowledge graph architecture is constructed with legal classification ontology, representation, and instance layers. Four complementary methods enable precise legal concept retrieval: direct legal norm code matching, domain-specific semantic vector similarity, ontology-based path reasoning, and specialized lexical segmentation. These components integrate with web search technology to establish a knowledge-enhanced framework for legal decision-making. Experimental results demonstrate significant performance improvements in legal dispute analysis, enabling accurate legal application analysis for complex cases while exhibiting nuanced understanding of judicial decision-making logic, providing a novel technical approach for implementing intelligent legal assistance systems.","Стрімкий розвиток штучного інтелекту позиціонує великі мовні моделі як фундаментальні компоненти інтелектуальних правових систем. Однак ці моделі стикаються зі значними обмеженнями в аналізі правових спорів, включаючи недостатнє представлення правових знань, обмежене розуміння концепцій та недоліки аргументації. У цьому дослідженні пропонується вдосконалений фреймворк, що поєднує оперативну інженерію з багатовимірними графами знань. Система запроваджує триступеневу ієрархічну структуру підказок, що включає визначення завдання, базу знань і керівництво для міркувань, доповнене шаблонами міркувань, специфічними для юриспруденції, і механізмами динамічної оптимізації. Побудовано тришарову архітектуру графа знань з онтологією правової класифікації, рівнями представлення та екземплярів. Чотири взаємодоповнюючі методи забезпечують точний пошук правових понять: пряма відповідність коду правової норми, схожість семантичного вектора для конкретного домену, міркування на основі онтології та спеціалізована лексична сегментація. Ці компоненти інтегруються з технологією веб-пошуку, щоб створити базу знань для прийняття правових рішень. Експериментальні результати демонструють значне підвищення ефективності аналізу правових спорів, що дозволяє проводити точний аналіз застосування законодавства у складних справах, демонструючи при цьому тонке розуміння логіки прийняття судових рішень, забезпечуючи новий технічний підхід для впровадження інтелектуальних систем правової допомоги.",168,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07893,https://arxiv.org/pdf/2507.07893.pdf,true
2507.07787,Measuring AI Alignment with Human Flourishing,"Elizabeth Hilliard, Akshaya Jagadeesh, Alex Cook, Steele Billings, Nicholas Skytland, Alicia Llewellyn, Jackson Paull, Nathan Paull, Nolan Kurylo, Keatra Nesbitt, Robert Gruenewald, Anthony Jantzi, Omar Chavez","This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel evaluation framework that assesses AI alignment with human flourishing across seven dimensions: Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability, and Faith and Spirituality. Unlike traditional benchmarks that focus on technical capabilities or harm prevention, the FAI Benchmark measures AI performance on how effectively models contribute to the flourishing of a person across these dimensions. The benchmark evaluates how effectively LLM AI systems align with current research models of holistic human well-being through a comprehensive methodology that incorporates 1,229 objective and subjective questions. Using specialized judge Large Language Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs geometric mean scoring to ensure balanced performance across all flourishing dimensions. Initial testing of 28 leading language models reveals that while some models approach holistic alignment (with the highest-scoring models achieving 72/100), none are acceptably aligned across all dimensions, particularly in Faith and Spirituality, Character and Virtue, and Meaning and Purpose. This research establishes a framework for developing AI systems that actively support human flourishing rather than merely avoiding harm, offering significant implications for AI development, ethics, and evaluation.","У цьому документі представлено Індикатор процвітання штучного інтелекту (ІПШІ) - нову систему оцінювання, яка оцінює відповідність штучного інтелекту людському процвітанню за сімома вимірами: Характер і чесноти, тісні соціальні зв'язки, щастя і задоволеність життям, сенс і мета, психічне і фізичне здоров'я, фінансова і матеріальна стабільність, віра і духовність. На відміну від традиційних тестів, які зосереджені на технічних можливостях або запобіганні шкоді, тест FAI вимірює ефективність ШІ за тим, наскільки ефективно моделі сприяють процвітанню людини в усіх цих вимірах. Тест оцінює, наскільки ефективно системи ШІ LLM узгоджуються з сучасними дослідницькими моделями цілісного благополуччя людини за допомогою комплексної методології, яка включає 1 229 об'єктивних і суб'єктивних запитань. Використовуючи спеціалізовані суддівські великі мовні моделі (LLM) і міжвимірну оцінку, FAI Benchmark застосовує середнє геометричне значення балів, щоб забезпечити збалансовану продуктивність за всіма вимірами процвітання. Початкове тестування 28 провідних мовних моделей показало, що хоча деякі моделі наближаються до цілісного вирівнювання (моделі з найвищим показником 72/100), жодна з них не є прийнятно вирівняною за всіма вимірами, особливо за такими, як ""Віра і духовність"", ""Характер і чесноти"", ""Значення і мета"". Це дослідження створює основу для розробки систем ШІ, які активно підтримують процвітання людини, а не просто уникають шкоди, пропонуючи значні наслідки для розвитку, етики та оцінки ШІ.",200,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07787,https://arxiv.org/pdf/2507.07787.pdf,true
2507.07155,Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics,"Xueqing Xu, Boris Bolliet, Adrian Dimitrov, Andrew Laverick, Francisco Villaescusa-Navarro, Licong Xu, Íñigo Zubeldia","We evaluate 9 Retrieval Augmented Generation (RAG) agent configurations on 105 Cosmology Question-Answer (QA) pairs that we built specifically for this RAG configurations are manually evaluated by a human expert, that is, a total of 945 generated answers were assessed. We find that currently the best RAG agent configuration is with OpenAI embedding and generative model, yielding 91.4\% accuracy. Using our human evaluation results we calibrate LLM-as-a-Judge (LLMaaJ) system which can be used as a robust proxy for human evaluation. These results allow us to systematically select the best RAG agent configuration for multi-agent system for autonomous scientific discovery in astrophysics (e.g., cmbagent presented in a companion paper) and provide us with an LLMaaJ system that can be scaled to thousands of cosmology QA pairs. We make our QA dataset, human evaluation results, RAG pipelines, and LLMaaJ system publicly available for further use by the astrophysics community.","Ми оцінюємо 9 конфігурацій агентів розширеного пошуку (Retrieval Augmented Generation, RAG) на 105 парах запитань-відповідей (QA) з космології, які ми створили спеціально для цього RAG-конфігурації оцінюються вручну людиною-експертом, тобто загалом було оцінено 945 згенерованих відповідей. Ми виявили, що наразі найкращою конфігурацією RAG-агентів є конфігурація з вбудовуванням OpenAI та генеративною моделлю, яка дає 91,4\% точності. Використовуючи результати людського оцінювання, ми відкалібрували систему LLM-as-a-Judge (LLMaaJ), яка може бути використана як надійний проксі для людського оцінювання. Ці результати дозволяють нам систематично вибирати найкращу конфігурацію RAG-агентів для мультиагентної системи для автономних наукових відкриттів в астрофізиці (наприклад, cmbagent, представленої в супровідній статті) і надають нам систему LLMaaJ, яка може бути масштабована до тисяч космологічних пар QA. Ми робимо наш набір даних QA, результати людського оцінювання, конвеєри RAG та систему LLMaaJ загальнодоступними для подальшого використання астрофізичною спільнотою.",147,Instrumentation and Methods for Astrophysics (astro-ph.IM),https://arxiv.org/abs/2507.07155,https://arxiv.org/pdf/2507.07155.pdf,true
2507.07818,MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving,"Lu Xu, Jiaqian Yu, Xiongfeng Peng, Yiwei Chen, Weiming Li, Jaewook Yoo, Sunghyun Chunag, Dongwook Lee, Daehyun Ji, Chao Zhang","Recent studies show large language models (LLMs) and vision language models (VLMs) trained using web-scale data can empower end-to-end autonomous driving systems for a better generalization and interpretation. Specifically, by dynamically routing inputs to specialized subsets of parameters, the Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve substantial performance improvements while maintaining computational efficiency. However, general MoE models usually demands extensive training data and complex optimization. In this work, inspired by the learning process of human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human drivers' learning process and reasoning process, skill-by-skill and step-by-step. We propose a skill-oriented routing mechanism that begins with defining and annotating specific skills, enabling experts to identify the necessary driving competencies for various scenarios and reasoning tasks, thereby facilitating skill-by-skill learning. Further align the driving process to multi-step planning in human reasoning and end-to-end driving models, we build a hierarchical skill dataset and pretrain the router to encourage the model to think step-by-step. Unlike multi-round dialogs, MoSE integrates valuable auxiliary tasks (e.g.\ description, reasoning, planning) in one single forward process without introducing any extra computational cost. With less than 3B sparsely activated parameters, our model outperforms several 8B+ parameters on CODA AD corner case reasoning task. Compared to existing methods based on open-source models and data, our approach achieves state-of-the-art performance with significantly reduced activated model size (at least by $62.5\%$) with a single-turn conversation.","Нещодавні дослідження показують, що великі мовні моделі (БММ) і моделі мови зору (ММЗ), навчені на основі даних з Інтернету, можуть розширити можливості наскрізних автономних систем водіння для кращого узагальнення та інтерпретації. Зокрема, динамічно спрямовуючи вхідні дані на спеціалізовані підмножини параметрів, методика Mixture-of-Experts (MoE) дозволяє загальним LLM або VLM досягти значного покращення продуктивності, зберігаючи при цьому обчислювальну ефективність. Однак загальні моделі МДЕ зазвичай вимагають великих навчальних даних і складної оптимізації. У цій роботі, натхненні процесом навчання людей-водіїв, ми пропонуємо орієнтований на навички МН, названий MoSE, який імітує процес навчання і процес міркувань людей-водіїв, навичка за навичкою і крок за кроком. Ми пропонуємо механізм маршрутизації, орієнтований на навички, який починається з визначення та анотування конкретних навичок, що дозволяє експертам визначити необхідні водійські компетенції для різних сценаріїв і завдань на міркування, тим самим полегшуючи навчання навичкам за навичками. Для подальшого приведення процесу водіння у відповідність до багатокрокового планування в міркуваннях людини та наскрізних моделях водіння ми створюємо ієрархічний набір даних про навички та попередньо навчаємо маршрутизатор, щоб заохотити модель мислити поетапно. На відміну від багатораундових діалогів, MoSE інтегрує цінні допоміжні завдання (наприклад, опис, міркування, планування) в один єдиний прямий процес без додаткових обчислювальних витрат. Маючи менше 3B рідко активованих параметрів, наша модель перевершує декілька 8B+ параметрів у задачі міркувань CODA AD про кутовий випадок. У порівнянні з існуючими методами, що базуються на моделях і даних з відкритих джерел, наш підхід досягає найсучаснішої продуктивності при значно меншому розмірі активованої моделі (щонайменше на $62.5\%$) при однообертальному діалозі.",234,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07818,https://arxiv.org/pdf/2507.07818.pdf,true
2507.07820,"AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift","Eunsu Baek, Keondo Park, Jeonggil Ko, Min-hwan Oh, Taesik Gong, Hyung-Sin Kim","Current AI advances largely rely on scaling neural models and expanding training datasets to achieve generalization and robustness. Despite notable successes, this paradigm incurs significant environmental, economic, and ethical costs, limiting sustainability and equitable access. Inspired by biological sensory systems, where adaptation occurs dynamically at the input (e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive sensing as a necessary and foundational shift. Adaptive sensing proactively modulates sensor parameters (e.g., exposure, sensitivity, multimodal configurations) at the input level, significantly mitigating covariate shifts and improving efficiency. Empirical evidence from recent studies demonstrates that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass substantially larger models (e.g., OpenCLIP-H) trained with significantly more data and compute. We (i) outline a roadmap for broadly integrating adaptive sensing into real-world applications spanning humanoid, healthcare, autonomous systems, agriculture, and environmental monitoring, (ii) critically assess technical and ethical integration challenges, and (iii) propose targeted research directions, such as standardized benchmarks, real-time adaptive algorithms, multimodal integration, and privacy-preserving methods. Collectively, these efforts aim to transition the AI community toward sustainable, robust, and equitable artificial intelligence systems.","Сучасні досягнення в галузі штучного інтелекту значною мірою покладаються на масштабування нейронних моделей і розширення наборів навчальних даних для досягнення узагальнення та надійності. Незважаючи на помітні успіхи, ця парадигма несе значні екологічні, економічні та етичні витрати, обмежуючи стійкість і справедливий доступ. Натхненні біологічними сенсорними системами, де адаптація відбувається динамічно на вході (наприклад, регулювання розміру зіниці, перефокусування зору), ми виступаємо за адаптивне зондування як необхідну і фундаментальну зміну. Адаптивне зондування проактивно модулює параметри датчика (наприклад, експозицію, чутливість, мультимодальні конфігурації) на рівні входу, значно зменшуючи коваріативні зсуви і підвищуючи ефективність. Емпіричні дані останніх досліджень демонструють, що адаптивне зондування дозволяє невеликим моделям (наприклад, EfficientNet-B0) перевершити значно більші моделі (наприклад, OpenCLIP-H), навчені на значно більшій кількості даних і обчислень. Ми (i) окреслили дорожню карту для широкої інтеграції адаптивного зондування в реальні додатки, що охоплюють гуманоїдів, охорону здоров'я, автономні системи, сільське господарство і моніторинг навколишнього середовища, (ii) критично оцінили технічні та етичні проблеми інтеграції, і (iii) запропонували цільові напрямки досліджень, такі як стандартизовані бенчмарки, адаптивні алгоритми в реальному часі, мультимодальна інтеграція і методи збереження конфіденційності. Разом ці зусилля спрямовані на перехід спільноти ШІ до стійких, надійних і справедливих систем штучного інтелекту.",178,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07820,https://arxiv.org/pdf/2507.07820.pdf,true
2507.07857,Searching for actual causes: Approximate algorithms with adjustable precision,"Samuel Reyd, Ada Diaconescu, Jean-Louis Dessalles","Causality has gained popularity in recent years. It has helped improve the performance, reliability, and interpretability of machine learning models. However, recent literature on explainable artificial intelligence (XAI) has faced criticism. The classical XAI and causality literature focuses on understanding which factors contribute to which consequences. While such knowledge is valuable for researchers and engineers, it is not what non-expert users expect as explanations. Instead, these users often await facts that cause the target consequences, i.e., actual causes. Formalizing this notion is still an open problem. Additionally, identifying actual causes is reportedly an NP-complete problem, and there are too few practical solutions to approximate formal definitions. We propose a set of algorithms to identify actual causes with a polynomial complexity and an adjustable level of precision and exhaustiveness. Our experiments indicate that the algorithms (1) identify causes for different categories of systems that are not handled by existing approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be adjusted to gain more precision and exhaustiveness with more computation time.","Останніми роками причинно-наслідкові зв'язки набули популярності. Вона допомогла покращити продуктивність, надійність та інтерпретованість моделей машинного навчання. Однак нещодавня література про пояснюваний штучний інтелект (XAI) зіткнулася з критикою. Класична література з пояснюваного штучного інтелекту та причинно-наслідкових зв'язків зосереджується на розумінні того, які фактори впливають на ті чи інші наслідки. Хоча такі знання є цінними для дослідників та інженерів, це не те, що очікують від них користувачі, які не є експертами. Натомість ці користувачі часто очікують на факти, які спричиняють цільові наслідки, тобто на справжні причини. Формалізація цього поняття все ще залишається відкритою проблемою. Крім того, ідентифікація фактичних причин є NP-повною проблемою, і існує занадто мало практичних рішень для наближення до формальних визначень. Ми пропонуємо набір алгоритмів для визначення фактичних причин з поліноміальною складністю і регульованим рівнем точності та вичерпності. Наші експерименти показують, що алгоритми (1) ідентифікують причини для різних категорій систем, які не обробляються існуючими підходами (наприклад, небулеві, чорні ящики та стохастичні системи), (2) можуть бути налаштовані для отримання більшої точності та вичерпності з більшим часом обчислень.",169,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07857,https://arxiv.org/pdf/2507.07857.pdf,true
2507.07318,SonicMotion: Dynamic Spatial Audio Soundscapes with Latent Diffusion Models,"Christian Templin, Yanda Zhu, Hao Wang","Spatial audio is an integral part of immersive entertainment, such as VR/AR, and has seen increasing popularity in cinema and music as well. The most common format of spatial audio is described as first-order Ambisonics (FOA). We seek to extend recent advancements in FOA generative AI models to enable the generation of 3D scenes with dynamic sound sources. Our proposed end-to-end model, SonicMotion, comes in two variations which vary in their user input and level of precision in sound source localization. In addition to our model, we also present a new dataset of simulated spatial audio-caption pairs. Evaluation of our models demonstrate that they are capable of matching the semantic alignment and audio quality of state of the art models while capturing the desired spatial attributes.","Просторове аудіо є невід'ємною частиною імерсивних розваг, таких як VR/AR, а також набуває все більшої популярності в кінематографі та музиці. Найпоширеніший формат просторового аудіо називається амбісонікою першого порядку (FOA). Ми прагнемо розширити останні досягнення в генеративних моделях ШІ, що генерують FOA, щоб уможливити генерацію 3D-сцен з динамічними джерелами звуку. Запропонована нами наскрізна модель SonicMotion існує у двох варіаціях, які відрізняються за кількістю введених користувачем даних та рівнем точності локалізації джерела звуку. На додаток до нашої моделі, ми також представляємо новий набір даних зі змодельованими просторовими парами звуку та титрів. Оцінка наших моделей демонструє, що вони здатні відповідати за семантичним вирівнюванням та якістю звуку найсучаснішим моделям, одночасно фіксуючи бажані просторові атрибути.",126,Sound (cs.SD),https://arxiv.org/abs/2507.07318,https://arxiv.org/pdf/2507.07318.pdf,true
2507.07931,Meek Models Shall Inherit the Earth,"Hans Gundlach, Jayson Lynch, Neil Thompson","The past decade has seen incredible scaling of AI systems by a few companies, leading to inequality in AI model performance. This paper argues that, contrary to prevailing intuition, the diminishing returns to compute scaling will lead to a convergence of AI model capabilities. In other words, meek models (those with limited computation budget) shall inherit the earth, approaching the performance level of the best models overall. We develop a model illustrating that under a fixed-distribution next-token objective, the marginal capability returns to raw compute shrink substantially. Given current scaling practices, we argue that these diminishing returns are strong enough that even companies that can scale their models exponentially faster than other organizations will eventually have little advantage in capabilities. As part of our argument, we give several reasons that proxies like training loss differences capture important capability measures using evidence from benchmark data and theoretical performance models. In addition, we analyze empirical data on the capability difference of AI models over time. Finally, in light of the increasing ability of meek models, we argue that AI strategy and policy require reexamination, and we outline the areas this shift will affect.","За останнє десятиліття кілька компаній неймовірно масштабували системи штучного інтелекту, що призвело до нерівності в продуктивності моделей штучного інтелекту. У цій статті стверджується, що, всупереч поширеній інтуїції, зменшення віддачі від масштабування обчислень призведе до конвергенції можливостей ШІ-моделей. Іншими словами, покірні моделі (моделі з обмеженим обчислювальним бюджетом) успадкують землю, наблизившись до рівня продуктивності найкращих моделей в цілому. Ми розробили модель, яка ілюструє, що при фіксованому розподілі наступної мети гранична віддача від сирих обчислень суттєво зменшується. Враховуючи сучасні практики масштабування, ми стверджуємо, що ця падаюча віддача є достатньо сильною, щоб навіть компанії, які можуть масштабувати свої моделі експоненціально швидше, ніж інші організації, врешті-решт не мали значних переваг у можливостях. Як частину нашого аргументу ми наводимо кілька причин, чому такі проксі-показники, як різниця у втратах на навчання, відображають важливі показники спроможностей, використовуючи докази з порівняльних даних і теоретичних моделей продуктивності. Крім того, ми аналізуємо емпіричні дані про різницю в можливостях моделей ШІ з плином часу. Нарешті, у світлі зростаючих можливостей покірних моделей ми стверджуємо, що стратегія і політика ШІ потребують перегляду, і окреслюємо сфери, на які вплине цей зсув.",191,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07931,https://arxiv.org/pdf/2507.07931.pdf,true
2507.07935,Working with AI: Measuring the Occupational Implications of Generative AI,"Kiran Tomlinson, Sonia Jaffe, Will Wang, Scott Counts, Siddharth Suri","Given the rapid adoption of generative AI and its potential to impact a wide range of tasks, understanding the effects of AI on the economy is one of society's most important questions. In this work, we take a step toward that goal by analyzing the work activities people do with AI, how successfully and broadly those activities are done, and combine that with data on what occupations do those activities. We analyze a dataset of 200k anonymized and privacy-scrubbed conversations between users and Microsoft Bing Copilot, a publicly available generative AI system. We find the most common work activities people seek AI assistance for involve gathering information and writing, while the most common activities that AI itself is performing are providing information and assistance, writing, teaching, and advising. Combining these activity classifications with measurements of task success and scope of impact, we compute an AI applicability score for each occupation. We find the highest AI applicability scores for knowledge work occupation groups such as computer and mathematical, and office and administrative support, as well as occupations such as sales whose work activities involve providing and communicating information. Additionally, we characterize the types of work activities performed most successfully, how wage and education correlate with AI applicability, and how real-world usage compares to predictions of occupational AI impact.","Враховуючи швидке впровадження генеративного ШІ та його потенціал для вирішення широкого кола завдань, розуміння впливу ШІ на економіку є одним із найважливіших питань, що стоять перед суспільством. У цій роботі ми робимо крок до цієї мети, аналізуючи роботу, яку люди виконують за допомогою штучного інтелекту, наскільки успішно і широко вони її виконують, і поєднуємо це з даними про те, які професії виконують цю роботу. Ми проаналізували 200 тисяч анонімних і очищених від конфіденційності розмов між користувачами та Microsoft Bing Copilot, загальнодоступною генеративною системою штучного інтелекту. Ми виявили, що найпоширеніші види діяльності, для яких люди звертаються за допомогою до ШІ, - це збір інформації та написання текстів, тоді як найпоширеніші види діяльності, які виконує сам ШІ, - це надання інформації та допомоги, написання текстів, навчання та консультування. Поєднуючи ці класифікації видів діяльності з показниками успішності виконання завдань і масштабу впливу, ми обчислюємо показник застосовності ШІ для кожної професії. Ми виявили, що найвищі бали застосовності ШІ мають професії, пов'язані з роботою зі знаннями, такі як комп'ютерна та математична, офісна та адміністративна підтримка, а також професії, пов'язані з продажами, які передбачають надання та передачу інформації. Крім того, ми охарактеризували типи трудової діяльності, які виконуються найуспішніше, як заробітна плата та освіта співвідносяться із застосуванням ШІ, а також як реальне використання ШІ порівнюється з прогнозами щодо його впливу на професійну сферу.",217,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.07935,https://arxiv.org/pdf/2507.07935.pdf,true
2506.13201,A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping,"Wenfeng Jia, Bin Liang, Yuxi Liu, Muhammad Arif Khan, Lihong Zheng","Flooding remains a major global challenge, worsened by climate change and urbanization, demanding advanced solutions for effective disaster management. While traditional 2D flood mapping techniques provide limited insights, 3D flood mapping, powered by deep learning (DL), offers enhanced capabilities by integrating flood extent and depth. This paper presents a comprehensive survey of deep learning-based 3D flood mapping, emphasizing its advancements over 2D maps by integrating flood extent and depth for effective disaster management and urban planning. The survey categorizes deep learning techniques into task decomposition and end-to-end approaches, applicable to both static and dynamic flood features. We compare key DL architectures, highlighting their respective roles in enhancing prediction accuracy and computational efficiency. Additionally, this work explores diverse data sources such as digital elevation models, satellite imagery, rainfall, and simulated data, outlining their roles in 3D flood mapping. The applications reviewed range from real-time flood prediction to long-term urban planning and risk assessment. However, significant challenges persist, including data scarcity, model interpretability, and integration with traditional hydrodynamic models. This survey concludes by suggesting future directions to address these limitations, focusing on enhanced datasets, improved models, and policy implications for flood management. This survey aims to guide researchers and practitioners in leveraging DL techniques for more robust and reliable 3D flood mapping, fostering improved flood management strategies.","Повені залишаються серйозною глобальною проблемою, яка погіршується зміною клімату та урбанізацією і вимагає передових рішень для ефективного управління стихійними лихами. У той час як традиційні 2D-методи картографування повеней дають обмежену інформацію, 3D-картографування повеней на основі глибокого навчання (DL) пропонує розширені можливості завдяки інтеграції масштабу і глибини повені. У цій статті представлено всебічний огляд 3D-картування повеней на основі глибокого навчання, в якому підкреслюються його переваги над 2D-картами завдяки інтеграції масштабів і глибини повені для ефективного управління катастрофами та міського планування. В огляді методи глибокого навчання поділяються на декомпозицію завдань і наскрізні підходи, що застосовуються як до статичних, так і до динамічних характеристик повеней. Ми порівнюємо ключові архітектури DL, висвітлюючи їхню роль у підвищенні точності прогнозування та ефективності обчислень. Крім того, в цій роботі досліджуються різні джерела даних, такі як цифрові моделі рельєфу, супутникові знімки, дані про кількість опадів та імітаційні дані, і окреслюється їхня роль у тривимірному картографуванні повеней. Розглянуті програми варіюються від прогнозування повеней у реальному часі до довгострокового міського планування та оцінки ризиків. Однак залишаються значні проблеми, зокрема брак даних, інтерпретованість моделей та інтеграція з традиційними гідродинамічними моделями. У цьому огляді пропонуються майбутні напрямки подолання цих обмежень з акцентом на розширенні наборів даних, вдосконаленні моделей і політичних наслідках для управління повенями. Цей огляд має на меті допомогти дослідникам і практикам у використанні методів ДЗ для більш надійного і достовірного тривимірного картографування повеней, що сприятиме вдосконаленню стратегій управління повенями.",215,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2506.13201,https://arxiv.org/pdf/2506.13201.pdf,true
2506.21142,Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks,"Deepak Kumar Panda, Weisi Guo","The growing integration of UAVs into civilian airspace underscores the need for resilient and intelligent intrusion detection systems (IDS), as traditional anomaly detection methods often fail to identify novel threats. A common approach treats unfamiliar attacks as out-of-distribution (OOD) samples; however, this leaves systems vulnerable when mitigation is inadequate. Moreover, conventional OOD detectors struggle to distinguish stealthy adversarial attacks from genuine OOD events. This paper introduces a conditional generative adversarial network (cGAN)-based framework for crafting stealthy adversarial attacks that evade IDS mechanisms. We first design a robust multi-class IDS classifier trained on benign UAV telemetry and known cyber-attacks, including Denial of Service (DoS), false data injection (FDI), man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN perturbs known attacks to generate adversarial samples that misclassify as benign while retaining statistical resemblance to OOD distributions. These adversarial samples are iteratively refined to achieve high stealth and success rates. To detect such perturbations, we implement a conditional variational autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based regret scores significantly outperform traditional Mahalanobis distance-based detectors in identifying stealthy adversarial threats. Our findings emphasize the importance of advanced probabilistic modeling to strengthen IDS capabilities against adaptive, generative-model-based cyber intrusions.","Зростаюча інтеграція БПЛА в цивільний повітряний простір підкреслює потребу в стійких та інтелектуальних системах виявлення вторгнень (IDS), оскільки традиційні методи виявлення аномалій часто не здатні ідентифікувати нові загрози. Загальноприйнятий підхід розглядає незнайомі атаки як зразки позарозповсюдження (OOD); однак це робить системи вразливими, якщо не вживати належних заходів для їх усунення. Крім того, звичайні детектори OOD намагаються відрізнити приховані ворожі атаки від справжніх подій OOD. У цій статті представлено фреймворк на основі умовної генеративної змагальної мережі (cGAN) для створення прихованих ворожих атак, які оминають механізми IDS. Спочатку ми розробили надійний багатокласовий класифікатор IDS-атак, навчений на доброякісній телеметрії БПЛА та відомих кібератаках, включаючи відмову в обслуговуванні (DoS), введення неправдивих даних (FDI), атаки ""людина посередині"" (MiTM) та атаки з повторним відтворенням. Використовуючи цей класифікатор, наш cGAN спотворює відомі атаки, щоб генерувати ворожі зразки, які помилково класифікуються як доброякісні, зберігаючи при цьому статистичну схожість з розподілами OOD. Ці зразки ітеративно вдосконалюються, щоб досягти високих показників скритності та успішності. Для виявлення таких збурень ми застосовуємо умовний варіаційний автокодер (CVAE), який використовує від'ємну лог-правдоподібність, щоб відокремити ворожі вхідні дані від автентичних зразків OOD. Порівняльна оцінка показує, що оцінка жалю на основі CVAE значно перевершує традиційні детектори Махаланобіса на основі відстані у виявленні прихованих ворожих загроз. Наші висновки підкреслюють важливість передового імовірнісного моделювання для посилення можливостей IDS проти адаптивних кібервторгнень, заснованих на генеративних моделях.",206,Machine Learning (cs.LG),https://arxiv.org/abs/2506.21142,https://arxiv.org/pdf/2506.21142.pdf,true
2507.07108,Multi-level Mixture of Experts for Multimodal Entity Linking,"Zhiwei Hu, Víctor Gutiérrez-Basulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan","Multimodal Entity Linking (MEL) aims to link ambiguous mentions within multimodal contexts to associated entities in a multimodal knowledge base. Existing approaches to MEL introduce multimodal interaction and fusion mechanisms to bridge the modality gap and enable multi-grained semantic matching. However, they do not address two important problems: (i) mention ambiguity, i.e., the lack of semantic content caused by the brevity and omission of key information in the mention's textual context; (ii) dynamic selection of modal content, i.e., to dynamically distinguish the importance of different parts of modal information. To mitigate these issues, we propose a Multi-level Mixture of Experts (MMoE) model for MEL. MMoE has four components: (i) the description-aware mention enhancement module leverages large language models to identify the WikiData descriptions that best match a mention, considering the mention's textual context; (ii) the multimodal feature extraction module adopts multimodal feature encoders to obtain textual and visual embeddings for both mentions and entities; (iii)-(iv) the intra-level mixture of experts and inter-level mixture of experts modules apply a switch mixture of experts mechanism to dynamically and adaptively select features from relevant regions of information. Extensive experiments demonstrate the outstanding performance of MMoE compared to the state-of-the-art. MMoE's code is available at: .","Мультимодальне зв'язування об'єктів (MEL) має на меті зв'язати неоднозначні згадки в мультимодальних контекстах з відповідними об'єктами в мультимодальній базі знань. Існуючі підходи до MEL запроваджують механізми мультимодальної взаємодії та злиття для подолання розриву між модальностями та уможливлюють багатогранне семантичне співставлення. Однак вони не вирішують двох важливих проблем: (i) неоднозначності згадки, тобто браку семантичного змісту, спричиненого стислістю та відсутністю ключової інформації в текстовому контексті згадки; (ii) динамічного відбору модального змісту, тобто динамічного розрізнення важливості різних частин модальної інформації. Для пом'якшення цих проблем ми пропонуємо модель багаторівневого змішання експертів (MMoE) для MEL. MMoE складається з чотирьох компонентів: (i) модуль покращення згадок з урахуванням описів використовує великі мовні моделі для визначення описів Вікіданих, які найкраще відповідають згадці, враховуючи текстовий контекст згадки; (ii) модуль вилучення мультимодальних ознак використовує мультимодальні кодувальники ознак для отримання текстових і візуальних вбудовувань як для згадок, так і для сутностей; (iii)-(iv) модулі внутрішньорівневої суміші експертів і міжрівневої суміші експертів застосовують механізм перемикання суміші експертів для динамічного й адаптивного вибору ознак з релевантних ділянок інформації. Широкі експерименти демонструють видатну продуктивність MMoE порівняно з найсучаснішими методами. Код MMoE доступний за адресою: .",202,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07108,https://arxiv.org/pdf/2507.07108.pdf,true
2507.07116,Analysing semantic data storage in Distributed Ledger Technologies for Data Spaces,"Juan Cano-Benito, Andrea Cimmino, Sven Hertling, Heiko Paulheim, Raúl García-Castro","Data spaces are emerging as decentralised infrastructures that enable sovereign, secure, and trustworthy data exchange among multiple participants. To achieve semantic interoperability within these environments, the use of semantic web technologies and knowledge graphs has been proposed. Although distributed ledger technologies (DLT) fit as the underlying infrastructure for data spaces, there remains a significant gap in terms of the efficient storage of semantic data on these platforms. This paper presents a systematic evaluation of semantic data storage across different types of DLT (public, private, and hybrid), using a real-world knowledge graph as an experimental basis. The study compares performance, storage efficiency, resource consumption, and the capabilities to update and query semantic data. The results show that private DLTs are the most efficient for storing and managing semantic content, while hybrid DLTs offer a balanced trade-off between public auditability and operational efficiency. This research leads to a discussion on the selection of the most appropriate DLT infrastructure based on the data sovereignty requirements of decentralised data ecosystems.","Простори даних розвиваються як децентралізовані інфраструктури, що забезпечують суверенний, безпечний і надійний обмін даними між багатьма учасниками. Для досягнення семантичної інтероперабельності в цих середовищах було запропоновано використання технологій семантичного вебу і графів знань. Хоча технології розподілених реєстрів (DLT) підходять як базова інфраструктура для просторів даних, залишається значна прогалина з точки зору ефективного зберігання семантичних даних на цих платформах. У цій статті представлено систематичну оцінку зберігання семантичних даних у різних типах DLT (публічних, приватних та гібридних), використовуючи реальний граф знань як експериментальну основу. У дослідженні порівнюються продуктивність, ефективність зберігання, споживання ресурсів, а також можливості оновлення та запитів до семантичних даних. Результати показують, що приватні DLT є найбільш ефективними для зберігання та управління семантичним контентом, тоді як гібридні DLT пропонують збалансований компроміс між публічною аудиторійністю та операційною ефективністю. Це дослідження спонукає до дискусії щодо вибору найбільш підходящої інфраструктури DLT на основі вимог суверенітету даних у децентралізованих екосистемах даних.",166,"Distributed, Parallel, and Cluster Computing (cs.DC)",https://arxiv.org/abs/2507.07116,https://arxiv.org/pdf/2507.07116.pdf,true
2507.07117,Collective Communication Profiling of Modern-day Machine Learning Workloads,"Jit Gupta, Andrew Li, Tarun Banka, Ariel Cohen, T. Sridhar, Raj Yavatkar","Machine Learning jobs, carried out on large number of distributed high performance systems, involve periodic communication using operations like AllReduce, AllGather, and Broadcast. These operations may create high bandwidth and bursty traffic patterns, leading to network congestion and packet loss, thus impacting the performance of these jobs. Hence it is imperative to analyze these patterns, which can be helpful in provisioning network resources depending on the type of machine learning workloads. In this poster we carry out extensive analysis of the collective communication behavior seen in a wide variety of models (ex. DeepSeek, GPT, Llama, etc.) To achieve this we instrument Nvidia Collective Communication Library logging functionality for richer context about the collectives and workloads. We adjust configuration parameters that influence collective communication behavior, such as parallelism, number of nodes, and model type. This overview presents and discusses some of the results on the collective communication behavior for the open source DeepSeek V3 inferencing model, which includes operation type and count, transfer sizes per operation, and request size distribution. Our analysis shows that it makes sense to rethink current collective communication frameworks and network topologies so as to accommodate the effect of network anomalies on the mentioned workloads.","Завдання машинного навчання, що виконуються на великій кількості розподілених високопродуктивних систем, передбачають періодичний обмін даними з використанням таких операцій, як AllReduce, AllGather і Broadcast. Ці операції можуть створювати високу пропускну здатність і пакети трафіку, що призводить до перевантаження мережі і втрати пакетів, тим самим впливаючи на продуктивність цих завдань. Тому вкрай важливо аналізувати ці патерни, що може бути корисним при розподілі мережевих ресурсів в залежності від типу робочих навантажень машинного навчання. У цій доповіді ми проводимо детальний аналіз поведінки колективної комунікації в різних моделях (наприклад, DeepSeek, GPT, Llama та ін.). Для цього ми використовуємо функціонал логування бібліотеки колективної комунікації Nvidia для отримання більш повної інформації про колективи та робочі навантаження. Ми налаштовуємо параметри конфігурації, які впливають на поведінку колективної взаємодії, такі як паралелізм, кількість вузлів та тип моделі. У цьому огляді представлено та обговорено деякі результати щодо поведінки колективної взаємодії для моделі виведення з відкритим вихідним кодом DeepSeek V3, яка включає тип та кількість операцій, розміри передачі даних за операцію та розподіл розмірів запитів. Наш аналіз показує, що є сенс переосмислити поточні фреймворки колективної комунікації та мережеві топології, щоб врахувати вплив мережевих аномалій на згадані робочі навантаження.",198,"Distributed, Parallel, and Cluster Computing (cs.DC)",https://arxiv.org/abs/2507.07117,https://arxiv.org/pdf/2507.07117.pdf,true
2507.07120,Helix Parallelism: Rethinking Sharding Strategies for Interactive Multi-Million-Token LLM Decoding,"Nidhi Bhatia, Ankit More, Ritika Borkar, Tiyasa Mitra, Ramon Matas, Ritchie Zhao, Maximilian Golub, Dheevatsa Mudigere, Brian Pharris, Bita Darvish Rouhani","As LLMs scale to multi-million-token KV histories, real-time autoregressive decoding under tight Token-to-Token Latency (TTL) constraints faces growing pressure. Two core bottlenecks dominate: accessing Feed-Forward Network (FFN) weights and reading long KV caches. While Tensor Parallelism (TP) helps mitigate the cost of FFN weight reads, it does not scale well for attention. When TP width exceeds the number of KV heads, it leads to inefficient KV duplication, limits parallelism, and constrains batch size. Simultaneously, DRAM reads for long KV histories scale linearly with batch size, further capping efficiency. We introduce Helix Parallelism, a hybrid execution strategy that applies KV parallelism during attention to shard KV caches across GPUs, then reuses the same GPUs for TP in dense LLMs or TPxExpert Parallel (EP) in MoEs during FFN computation. To preserve exact attention behavior, Helix includes a lightweight communication step. To minimize the exposed communication cost, we introduce Helix HOP-B. Helix HOP-B effectively minimizes communication overhead through batchwise overlap, preserving low TTL while improving GPU efficiency. Compared to conventional parallelism approaches, Helix reduces TTL by up to 1.5x at fixed batch sizes and supports up to 32x larger batches under the same latency budget for DeepSeek-R1, pushing forward the throughput-latency Pareto on Blackwell and making real-time inference with ultra-long-sequence practical.","У міру того, як LLM масштабуються до багатомільйонних історій KV, авторегресійне декодування в реальному часі в умовах жорстких обмежень затримки між маркерами (TTL) стикається зі зростаючим тиском. Домінують два основні вузькі місця: доступ до вагових коефіцієнтів прямої мережі (FFN) і читання довгих кешів KV. Хоча тензорний паралелізм (Tensor Parallelism, TP) допомагає зменшити вартість зчитування ваг FFN, він не дуже добре масштабується для уваги. Коли ширина TP перевищує кількість головок KV, це призводить до неефективного дублювання KV, обмежує паралелізм і обмежує розмір партії. У той же час, читання DRAM для довгих історій KV лінійно масштабується з розміром партії, що додатково підвищує ефективність обмеження. Ми представляємо Helix Parallelism, гібридну стратегію виконання, яка застосовує паралелізм KV під час уваги до осколкових кешів KV на різних графічних процесорах, а потім повторно використовує ті самі графічні процесори для TP у щільних LLM або TPxExpert Parallel (EP) в MoE під час обчислень FFN. Щоб зберегти точну поведінку уваги, Helix включає полегшений крок комунікації. Щоб мінімізувати відкриті комунікаційні витрати, ми представляємо Helix HOP-B. Helix HOP-B ефективно мінімізує накладні витрати на передачу даних завдяки пакетному перекриттю, зберігаючи низький TTL та підвищуючи ефективність роботи графічного процесора. У порівнянні з традиційними підходами паралелізму, Helix зменшує TTL до 1,5 разів при фіксованих розмірах пакетів і підтримує до 32 разів більші пакети при тому ж бюджеті затримок для DeepSeek-R1, просуваючи вперед співвідношення пропускної здатності і затримок Парето на Блеквелла і роблячи практичним висновок в реальному часі з наддовгими послідовностями.",208,"Distributed, Parallel, and Cluster Computing (cs.DC)",https://arxiv.org/abs/2507.07120,https://arxiv.org/pdf/2507.07120.pdf,true
2507.07393,KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos,"Jinseong Kim, Junghoon Song, Gyeongseon Baek, Byeongjoon Noh","We propose \textbf{KeyRe-ID}, a keypoint-guided video-based person re-identification framework consisting of global and local branches that leverage human keypoints for enhanced spatiotemporal representation learning. The global branch captures holistic identity semantics through Transformer-based temporal aggregation, while the local branch dynamically segments body regions based on keypoints to generate fine-grained, part-aware features. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate state-of-the-art performance, achieving 91.73\% mAP and 97.32\% Rank-1 accuracy on MARS, and 96.00\% Rank-1 and 100.0\% Rank-5 accuracy on iLIDS-VID. The code for this work will be publicly available on GitHub upon publication.","Ми пропонуємо \textbf{KeyRe-ID}, систему відео-ідентифікації людини на основі ключових точок, що складається з глобальної та локальної гілок, які використовують ключові точки людини для покращеного навчання просторово-часової репрезентації. Глобальна гілка фіксує цілісну семантику ідентичності за допомогою часової агрегації на основі трансформатора, в той час як локальна гілка динамічно сегментує ділянки тіла на основі ключових точок, щоб генерувати дрібнозернисті, частково усвідомлювані ознаки. Широкі експерименти на бенчмарках MARS та iLIDS-VID демонструють найсучаснішу продуктивність, досягаючи 91,73\% точності mAP та 97,32\% точності Rank-1 на MARS, та 96,00\% точності Rank-1 та 100,0\% точності Rank-5 на iLIDS-VID. Код цієї роботи буде у відкритому доступі на GitHub після публікації.",92,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07393,https://arxiv.org/pdf/2507.07393.pdf,true
2507.07126,DpDNet: An Dual-Prompt-Driven Network for Universal PET-CT Segmentation,"Xinglong Liang, Jiaju Huang, Luyi Han, Tianyu Zhang, Xin Wang, Yuan Gao, Chunyao Lu, Lishan Cai, Tao Tan, Ritse Mann","PET-CT lesion segmentation is challenging due to noise sensitivity, small and variable lesion morphology, and interference from physiological high-metabolic signals. Current mainstream approaches follow the practice of one network solving the segmentation of multiple cancer lesions by treating all cancers as a single task. However, this overlooks the unique characteristics of different cancer types. Considering the specificity and similarity of different cancers in terms of metastatic patterns, organ preferences, and FDG uptake intensity, we propose DpDNet, a Dual-Prompt-Driven network that incorporates specific prompts to capture cancer-specific features and common prompts to retain shared knowledge. Additionally, to mitigate information forgetting caused by the early introduction of prompts, prompt-aware heads are employed after the decoder to adaptively handle multiple segmentation tasks. Experiments on a PET-CT dataset with four cancer types show that DpDNet outperforms state-of-the-art models. Finally, based on the segmentation results, we calculated MTV, TLG, and SUVmax for breast cancer survival analysis. The results suggest that DpDNet has the potential to serve as a valuable tool for personalized risk stratification, supporting clinicians in optimizing treatment strategies and improving outcomes. Code is available at .","Сегментація вогнищ ураження за допомогою ПЕТ-КТ є складним завданням через чутливість до шуму, малі розміри та варіабельну морфологію вогнищ ураження, а також перешкоди від фізіологічних сигналів з високим рівнем метаболізму. Сучасні основні підходи базуються на практиці, коли одна мережа вирішує сегментацію множинних ракових уражень, розглядаючи всі види раку як єдину задачу. Однак при цьому не враховуються унікальні характеристики різних типів раку. Враховуючи специфіку та схожість різних видів раку з точки зору метастазування, переваг органів та інтенсивності поглинання FDG, ми пропонуємо DpDNet - мережу з подвійними підказками, яка включає в себе специфічні підказки для фіксації особливостей раку та загальні підказки для збереження спільних знань. Крім того, щоб зменшити забування інформації, спричинене раннім введенням підказок, після розшифровувача використовуються головки, які знають підказки, щоб адаптивно обробляти численні завдання сегментації. Експерименти на наборі даних ПЕТ-КТ з чотирма типами раку показали, що DpDNet перевершує найсучасніші моделі. Нарешті, на основі результатів сегментації ми розрахували MTV, TLG і SUVmax для аналізу виживаності при раку молочної залози. Отримані результати свідчать про те, що DpDNet має потенціал слугувати цінним інструментом для персоналізованої стратифікації ризику, допомагаючи лікарям оптимізувати стратегії лікування та покращувати результати. Код доступний за адресою .",183,Image and Video Processing (eess.IV),https://arxiv.org/abs/2507.07126,https://arxiv.org/pdf/2507.07126.pdf,true
2507.07133,Generative Panoramic Image Stitching,"Mathieu Tuli, Kaveh Kamali, David B. Lindell","We introduce the task of generative panoramic image stitching, which aims to synthesize seamless panoramas that are faithful to the content of multiple reference images containing parallax effects and strong variations in lighting, camera capture settings, or style. In this challenging setting, traditional image stitching pipelines fail, producing outputs with ghosting and other artifacts. While recent generative models are capable of outpainting content consistent with multiple reference images, they fail when tasked with synthesizing large, coherent regions of a panorama. To address these limitations, we propose a method that fine-tunes a diffusion-based inpainting model to preserve a scene's content and layout based on multiple reference images. Once fine-tuned, the model outpaints a full panorama from a single reference image, producing a seamless and visually coherent result that faithfully integrates content from all reference images. Our approach significantly outperforms baselines for this task in terms of image quality and the consistency of image structure and scene layout when evaluated on captured datasets.","Ми представляємо задачу генеративного зшивання панорамних зображень, метою якої є синтез безшовних панорам, що відповідають вмісту декількох еталонних зображень, які містять ефекти паралакса та сильні варіації в освітленні, налаштуваннях зйомки або стилі. У таких складних умовах традиційні конвеєри зшивання зображень не справляються, створюючи на виході зображення з ореолами та іншими артефактами. Хоча сучасні генеративні моделі здатні зафарбовувати контент, що відповідає декільком еталонним зображенням, вони не справляються із завданням синтезу великих, когерентних областей панорами. Для подолання цих обмежень ми пропонуємо метод, який точно налаштовує модель зафарбовування на основі дифузії, щоб зберегти вміст і структуру сцени на основі декількох опорних зображень. Після точного налаштування модель зафарбовує повну панораму з одного еталонного зображення, створюючи безшовний і візуально цілісний результат, який точно інтегрує вміст усіх еталонних зображень. Наш підхід значно перевершує базові рішення для цієї задачі з точки зору якості зображення та узгодженості структури зображення і компонування сцени при оцінюванні на зібраних наборах даних.",161,Graphics (cs.GR),https://arxiv.org/abs/2507.07133,https://arxiv.org/pdf/2507.07133.pdf,true
2507.07147,Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation,"Sua Lee, Kyubum Shin, Jung Ho Park","Recent advances in pre-trained Vision Language Models (VLM) have shown promising potential for effectively adapting to downstream tasks through prompt learning, without the need for additional annotated paired datasets. To supplement the text information in VLM trained on correlations with vision data, new approaches leveraging Large Language Models (LLM) in prompts have been proposed, enhancing robustness to unseen and diverse data. Existing methods typically extract text-based responses (i.e., descriptions) from LLM to incorporate into prompts; however, this approach suffers from high variability and low reliability. In this work, we propose Description-free Multi-prompt Learning(DeMul), a novel method that eliminates the process of extracting descriptions and instead directly distills knowledge from LLM into prompts. By adopting a description-free approach, prompts can encapsulate richer semantics while still being represented as continuous vectors for optimization, thereby eliminating the need for discrete pre-defined templates. Additionally, in a multi-prompt setting, we empirically demonstrate the potential of prompt weighting in reflecting the importance of different prompts during training. Experimental results show that our approach achieves superior performance across 11 recognition datasets.","Нещодавні досягнення в області попередньо навчених моделей мови зору (VLM) показали багатообіцяючий потенціал для ефективної адаптації до подальших завдань за допомогою швидкого навчання без потреби в додаткових анотованих парних наборах даних. Для доповнення текстової інформації в VLM, навчених на кореляції з даними зору, були запропоновані нові підходи з використанням великих мовних моделей (LLM) у підказках, що підвищують стійкість до невидимих і різноманітних даних. Існуючі методи зазвичай витягують текстові відповіді (тобто описи) з LLM для включення в підказки; однак цей підхід страждає від високої варіабельності і низької надійності. У цій роботі ми пропонуємо мультипідказкове навчання без описів (DeMul), новий метод, який виключає процес вилучення описів і натомість безпосередньо витягує знання з LLM у підказки. Завдяки застосуванню підходу без описів, підказки можуть інкапсулювати багатшу семантику, в той же час будучи представленими у вигляді безперервних векторів для оптимізації, таким чином усуваючи потребу в дискретних заздалегідь визначених шаблонах. Крім того, у випадку з декількома підказками ми емпірично демонструємо потенціал зважування підказок для відображення важливості різних підказок під час навчання. Експериментальні результати показують, що наш підхід демонструє чудову продуктивність на 11 наборах даних розпізнавання.",174,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07147,https://arxiv.org/pdf/2507.07147.pdf,true
2507.07151,Robust Multimodal Large Language Models Against Modality Conflict,"Zongmeng Zhang, Wengang Zhou, Jie Zhao, Houqiang Li","Despite the impressive capabilities of multimodal large language models (MLLMs) in vision-language tasks, they are prone to hallucinations in real-world scenarios. This paper investigates the hallucination phenomenon in MLLMs from the perspective of modality conflict. Unlike existing works focusing on the conflicts between model responses and inputs, we study the inherent conflicts in inputs from different modalities that place MLLMs in a dilemma and directly lead to hallucinations. We formally define the modality conflict and construct a dataset named Multimodal Modality Conflict (MMMC) to simulate this phenomenon in vision-language tasks. Three methods based on prompt engineering, supervised fine-tuning, and reinforcement learning are proposed to alleviate the hallucination caused by modality conflict. Extensive experiments are conducted on the MMMC dataset to analyze the merits and demerits of these methods. Our results show that the reinforcement learning method achieves the best performance in mitigating the hallucination under modality conflict, while the supervised fine-tuning method shows promising and stable performance. Our work sheds light on the unnoticed modality conflict that leads to hallucinations and provides more insights into the robustness of MLLMs.","Незважаючи на вражаючі можливості мультимодальних великих мовних моделей (ММВМ) у задачах мови зору, вони схильні до галюцинацій у реальних сценаріях. У цій статті досліджується феномен галюцинацій у MLLM з точки зору конфлікту модальностей. На відміну від існуючих робіт, що зосереджуються на конфліктах між відповідями моделі та вхідними даними, ми вивчаємо внутрішні конфлікти у вхідних даних різних модальностей, які ставлять MLLM в дилему і безпосередньо призводять до галюцинацій. Ми формально визначаємо конфлікт модальностей і створюємо набір даних, названий Мультимодальний конфлікт модальностей (MMMC), для моделювання цього явища в завданнях на мові зору. Для зменшення галюцинацій, спричинених конфліктом модальностей, запропоновано три методи, що базуються на швидкому проектуванні, контрольованому налаштуванні та навчанні з підкріпленням. Для аналізу переваг і недоліків цих методів на наборі даних MMMC проведено широкі експерименти. Наші результати показують, що метод навчання з підкріпленням досягає найкращих результатів у зменшенні галюцинацій при конфлікті модальностей, в той час як метод контрольованого тонкого налаштування показує багатообіцяючу і стабільну роботу. Наша робота проливає світло на непомічений конфлікт модальностей, який призводить до галюцинацій, і дає більше розуміння надійності MLLMs.",179,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07151,https://arxiv.org/pdf/2507.07151.pdf,true
2507.07153,Aerial Maritime Vessel Detection and Identification,"Antonella Barisic Kulas, Frano Petric, Stjepan Bogdan","Autonomous maritime surveillance and target vessel identification in environments where Global Navigation Satellite Systems (GNSS) are not available is critical for a number of applications such as search and rescue and threat detection. When the target vessel is only described by visual cues and its last known position is not available, unmanned aerial vehicles (UAVs) must rely solely on on-board vision to scan a large search area under strict computational constraints. To address this challenge, we leverage the YOLOv8 object detection model to detect all vessels in the field of view. We then apply feature matching and hue histogram distance analysis to determine whether any detected vessel corresponds to the target. When found, we localize the target using simple geometric principles. We demonstrate the proposed method in real-world experiments during the MBZIRC2023 competition, integrated into a fully autonomous system with GNSS-denied navigation. We also evaluate the impact of perspective on detection accuracy and localization precision and compare it with the oracle approach.","Автономне морське спостереження та ідентифікація суден-мішеней в умовах, коли глобальні навігаційні супутникові системи (GNSS) недоступні, є критично важливими для низки застосувань, таких як пошук і порятунок та виявлення загроз. Коли цільове судно описується лише за візуальними ознаками, а його останнє відоме місцезнаходження недоступне, безпілотні літальні апарати (БПЛА) повинні покладатися виключно на бортовий зір для сканування великої зони пошуку в умовах суворих обчислювальних обмежень. Щоб вирішити цю проблему, ми використовуємо модель виявлення об'єктів YOLOv8 для виявлення всіх суден у полі зору. Потім ми застосовуємо зіставлення ознак і аналіз відстані за гістограмою відтінку, щоб визначити, чи відповідає виявлене судно цілі. У разі виявлення, ми локалізуємо ціль за допомогою простих геометричних принципів. Ми демонструємо запропонований метод у реальних експериментах під час змагань MBZIRC2023, інтегрованих у повністю автономну систему з навігацією без використання GNSS. Ми також оцінюємо вплив перспективи на точність виявлення та локалізації і порівнюємо його з підходом оракула.",162,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07153,https://arxiv.org/pdf/2507.07153.pdf,true
2507.07622,TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection,"Federico Del Pup, Riccardo Brun, Filippo Iotti, Edoardo Paccagnella, Mattia Pezzato, Sabrina Bertozzo, Andrea Zanola, Louis Fabrice Tshimanga, Henning Müller, Manfredo Atzori","Electroencephalography (EEG) is establishing itself as an important, low-cost, noninvasive diagnostic tool for the early detection of Parkinson's Disease (PD). In this context, EEG-based Deep Learning (DL) models have shown promising results due to their ability to discover highly nonlinear patterns within the signal. However, current state-of-the-art DL models suffer from poor generalizability caused by high inter-subject variability. This high variability underscores the need for enhancing model generalizability by developing new architectures better tailored to EEG data. This paper introduces TransformEEG, a hybrid Convolutional-Transformer designed for Parkinson's disease detection using EEG data. Unlike transformer models based on the EEGNet structure, TransformEEG incorporates a depthwise convolutional tokenizer. This tokenizer is specialized in generating tokens composed by channel-specific features, which enables more effective feature mixing within the self-attention layers of the transformer encoder. To evaluate the proposed model, four public datasets comprising 290 subjects (140 PD patients, 150 healthy controls) were harmonized and aggregated. A 10-outer, 10-inner Nested-Leave-N-Subjects-Out (N-LNSO) cross-validation was performed to provide an unbiased comparison against seven other consolidated EEG deep learning models. TransformEEG achieved the highest balanced accuracy's median (78.45%) as well as the lowest interquartile range (6.37%) across all the N-LNSO partitions. When combined with data augmentation and threshold correction, median accuracy increased to 80.10%, with an interquartile range of 5.74%. In conclusion, TransformEEG produces more consistent and less skewed results. It demonstrates a substantial reduction in variability and more reliable PD detection using EEG data compared to the other investigated models.","Електроенцефалографія (ЕЕГ) зарекомендувала себе як важливий, недорогий, неінвазивний діагностичний інструмент для раннього виявлення хвороби Паркінсона (ХП). У цьому контексті моделі глибокого навчання (DL) на основі ЕЕГ показали багатообіцяючі результати завдяки своїй здатності виявляти високонелінійні патерни в сигналі. Однак сучасні моделі глибинного навчання страждають від поганої узагальнюваності, спричиненої високою міжсуб'єктною варіабельністю. Ця висока варіабельність підкреслює необхідність покращення узагальнюваності моделей шляхом розробки нових архітектур, краще пристосованих до даних ЕЕГ. У цій статті представлено TransformEEG, гібридну згортково-трансформаторну модель, призначену для виявлення хвороби Паркінсона за даними ЕЕГ. На відміну від трансформаційних моделей, заснованих на структурі EEGNet, TransformEEG включає в себе глибинний згортковий токенізатор. Цей токенізатор спеціалізується на генеруванні токенів, складених із специфічних для каналу ознак, що забезпечує більш ефективне змішування ознак у шарах самоуваги трансформантного кодера. Для оцінки запропонованої моделі було гармонізовано та агреговано чотири загальнодоступні набори даних, що включають 290 суб'єктів (140 пацієнтів з РД, 150 здорових осіб). Для забезпечення неупередженого порівняння з сімома іншими консолідованими моделями глибокого навчання ЕЕГ була проведена перехресна перевірка з вкладеним залишенням N суб'єктів (N-LNSO), яка включала 10 зовнішніх і 10 внутрішніх суб'єктів. TransformEEG досягла найвищої медіани збалансованої точності (78,45%), а також найнижчого міжквартильного діапазону (6,37%) у всіх розділах N-LNSO. У поєднанні з доповненням даних і пороговою корекцією медіана точності зросла до 80,10%, а міжквартильний розкид склав 5,74%. Отже, TransformEEG дає більш узгоджені та менш викривлені результати. Вона демонструє суттєве зменшення варіабельності та більш надійне виявлення ФП за даними ЕЕГ порівняно з іншими досліджуваними моделями.",244,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07622,https://arxiv.org/pdf/2507.07622.pdf,true
2507.07186,"Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs","Itay Itzhak, Yonatan Belinkov, Gabriel Stanovsky","Large language models (LLMs) exhibit cognitive biases -- systematic tendencies of irrational decision-making, similar to those seen in humans. Prior work has found that these biases vary across models and can be amplified by instruction tuning. However, it remains unclear if these differences in biases stem from pretraining, finetuning, or even random noise due to training stochasticity. We propose a two-step causal experimental approach to disentangle these factors. First, we finetune models multiple times using different random seeds to study how training randomness affects over $30$ cognitive biases. Second, we introduce \emph{cross-tuning} -- swapping instruction datasets between models to isolate bias sources. This swap uses datasets that led to different bias patterns, directly testing whether biases are dataset-dependent. Our findings reveal that while training randomness introduces some variability, biases are mainly shaped by pretraining: models with the same pretrained backbone exhibit more similar bias patterns than those sharing only finetuning data. These insights suggest that understanding biases in finetuned models requires considering their pretraining origins beyond finetuning effects. This perspective can guide future efforts to develop principled strategies for evaluating and mitigating bias in LLMs.","Великі мовні моделі (ВММ) демонструють когнітивні упередження - систематичні тенденції до ірраціонального прийняття рішень, подібні до тих, що спостерігаються у людей. Попередні дослідження показали, що ці упередження варіюються в різних моделях і можуть бути посилені налаштуванням інструкцій. Однак залишається незрозумілим, чи є ці відмінності в упередженнях наслідком попереднього навчання, остаточного налаштування або навіть випадкового шуму, спричиненого стохастичністю навчання. Ми пропонуємо двоетапний причинно-наслідковий експериментальний підхід, щоб з'ясувати ці фактори. По-перше, ми доналаштовуємо моделі кілька разів, використовуючи різні випадкові насіння, щоб дослідити, як випадковість навчання впливає на когнітивні упередження понад $30$. По-друге, ми вводимо \emph{cross-tuning} - обмін наборами даних інструкцій між моделями, щоб ізолювати джерела похибок. Ця заміна використовує набори даних, які призвели до різних патернів упереджень, безпосередньо перевіряючи, чи залежать упередження від набору даних. Наші результати показують, що, хоча випадковість навчання вносить певну варіативність, упередження в основному формуються попереднім навчанням: моделі з однаковим попередньо навченим кістяком демонструють більш схожі патерни упереджень, ніж ті, що мають спільні дані для уточнення. Ці висновки свідчать про те, що для розуміння зсувів у доналаштованих моделях необхідно розглядати їхнє походження не лише з точки зору ефектів доналаштування, а й з точки зору попереднього навчання. Ця перспектива може спрямовувати майбутні зусилля на розробку принципових стратегій для оцінки та пом'якшення зсуву в LLMs.",185,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07186,https://arxiv.org/pdf/2507.07186.pdf,true
2507.07188,Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses,"Jens Rupprecht, Georg Ahnert, Markus Strohmaier","Large Language Models (LLMs) are increasingly used as proxies for human subjects in social science surveys, but their reliability and susceptibility to known response biases are poorly understood. This paper investigates the response robustness of LLMs in normative survey contexts -- we test nine diverse LLMs on questions from the World Values Survey (WVS), applying a comprehensive set of 11 perturbations to both question phrasing and answer option structure, resulting in over 167,000 simulated interviews. In doing so, we not only reveal LLMs' vulnerabilities to perturbations but also reveal that all tested models exhibit a consistent \textit{recency bias} varying in intensity, disproportionately favoring the last-presented answer option. While larger models are generally more robust, all models remain sensitive to semantic variations like paraphrasing and to combined perturbations. By applying a set of perturbations, we reveal that LLMs partially align with survey response biases identified in humans. This underscores the critical importance of prompt design and robustness testing when using LLMs to generate synthetic survey data.","Великі мовні моделі (ВММ) дедалі частіше використовуються як проксі для заміни респондентів у соціологічних дослідженнях, але їхня надійність та схильність до відомих упереджень у відповідях вивчені недостатньо. У цій статті ми досліджуємо стійкість відповідей LLM у контексті нормативних опитувань - ми тестуємо дев'ять різноманітних LLM на запитаннях Світового дослідження цінностей (WVS), застосовуючи комплексний набір з 11 збурень як до формулювань запитань, так і до структури варіантів відповідей, в результаті чого було проведено понад 167 000 змодельованих інтерв'ю. Таким чином, ми не лише виявили вразливість LLM до збурень, але й виявили, що всі протестовані моделі демонструють послідовне \textit{recency bias} різної інтенсивності, непропорційно надаючи перевагу останньому представленому варіанту відповіді. Хоча більші моделі, як правило, більш стійкі, всі моделі залишаються чутливими до семантичних варіацій, таких як перефразування, і до комбінованих збурень. Застосовуючи набір збурень, ми виявили, що LLM частково узгоджуються з упередженнями у відповідях на опитування, виявленими у людей. Це підкреслює критичну важливість швидкого проектування та тестування надійності при використанні LLM для створення синтетичних даних опитувань.",165,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07188,https://arxiv.org/pdf/2507.07188.pdf,true
2507.07192,Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching,"Huibo Xu, Runlong Yu, Likang Wu, Xianquan Wang, Qi Liu","Diffusion models, a type of generative model, have shown promise in time series forecasting. But they face limitations like rigid source distributions and limited sampling paths, which hinder their performance. Flow matching offers faster generation, higher-quality outputs, and greater flexibility, while also possessing the ability to utilize valuable information from the prediction errors of prior models, which were previously inaccessible yet critically important. To address these challenges and fully unlock the untapped potential of flow matching, we propose Conditional Guided Flow Matching (CGFM). CGFM extends flow matching by incorporating the outputs of an auxiliary model, enabling a previously unattainable capability in the field: learning from the errors of the auxiliary model. For time series forecasting tasks, it integrates historical data as conditions and guidance, constructs two-sided conditional probability paths, and uses a general affine path to expand the space of probability paths, ultimately leading to improved predictions. Extensive experiments show that CGFM consistently enhances and outperforms state-of-the-art models, highlighting its effectiveness in advancing forecasting methods.","Дифузійні моделі, різновид генеративних моделей, є перспективними для прогнозування часових рядів. Але вони стикаються з обмеженнями, такими як жорсткий розподіл джерел і обмежені шляхи вибірки, які перешкоджають їхній роботі. Узгодження з потоком пропонує швидшу генерацію, вищу якість результатів і більшу гнучкість, а також має можливість використовувати цінну інформацію з помилок прогнозування попередніх моделей, яка раніше була недоступною, але критично важливою. Для вирішення цих проблем і повного розкриття невикористаного потенціалу узгодження потоків ми пропонуємо метод умовного керованого узгодження потоків (CGFM). CGFM розширює можливості узгодження потоків за рахунок включення результатів допоміжної моделі, що дає змогу отримати раніше недосяжну в цій галузі можливість: вчитися на помилках допоміжної моделі. Для задач прогнозування часових рядів він інтегрує історичні дані як умови і вказівки, будує двосторонні умовні ймовірнісні траєкторії і використовує загальний афінний шлях для розширення простору ймовірнісних траєкторій, що в кінцевому підсумку призводить до поліпшення прогнозів. Широкі експерименти показують, що CGFM постійно вдосконалює і перевершує найсучасніші моделі, що підкреслює його ефективність у вдосконаленні методів прогнозування.",165,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07192,https://arxiv.org/pdf/2507.07192.pdf,true
2507.07197,Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning,"Elia Piccoli, Malio Li, Giacomo Carfì, Vincenzo Lomonaco, Davide Bacciu","The recent focus and release of pre-trained models have been a key components to several advancements in many fields (e.g. Natural Language Processing and Computer Vision), as a matter of fact, pre-trained models learn disparate latent embeddings sharing insightful representations. On the other hand, Reinforcement Learning (RL) focuses on maximizing the cumulative reward obtained via agent's interaction with the environment. RL agents do not have any prior knowledge about the world, and they either learn from scratch an end-to-end mapping between the observation and action spaces or, in more recent works, are paired with monolithic and computationally expensive Foundational Models. How to effectively combine and leverage the hidden information of different pre-trained models simultaneously in RL is still an open and understudied question. In this work, we propose Weight Sharing Attention (WSA), a new architecture to combine embeddings of multiple pre-trained models to shape an enriched state representation, balancing the tradeoff between efficiency and performance. We run an extensive comparison between several combination modes showing that WSA obtains comparable performance on multiple Atari games compared to end-to-end models. Furthermore, we study the generalization capabilities of this approach and analyze how scaling the number of models influences agents' performance during and after training.","Нещодавня увага та випуск попередньо навчених моделей стали ключовими компонентами кількох досягнень у багатьох галузях (наприклад, обробка природної мови та комп'ютерний зір), адже попередньо навчені моделі вивчають розрізнені латентні вбудовування, об'єднуючись з глибокими уявленнями. З іншого боку, навчання з підкріпленням (RL) фокусується на максимізації сукупної винагороди, отриманої від взаємодії агента з навколишнім середовищем. Агенти RL не мають жодних попередніх знань про світ, і вони або вивчають з нуля наскрізне відображення між простором спостереження і простором дії, або, в останніх роботах, поєднуються з монолітними і обчислювально дорогими фундаментальними моделями. Як ефективно поєднувати і використовувати приховану інформацію різних попередньо навчених моделей одночасно в RL, залишається відкритим і маловивченим питанням. У цій роботі ми пропонуємо Weight Sharing Attention (WSA), нову архітектуру для об'єднання вбудовувань декількох попередньо навчених моделей для формування збагаченого представлення стану, балансуючи між ефективністю та продуктивністю. Ми провели широке порівняння між кількома режимами комбінування, яке показало, що WSA досягає порівнянної продуктивності на кількох іграх Atari порівняно з наскрізними моделями. Крім того, ми вивчаємо можливості узагальнення цього підходу та аналізуємо, як масштабування кількості моделей впливає на продуктивність агентів під час та після навчання.",202,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07197,https://arxiv.org/pdf/2507.07197.pdf,true
2507.07201,MODA: A Unified 3D Diffusion Framework for Multi-Task Target-Aware Molecular Generation,"Dong Xu, Zhangfan Yang, Sisi Yuan, Jenna Xinyi Yao, Jiangqiang Li, Junkai Ji","Three-dimensional molecular generators based on diffusion models can now reach near-crystallographic accuracy, yet they remain fragmented across tasks. SMILES-only inputs, two-stage pretrain-finetune pipelines, and one-task-one-model practices hinder stereochemical fidelity, task alignment, and zero-shot transfer. We introduce MODA, a diffusion framework that unifies fragment growing, linker design, scaffold hopping, and side-chain decoration with a Bayesian mask scheduler. During training, a contiguous spatial fragment is masked and then denoised in one pass, enabling the model to learn shared geometric and chemical priors across tasks. Multi-task training yields a universal backbone that surpasses six diffusion baselines and three training paradigms on substructure, chemical property, interaction, and geometry. Model-C reduces ligand-protein clashes and substructure divergences while maintaining Lipinski compliance, whereas Model-B preserves similarity but trails in novelty and binding affinity. Zero-shot de novo design and lead-optimisation tests confirm stable negative Vina scores and high improvement rates without force-field refinement. These results demonstrate that a single-stage multi-task diffusion routine can replace two-stage workflows for structure-based molecular design.","Тривимірні молекулярні генератори, засновані на дифузійних моделях, тепер можуть досягати майже кристалографічної точності, проте вони залишаються фрагментованими для різних завдань. Вхідні дані, що містять лише SMILES, двоступеневі конвеєри з попередньою підготовкою та налаштуванням, а також практика ""одна задача - одна модель"" перешкоджають стереохімічній точності, узгодженню завдань та перенесенню нульового пострілу. Ми представляємо MODA - дифузійний фреймворк, який об'єднує вирощування фрагментів, дизайн лінкерів, скафолдинг та декорування бічних ланцюгів за допомогою байєсівського планувальника масок. Під час навчання суміжний просторовий фрагмент маскується, а потім деноізується за один прохід, що дозволяє моделі засвоювати спільні геометричні та хімічні передумови для різних завдань. Багатозадачне навчання дає універсальну основу, яка перевершує шість дифузійних базових ліній і три навчальні парадигми щодо субструктури, хімічних властивостей, взаємодії та геометрії. Модель-C зменшує кількість зіткнень ліганд-білок і розбіжностей субструктури, зберігаючи при цьому відповідність Ліпінського, тоді як модель-B зберігає схожість, але поступається в новизні та афінності зв'язування. Тести з нульовим дизайном de novo та оптимізацією свинцю підтверджують стабільні негативні результати за шкалою Віна та високі темпи покращення без вдосконалення силового поля. Ці результати демонструють, що одностадійна багатозадачна процедура дифузії може замінити двостадійні робочі процеси для молекулярного дизайну на основі структури.",162,Biomolecules (q-bio.BM),https://arxiv.org/abs/2507.07201,https://arxiv.org/pdf/2507.07201.pdf,true
2507.07216,Bias-Aware Mislabeling Detection via Decoupled Confident Learning,"Yunyi Li, Maria De-Arteaga, Maytal Saar-Tsechansky","Reliable data is a cornerstone of modern organizational systems. A notable data integrity challenge stems from label bias, which refers to systematic errors in a label, a covariate that is central to a quantitative analysis, such that its quality differs across social groups. This type of bias has been conceptually and empirically explored and is widely recognized as a pressing issue across critical domains. However, effective methodologies for addressing it remain scarce. In this work, we propose Decoupled Confident Learning (DeCoLe), a principled machine learning based framework specifically designed to detect mislabeled instances in datasets affected by label bias, enabling bias aware mislabelling detection and facilitating data quality improvement. We theoretically justify the effectiveness of DeCoLe and evaluate its performance in the impactful context of hate speech detection, a domain where label bias is a well documented challenge. Empirical results demonstrate that DeCoLe excels at bias aware mislabeling detection, consistently outperforming alternative approaches for label error detection. Our work identifies and addresses the challenge of bias aware mislabeling detection and offers guidance on how DeCoLe can be integrated into organizational data management practices as a powerful tool to enhance data reliability.","Надійні дані є наріжним каменем сучасних організаційних систем. Значний виклик цілісності даних пов'язаний з упередженістю ярликів, яка стосується систематичних помилок у ярлику, коваріаті, що є центральною для кількісного аналізу, внаслідок чого його якість відрізняється в різних соціальних групах. Цей тип упередженості був концептуально та емпірично досліджений і широко визнаний як нагальна проблема в критично важливих сферах. Однак ефективних методологій для її подолання все ще бракує. У цій роботі ми пропонуємо роз'єднане впевнене навчання (Decoupled Confident Learning, DeCoLe) - принциповий фреймворк на основі машинного навчання, спеціально розроблений для виявлення неправильно маркованих екземплярів у наборах даних, на які впливає упередженість міток, що уможливлює виявлення неправильного маркування з урахуванням упередженості та сприяє підвищенню якості даних. Ми теоретично обґрунтовуємо ефективність DeCoLe та оцінюємо його продуктивність у контексті виявлення мови ворожнечі - сфери, де упереджене маркування є добре задокументованою проблемою. Емпіричні результати демонструють, що DeCoLe чудово виявляє упереджене маркування, стабільно перевершуючи альтернативні підходи до виявлення помилок у маркуванні. Наша робота визначає та вирішує проблему виявлення упередженого маркування та пропонує рекомендації щодо того, як DeCoLe може бути інтегрований в організаційні практики управління даними як потужний інструмент для підвищення надійності даних.",191,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07216,https://arxiv.org/pdf/2507.07216.pdf,true
2507.07236,An Information-Theoretic Perspective on Multi-LLM Uncertainty Estimation,"Maya Kruse, Majid Afshar, Saksham Khatwani, Anoop Mayampurath, Guanhua Chen, Yanjun Gao","Large language models (LLMs) often behave inconsistently across inputs, indicating uncertainty and motivating the need for its quantification in high-stakes settings. Prior work on calibration and uncertainty quantification often focuses on individual models, overlooking the potential of model diversity. We hypothesize that LLMs make complementary predictions due to differences in training and the Zipfian nature of language, and that aggregating their outputs leads to more reliable uncertainty estimates. To leverage this, we propose MUSE (Multi-LLM Uncertainty via Subset Ensembles), a simple information-theoretic method that uses Jensen-Shannon Divergence to identify and aggregate well-calibrated subsets of LLMs. Experiments on binary prediction tasks demonstrate improved calibration and predictive performance compared to single-model and naive ensemble baselines.","Великі лінгвістичні моделі (ЛМ) часто поводяться непослідовно в залежності від вхідних даних, що вказує на невизначеність і мотивує необхідність її кількісної оцінки в умовах високих ставок. Попередні роботи з калібрування та кількісної оцінки невизначеності часто зосереджуються на окремих моделях, не враховуючи потенціал різноманітності моделей. Ми припускаємо, що МНМ роблять взаємодоповнюючі прогнози через відмінності у навчанні та ципфіанську природу мови, і що агрегування їхніх результатів призводить до більш надійних оцінок невизначеності. Щоб використати це, ми пропонуємо MUSE (Multi-LLM Uncertainty via Subset Ensembles) - простий інформаційно-теоретичний метод, який використовує розбіжність Дженсена-Шеннона для визначення та агрегування добре відкаліброваних підмножин LLMs. Експерименти на задачах бінарного прогнозування демонструють покращену ефективність калібрування та прогнозування порівняно з одномодельними та наївними ансамблевими базовими лініями.",113,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07236,https://arxiv.org/pdf/2507.07236.pdf,true
2507.07247,Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention,"Zhengyu Tian, Anantha Padmanaban Krishna Kumar, Hemant Krishnakumar, Reza Rawassizadeh","As large language models (LLMs) and visual language models (VLMs) grow in scale and application, attention mechanisms have become a central computational bottleneck due to their high memory and time complexity. While many efficient attention variants have been proposed, there remains a lack of rigorous evaluation on their actual energy usage and hardware resource demands during training. In this work, we benchmark eight attention mechanisms in training GPT-2 architecture, measuring key metrics including training time, GPU memory usage, FLOPS, CPU usage, and power consumption. Our results reveal that attention mechanisms with optimized kernel implementations, including Flash Attention, Locality-Sensitive Hashing (LSH) Attention, and Multi-Head Latent Attention (MLA), achieve the best energy efficiency. We further show that lower GPU power alone does not guarantee reduced energy use, as training time plays an equally important role. Our study highlights the importance of energy-aware benchmarking in attention design and provides a practical insight for selecting resource-efficient mechanisms. All our codes are available at GitHub.","У міру того, як великі мовні моделі (ВММ) та візуальні мовні моделі (ВММ) зростають у масштабі та застосуванні, механізми уваги стають центральним обчислювальним вузьким місцем через їхню високу складність у плані пам'яті та часу. Хоча було запропоновано багато ефективних варіантів уваги, все ще бракує суворої оцінки їх фактичного використання енергії та вимог до апаратних ресурсів під час навчання. У цій роботі ми порівняли вісім механізмів уваги при навчанні архітектури GPT-2, вимірявши ключові метрики, включаючи час навчання, використання пам'яті GPU, FLOPS, використання CPU та енергоспоживання. Наші результати показують, що механізми уваги з оптимізованими реалізаціями ядра, включаючи Flash Attention, Locality-Sensitive Hashing (LSH) Attention та Multi-Head Latent Attention (MLA), досягають найкращої енергоефективності. Ми також показали, що зниження потужності графічного процесора саме по собі не гарантує зменшення енергоспоживання, оскільки час навчання відіграє не менш важливу роль. Наше дослідження підкреслює важливість енергоефективного бенчмаркінгу в дизайні уваги та надає практичне розуміння для вибору ресурсоефективних механізмів. Усі наші коди доступні на GitHub.",160,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07247,https://arxiv.org/pdf/2507.07247.pdf,true
2507.07259,Exploiting Edge Features for Transferable Adversarial Attacks in Distributed Machine Learning,"Giulio Rossolini, Fabio Brau, Alessandro Biondi, Battista Biggio, Giorgio Buttazzo","As machine learning models become increasingly deployed across the edge of internet of things environments, a partitioned deep learning paradigm in which models are split across multiple computational nodes introduces a new dimension of security risk. Unlike traditional inference setups, these distributed pipelines span the model computation across heterogeneous nodes and communication layers, thereby exposing a broader attack surface to potential adversaries. Building on these motivations, this work explores a previously overlooked vulnerability: even when both the edge and cloud components of the model are inaccessible (i.e., black-box), an adversary who intercepts the intermediate features transmitted between them can still pose a serious threat. We demonstrate that, under these mild and realistic assumptions, an attacker can craft highly transferable proxy models, making the entire deep learning system significantly more vulnerable to evasion attacks. In particular, the intercepted features can be effectively analyzed and leveraged to distill surrogate models capable of crafting highly transferable adversarial examples against the target model. To this end, we propose an exploitation strategy specifically designed for distributed settings, which involves reconstructing the original tensor shape from vectorized transmitted features using simple statistical analysis, and adapting surrogate architectures accordingly to enable effective feature distillation. A comprehensive and systematic experimental evaluation has been conducted to demonstrate that surrogate models trained with the proposed strategy, i.e., leveraging intermediate features, tremendously improve the transferability of adversarial attacks. These findings underscore the urgent need to account for intermediate feature leakage in the design of secure distributed deep learning systems.","Оскільки моделі машинного навчання все частіше розгортаються за межами середовищ інтернету речей, парадигма розділеного глибокого навчання, в якій моделі розподілені між кількома обчислювальними вузлами, створює новий вимір ризику для безпеки. На відміну від традиційних схем виведення, ці розподілені конвеєри охоплюють обчислення моделі через гетерогенні вузли і рівні зв'язку, тим самим відкриваючи ширшу поверхню атаки для потенційних супротивників. Спираючись на ці мотиви, ця робота досліджує вразливість, яку раніше не помічали: навіть коли периферійні та хмарні компоненти моделі недоступні (тобто, чорний ящик), зловмисник, який перехоплює проміжні функції, що передаються між ними, все одно може становити серйозну загрозу. Ми демонструємо, що за цих м'яких і реалістичних припущень зловмисник може створити проксі-моделі з високим ступенем передачі, що робить всю систему глибокого навчання значно більш вразливою до атак ухилення. Зокрема, перехоплені ознаки можуть бути ефективно проаналізовані та використані для створення сурогатних моделей, здатних створювати високопередавані приклади проти цільової моделі. З цією метою ми пропонуємо стратегію експлуатації, спеціально розроблену для розподілених середовищ, яка передбачає реконструкцію вихідної форми тензора з векторизованих переданих ознак за допомогою простого статистичного аналізу і відповідну адаптацію сурогатних архітектур для забезпечення ефективної дистиляції ознак. Було проведено всебічну і систематичну експериментальну оцінку, яка продемонструвала, що сурогатні моделі, навчені за запропонованою стратегією, тобто з використанням проміжних ознак, значно покращують передаваність атак противника. Ці висновки підкреслюють нагальну потребу враховувати витік проміжних ознак при розробці безпечних розподілених систем глибокого навчання.",248,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07259,https://arxiv.org/pdf/2507.07259.pdf,true
2507.07328,Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery,"Malikussaid, Hilal Hudan Nuha","Large Language Models (LLMs) often generate scientifically plausible but factually invalid information, a challenge we term the ""plausibility-validity gap,"" particularly in specialized domains like chemistry. This paper presents a systematic methodology to bridge this gap by developing a specialized scientific assistant. We utilized the Magistral Small model, noted for its integrated reasoning capabilities, and fine-tuned it using Low-Rank Adaptation (LoRA). A key component of our approach was the creation of a ""dual-domain dataset,"" a comprehensive corpus curated from various sources encompassing both molecular properties and chemical reactions, which was standardized to ensure quality. Our evaluation demonstrates that the fine-tuned model achieves significant improvements over the baseline model in format adherence, chemical validity of generated molecules, and the feasibility of proposed synthesis routes. The results indicate a hierarchical learning pattern, where syntactic correctness is learned more readily than chemical possibility and synthesis feasibility. While a comparative analysis with human experts revealed competitive performance in areas like chemical creativity and reasoning, it also highlighted key limitations, including persistent errors in stereochemistry, a static knowledge cutoff, and occasional reference hallucination. This work establishes a viable framework for adapting generalist LLMs into reliable, specialized tools for chemical research, while also delineating critical areas for future improvement.","Великі мовні моделі (ВММ) часто генерують науково достовірну, але фактично недостовірну інформацію - проблему, яку ми називаємо ""розрив між достовірністю та правдивістю"", особливо у спеціалізованих галузях, таких як хімія. У цій статті представлено систематичну методологію подолання цього розриву шляхом розробки спеціалізованого наукового асистента. Ми використали модель Magistral Small, відому своїми інтегрованими можливостями міркування, і допрацювали її за допомогою низькорангової адаптації (Low-Rank Adaptation, LoRA). Ключовим компонентом нашого підходу було створення ""дводоменного набору даних"" - всеосяжного корпусу даних з різних джерел, що охоплює як молекулярні властивості, так і хімічні реакції, який було стандартизовано для забезпечення якості. Наша оцінка демонструє, що доопрацьована модель досягає значних поліпшень порівняно з базовою моделлю в дотриманні формату, хімічній валідності згенерованих молекул і здійсненності запропонованих маршрутів синтезу. Результати вказують на ієрархічну модель навчання, де синтаксична правильність засвоюється легше, ніж хімічна можливість і здійсненність синтезу. Хоча порівняльний аналіз з експертами-людьми виявив конкурентну ефективність у таких сферах, як хімічна творчість і міркування, він також висвітлив ключові обмеження, включаючи постійні помилки в стереохімії, статичне відсікання знань і періодичні галюцинації щодо референтних даних. Ця робота створює життєздатні рамки для адаптації магістерських програм загального профілю в надійні, спеціалізовані інструменти для хімічних досліджень, а також окреслює критичні сфери для подальшого вдосконалення.",202,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07328,https://arxiv.org/pdf/2507.07328.pdf,true
2507.07335,Leveraging Manifold Embeddings for Enhanced Graph Transformer Representations and Learning,"Ankit Jyothish, Ali Jannesari","Graph transformers typically embed every node in a single Euclidean space, blurring heterogeneous topologies. We prepend a lightweight Riemannian mixture-of-experts layer that routes each node to various kinds of manifold, mixture of spherical, flat, hyperbolic - best matching its local structure. These projections provide intrinsic geometric explanations to the latent space. Inserted into a state-of-the-art ensemble graph transformer, this projector lifts accuracy by up to 3% on four node-classification benchmarks. The ensemble makes sure that both euclidean and non-euclidean features are captured. Explicit, geometry-aware projection thus sharpens predictive power while making graph representations more interpretable.","Трансформатори графів зазвичай вбудовують кожну вершину в єдиний евклідів простір, розмиваючи неоднорідні топології. Ми створюємо легкий ріманівський шар суміші експертів, який спрямовує кожну вершину до різних видів многовидів - сферичних, плоских, гіперболічних - які найкраще відповідають її локальній структурі. Ці проекції дають внутрішнє геометричне пояснення латентному простору. Вбудований у найсучасніший ансамблевий граф-трансформатор, цей проектор підвищує точність на 3% за чотирма критеріями класифікації вузлів. Ансамбль гарантує, що як евклідові, так і неевклідові особливості будуть захоплені. Таким чином, проекція з урахуванням геометрії підвищує прогностичну здатність, роблячи представлення графів більш зрозумілими для інтерпретації.",95,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07335,https://arxiv.org/pdf/2507.07335.pdf,true
2507.07359,Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning,"Zheyu Zhang, Jiayuan Dong, Jie Liu, Xun Huan","We present GO-CBED, a goal-oriented Bayesian framework for sequential causal experimental design. Unlike conventional approaches that select interventions aimed at inferring the full causal model, GO-CBED directly maximizes the expected information gain (EIG) on user-specified causal quantities of interest, enabling more targeted and efficient experimentation. The framework is both non-myopic, optimizing over entire intervention sequences, and goal-oriented, targeting only model aspects relevant to the causal query. To address the intractability of exact EIG computation, we introduce a variational lower bound estimator, optimized jointly through a transformer-based policy network and normalizing flow-based variational posteriors. The resulting policy enables real-time decision-making via an amortized network. We demonstrate that GO-CBED consistently outperforms existing baselines across various causal reasoning and discovery tasks-including synthetic structural causal models and semi-synthetic gene regulatory networks-particularly in settings with limited experimental budgets and complex causal mechanisms. Our results highlight the benefits of aligning experimental design objectives with specific research goals and of forward-looking sequential planning.","Ми представляємо GO-CBED - цілеспрямований байєсівський фреймворк для послідовного причинно-наслідкового експериментального дизайну. На відміну від традиційних підходів, які обирають втручання, спрямовані на виведення повної причинно-наслідкової моделі, GO-CBED безпосередньо максимізує очікуваний приріст інформації (EIG) щодо визначених користувачем причинно-наслідкових величин, що цікавлять його, дозволяючи проводити більш цілеспрямовані та ефективні експерименти. Система є одночасно і не короткозорою, оптимізуючи всі послідовності втручань, і цілеспрямованою, орієнтованою лише на ті аспекти моделі, які мають відношення до причинно-наслідкового запиту. Щоб вирішити проблему нерозв'язності точного обчислення EIG, ми вводимо варіаційний оцінювач нижньої межі, оптимізований спільно за допомогою мережі політик на основі трансформаторів і нормалізуючих варіаційних апостеріорів на основі потоків. Отримана політика дозволяє приймати рішення в реальному часі за допомогою амортизованої мережі. Ми продемонстрували, що GO-CBED постійно перевершує існуючі базові моделі в різних завданнях причинно-наслідкового аналізу та відкриттів, включаючи синтетичні структурні причинно-наслідкові моделі та напівсинтетичні генні регуляторні мережі, особливо в умовах обмеженого експериментального бюджету та складних причинно-наслідкових механізмів. Наші результати підкреслюють переваги узгодження цілей експериментального дизайну з конкретними дослідницькими цілями та перспективного послідовного планування.",156,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07359,https://arxiv.org/pdf/2507.07359.pdf,true
2507.07373,Atherosclerosis through Hierarchical Explainable Neural Network Analysis,"Irsyad Adam, Steven Swee, Erika Yilin, Ethan Ji, William Speier, Dean Wang, Alex Bui, Wei Wang, Karol Watson, Peipei Ping","In this work, we study the problem pertaining to personalized classification of subclinical atherosclerosis by developing a hierarchical graph neural network framework to leverage two characteristic modalities of a patient: clinical features within the context of the cohort, and molecular data unique to individual patients. Current graph-based methods for disease classification detect patient-specific molecular fingerprints, but lack consistency and comprehension regarding cohort-wide features, which are an essential requirement for understanding pathogenic phenotypes across diverse atherosclerotic trajectories. Furthermore, understanding patient subtypes often considers clinical feature similarity in isolation, without integration of shared pathogenic interdependencies among patients. To address these challenges, we introduce ATHENA: Atherosclerosis Through Hierarchical Explainable Neural Network Analysis, which constructs a novel hierarchical network representation through integrated modality learning; subsequently, it optimizes learned patient-specific molecular fingerprints that reflect individual omics data, enforcing consistency with cohort-wide patterns. With a primary clinical dataset of 391 patients, we demonstrate that this heterogeneous alignment of clinical features with molecular interaction patterns has significantly boosted subclinical atherosclerosis classification performance across various baselines by up to 13% in area under the receiver operating curve (AUC) and 20% in F1 score. Taken together, ATHENA enables mechanistically-informed patient subtype discovery through explainable AI (XAI)-driven subnetwork clustering; this novel integration framework strengthens personalized intervention strategies, thereby improving the prediction of atherosclerotic disease progression and management of their clinical actionable outcomes.","У цій роботі ми вивчаємо проблему персоналізованої класифікації субклінічного атеросклерозу шляхом розробки ієрархічної графової нейронної мережі для використання двох характерних модальностей пацієнта: клінічних особливостей в контексті когорти та молекулярних даних, унікальних для окремих пацієнтів. Сучасні методи класифікації захворювань на основі графів виявляють специфічні для пацієнта молекулярні відбитки, але їм бракує узгодженості та розуміння загальних для всієї когорти особливостей, що є важливою вимогою для розуміння патогенних фенотипів при різних атеросклеротичних траєкторіях. Крім того, розуміння підтипів пацієнтів часто розглядає схожість клінічних ознак ізольовано, без інтеграції спільних патогенетичних взаємозалежностей між пацієнтами. Для вирішення цих проблем ми представляємо ATHENA: Атеросклероз через ієрархічний аналіз нейронних мереж, який створює нове ієрархічне мережеве представлення за допомогою інтегрованого навчання модальностей; згодом він оптимізує вивчені молекулярні відбитки пацієнтів, які відображають індивідуальні омічні дані, забезпечуючи узгодженість із загальними для всієї когорти патернами. Використовуючи первинний клінічний набір даних 391 пацієнта, ми продемонстрували, що таке гетерогенне узгодження клінічних ознак з моделями молекулярної взаємодії значно підвищило ефективність класифікації субклінічного атеросклерозу на різних вихідних рівнях до 13% за площею під робочою кривою приймача (AUC) і до 20% за показником F1. У сукупності ATHENA дозволяє механістично визначати підтип пацієнта за допомогою кластеризації підмереж, керованої штучним інтелектом (XAI); ця нова інтеграційна структура посилює персоналізовані стратегії втручання, тим самим покращуючи прогнозування прогресування атеросклеротичного захворювання та управління його клінічними наслідками, що піддаються лікуванню.",222,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07373,https://arxiv.org/pdf/2507.07373.pdf,true
2507.07376,PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments,"Hengrui Liu, Yi Feng, Qilong Zhang","Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications.","Мультиагентний пошук і порятунок (MASAR) відіграє життєво важливу роль у реагуванні на катастрофи, розвідці та рекогносцировці. Однак динамічне і невідоме середовище створює значні проблеми через непередбачуваність цілей і невизначеність навколишнього середовища. Для вирішення цих проблем ми пропонуємо PILOC - систему, яка працює без глобальних попередніх знань, використовуючи місцеве сприйняття і комунікацію. Вона запроваджує механізм феромонного зворотного наведення для ефективної координації та динамічної локалізації цілей. PILOC сприяє децентралізованій співпраці через локальну комунікацію, значно зменшуючи залежність від глобальних каналів. На відміну від звичайної евристики, феромонний механізм вбудований у простір спостереження глибокого навчання з підкріпленням (DRL), підтримуючи непряму координацію агентів на основі сигналів навколишнього середовища. Далі ми інтегруємо цю стратегію в мультиагентну архітектуру на основі DRL і проводимо масштабні експерименти. Результати показують, що поєднання локальної комунікації з феромонними настановами значно підвищує ефективність пошуку, адаптивність та надійність системи. Порівняно з існуючими методами, PILOC працює краще в динамічних сценаріях і сценаріях з обмеженим зв'язком, пропонуючи перспективні напрямки для майбутніх застосувань MASAR.",153,Robotics (cs.RO),https://arxiv.org/abs/2507.07376,https://arxiv.org/pdf/2507.07376.pdf,true
2507.07394,Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer,"Zhimin Zhang, Bi'an Du, Caoyuan Ma, Zheng Wang, Wei Hu","Animal motion embodies species-specific behavioral habits, making the transfer of motion across categories a critical yet complex task for applications in animation and virtual reality. Existing motion transfer methods, primarily focused on human motion, emphasize skeletal alignment (motion retargeting) or stylistic consistency (motion style transfer), often neglecting the preservation of distinct habitual behaviors in animals. To bridge this gap, we propose a novel habit-preserved motion transfer framework for cross-category animal motion. Built upon a generative framework, our model introduces a habit-preservation module with category-specific habit encoder, allowing it to learn motion priors that capture distinctive habitual characteristics. Furthermore, we integrate a large language model (LLM) to facilitate the motion transfer to previously unobserved species. To evaluate the effectiveness of our approach, we introduce the DeformingThings4D-skl dataset, a quadruped dataset with skeletal bindings, and conduct extensive experiments and quantitative analyses, which validate the superiority of our proposed model.","Рухи тварин втілюють видові поведінкові звички, що робить передачу руху між категоріями критично важливим, але складним завданням для додатків в анімації та віртуальній реальності. Існуючі методи передачі руху, орієнтовані в першу чергу на рух людини, підкреслюють вирівнювання скелета (перенацілювання руху) або стилістичну узгодженість (передача стилю руху), часто нехтуючи збереженням чітких звичних форм поведінки тварин. Щоб заповнити цю прогалину, ми пропонуємо новий фреймворк передачі рухів зі збереженням звичок для міжкатегорійних рухів тварин. Побудована на основі генеративного фреймворку, наша модель вводить модуль збереження звичок з категоріально-специфічним кодувальником звичок, що дозволяє їй вивчати попередні рухи, які фіксують відмінні звичні характеристики. Крім того, ми інтегруємо велику мовну модель (LLM) для полегшення перенесення рухів на раніше неспостережувані види. Щоб оцінити ефективність нашого підходу, ми представили набір даних DeformingThings4D-skl, набір даних чотириногих зі скелетними прив'язками, і провели масштабні експерименти та кількісний аналіз, які підтвердили перевагу запропонованої нами моделі.",147,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07394,https://arxiv.org/pdf/2507.07394.pdf,true
2507.07399,Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization,"Yuntian Liu, Tao Zhu, Xiaoyang Liu, Yu Chen, Zhaoxuan Liu, Qingfeng Guo, Jiashuo Zhang, Kangjie Bao, Tao Luo","Statement autoformalization, the automated translation of statement from natural language into formal languages, has become a subject of extensive research, yet the development of robust automated evaluation metrics remains limited. Existing evaluation methods often lack semantic understanding, face challenges with high computational costs, and are constrained by the current progress of automated theorem proving. To address these issues, we propose GTED (Generalized Tree Edit Distance), a novel evaluation framework that first standardizes formal statements and converts them into operator trees, then determines the semantic similarity using the eponymous GTED metric. On the miniF2F and ProofNet benchmarks, GTED outperforms all baseline metrics by achieving the highest accuracy and Kappa scores, thus providing the community with a more faithful metric for automated evaluation. The code and experimental results are available at .","Автоформалізація тверджень, автоматизований переклад тверджень з природної мови на формальні мови, стала предметом широких досліджень, проте розробка надійних метрик автоматизованого оцінювання залишається обмеженою. Існуючим методам оцінювання часто бракує семантичного розуміння, вони стикаються з проблемами, пов'язаними з високими обчислювальними витратами, і обмежені сучасним прогресом автоматизованого доведення теорем. Для вирішення цих проблем ми пропонуємо GTED (Generalized Tree Edit Distance) - нову систему оцінювання, яка спочатку стандартизує формальні твердження і перетворює їх у дерева операторів, а потім визначає семантичну схожість за допомогою однойменної метрики GTED. На бенчмарках miniF2F і ProofNet GTED перевершує всі базові метрики, досягаючи найвищих показників точності та Kappa, таким чином надаючи спільноті більш надійну метрику для автоматизованого оцінювання. Код та експериментальні результати доступні за адресою .",130,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07399,https://arxiv.org/pdf/2507.07399.pdf,true
2507.07405,HGMP:Heterogeneous Graph Multi-Task Prompt Learning,"Pengfei Jiao, Jialong Ni, Di Jin, Xuan Guo, Huan Liu, Hongjiang Chen, Yanxian Bi","The pre-training and fine-tuning methods have gained widespread attention in the field of heterogeneous graph neural networks due to their ability to leverage large amounts of unlabeled data during the pre-training phase, allowing the model to learn rich structural features. However, these methods face the issue of a mismatch between the pre-trained model and downstream tasks, leading to suboptimal performance in certain application scenarios. Prompt learning methods have emerged as a new direction in heterogeneous graph tasks, as they allow flexible adaptation of task representations to address target inconsistency. Building on this idea, this paper proposes a novel multi-task prompt framework for the heterogeneous graph domain, named HGMP. First, to bridge the gap between the pre-trained model and downstream tasks, we reformulate all downstream tasks into a unified graph-level task format. Next, we address the limitations of existing graph prompt learning methods, which struggle to integrate contrastive pre-training strategies in the heterogeneous graph domain. We design a graph-level contrastive pre-training strategy to better leverage heterogeneous information and enhance performance in multi-task scenarios. Finally, we introduce heterogeneous feature prompts, which enhance model performance by refining the representation of input graph features. Experimental results on public datasets show that our proposed method adapts well to various tasks and significantly outperforms baseline methods.","Методи попереднього навчання та точного налаштування набули широкого поширення в галузі гетерогенних графових нейронних мереж завдяки їхній здатності використовувати великі обсяги немаркованих даних на етапі попереднього навчання, що дозволяє моделі вивчати багаті структурні особливості. Однак ці методи стикаються з проблемою невідповідності між попередньо навченою моделлю і подальшими завданнями, що призводить до неоптимальної продуктивності в певних сценаріях застосування. Методи швидкого навчання з'явилися як новий напрямок в гетерогенних графових задачах, оскільки вони дозволяють гнучко адаптувати представлення задачі для вирішення проблеми невідповідності мети. Спираючись на цю ідею, в цій статті пропонується нова багатозадачна система швидкого навчання для гетерогенних графів, названа HGMP. По-перше, щоб подолати розрив між попередньо навченою моделлю та подальшими завданнями, ми переформулюємо всі подальші завдання в уніфікований формат завдань на рівні графа. Далі ми розглянемо обмеження існуючих методів навчання з підказкою на основі графів, які намагаються інтегрувати контрастні стратегії попереднього навчання в гетерогенну графову область. Ми розробили контрастну стратегію попереднього навчання на рівні графів для кращого використання різнорідної інформації та підвищення продуктивності в багатозадачних сценаріях. Нарешті, ми вводимо гетерогенні підказки, які підвищують продуктивність моделі за рахунок уточнення представлення особливостей вхідних графів. Експериментальні результати на публічних наборах даних показують, що запропонований нами метод добре адаптується до різних завдань і значно перевершує базові методи.",210,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07405,https://arxiv.org/pdf/2507.07405.pdf,true
2507.07406,Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models,"Jikesh Thapa, Gurrehmat Chahal, Serban Voinea Gabreanu, Yazan Otoum","Phishing attacks are becoming increasingly sophisticated, underscoring the need for detection systems that strike a balance between high accuracy and computational efficiency. This paper presents a comparative evaluation of traditional Machine Learning (ML), Deep Learning (DL), and quantized small-parameter Large Language Models (LLMs) for phishing detection. Through experiments on a curated dataset, we show that while LLMs currently underperform compared to ML and DL methods in terms of raw accuracy, they exhibit strong potential for identifying subtle, context-based phishing cues. We also investigate the impact of zero-shot and few-shot prompting strategies, revealing that LLM-rephrased emails can significantly degrade the performance of both ML and LLM-based detectors. Our benchmarking highlights that models like DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above 80%, using only 17GB of VRAM, supporting their viability for cost-efficient deployment. We further assess the models' adversarial robustness and cost-performance tradeoffs, and demonstrate how lightweight LLMs can provide concise, interpretable explanations to support real-time decision-making. These findings position optimized LLMs as promising components in phishing defence systems and offer a path forward for integrating explainable, efficient AI into modern cybersecurity frameworks.","Фішингові атаки стають все більш витонченими, що підкреслює потребу в системах виявлення, які забезпечують баланс між високою точністю та обчислювальною ефективністю. У цій статті представлено порівняльну оцінку традиційного машинного навчання (ML), глибинного навчання (DL) та квантованих малопараметричних великих мовних моделей (LLM) для виявлення фішингу. За допомогою експериментів на кураторському наборі даних ми показуємо, що, хоча LLM наразі поступаються методам ML та DL в точності, вони демонструють значний потенціал для виявлення тонких контекстних ознак фішингу. Ми також дослідили вплив стратегій ""нульових"" та ""кількох"" підказок, виявивши, що перефразовані LLM-листи можуть значно погіршити ефективність як ML-, так і LLM-детекторів. Наш бенчмаркінг підкреслює, що такі моделі, як DeepSeek R1 Distill Qwen 14B (Q8_0), досягають конкурентної точності вище 80%, використовуючи лише 17 ГБ оперативної пам'яті, що підтверджує їхню життєздатність для економічно ефективного розгортання. Ми також оцінюємо стійкість моделей до загроз і компроміси між вартістю та продуктивністю, а також демонструємо, як легкі LLM можуть надавати стислі, зрозумілі пояснення для підтримки прийняття рішень у реальному часі. Ці висновки позиціонують оптимізовані LLM як перспективні компоненти в системах захисту від фішингу і пропонують шлях до інтеграції зрозумілого, ефективного ШІ в сучасні системи кібербезпеки.",184,Cryptography and Security (cs.CR),https://arxiv.org/abs/2507.07406,https://arxiv.org/pdf/2507.07406.pdf,true
2507.07413,Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks,"Mohammad F. Al-Hammouri, Yazan Otoum, Rasha Atwa, Amiya Nayak","This paper presents a novel approach to intrusion detection by integrating traditional signature-based methods with the contextual understanding capabilities of the GPT-2 Large Language Model (LLM). As cyber threats become increasingly sophisticated, particularly in distributed, heterogeneous, and resource-constrained environments such as those enabled by the Internet of Things (IoT), the need for dynamic and adaptive Intrusion Detection Systems (IDSs) becomes increasingly urgent. While traditional methods remain effective for detecting known threats, they often fail to recognize new and evolving attack patterns. In contrast, GPT-2 excels at processing unstructured data and identifying complex semantic relationships, making it well-suited to uncovering subtle, zero-day attack vectors. We propose a hybrid IDS framework that merges the robustness of signature-based techniques with the adaptability of GPT-2-driven semantic analysis. Experimental evaluations on a representative intrusion dataset demonstrate that our model enhances detection accuracy by 6.3%, reduces false positives by 9.0%, and maintains near real-time responsiveness. These results affirm the potential of language model integration to build intelligent, scalable, and resilient cybersecurity defences suited for modern connected environments.","У цій статті представлено новий підхід до виявлення вторгнень шляхом інтеграції традиційних методів, заснованих на сигнатурах, з можливостями контекстного розуміння великої мовної моделі GPT-2 (LLM). Оскільки кіберзагрози стають все більш витонченими, особливо в розподілених, гетерогенних і обмежених ресурсами середовищах, таких як Інтернет речей (IoT), потреба в динамічних і адаптивних системах виявлення вторгнень (IDS) стає все більш нагальною. Хоча традиційні методи залишаються ефективними для виявлення відомих загроз, вони часто не здатні розпізнати нові та еволюціонуючі шаблони атак. На відміну від них, GPT-2 чудово обробляє неструктуровані дані та виявляє складні семантичні зв'язки, що робить його придатним для виявлення витончених векторів атак ""нульового дня"". Ми пропонуємо гібридний фреймворк IDS, який поєднує надійність методів на основі сигнатур з адаптивністю семантичного аналізу на основі GPT-2. Експериментальні оцінки на репрезентативному наборі даних про вторгнення демонструють, що наша модель підвищує точність виявлення на 6,3%, зменшує кількість хибних спрацьовувань на 9,0% та підтримує реагування в режимі, близькому до реального часу. Ці результати підтверджують потенціал інтеграції мовних моделей для побудови інтелектуальних, масштабованих та стійких засобів захисту кібербезпеки, придатних для сучасних підключених середовищ.",171,Cryptography and Security (cs.CR),https://arxiv.org/abs/2507.07413,https://arxiv.org/pdf/2507.07413.pdf,true
2507.07414,GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation,Fardin Rastakhiz,"Time, cost, and energy efficiency are critical considerations in Deep-Learning (DL), particularly when processing long texts. Transformers, which represent the current state of the art, exhibit quadratic computational complexity relative to input length, making them inefficient for extended documents. This study introduces a novel model architecture that combines Graph Neural Networks (GNNs) and Convolutional Neural Networks (CNNs), integrated with a real-time, end-to-end graph generation mechanism. The model processes compact batches of character-level inputs without requiring padding or truncation. To enhance performance while maintaining high speed and efficiency, the model incorporates information from Large Language Models (LLMs), such as token embeddings and sentiment polarities, through efficient dictionary lookups. It captures local contextual patterns using CNNs, expands local receptive fields via lattice-based graph structures, and employs small-world graphs to aggregate document-level information. The generated graphs exhibit structural properties indicative of meaningful semantic organization, with an average clustering coefficient of approximately 0.45 and an average shortest path length ranging between 4 and 5. The model is evaluated across multiple text classification tasks, including sentiment analysis and news-categorization, and is compared against state-of-the-art models. Experimental results confirm the proposed model's efficiency and competitive performance.","Час, вартість та енергоефективність є критично важливими факторами при глибокому навчанні (DL), особливо при обробці довгих текстів. Трансформатори, які представляють сучасний стан техніки, демонструють квадратичну обчислювальну складність відносно довжини вхідних даних, що робить їх неефективними для довгих документів. Це дослідження представляє нову архітектуру моделі, яка поєднує графові нейронні мережі (GNN) та згорткові нейронні мережі (CNN), інтегровані з механізмом наскрізної генерації графів у реальному часі. Модель обробляє компактні партії вхідних даних на рівні символів, не вимагаючи заповнення або усікання. Щоб підвищити продуктивність, зберігаючи високу швидкість і ефективність, модель включає інформацію з великих мовних моделей (LLM), таку як вставки лексем і полярності речень, за допомогою ефективного пошуку в словнику. Вона фіксує локальні контекстні патерни за допомогою CNN, розширює локальні рецептивні поля за допомогою графових структур на основі решіток і використовує графи малого світу для агрегування інформації на рівні документів. Згенеровані графи демонструють структурні властивості, що вказують на значущу семантичну організацію, із середнім коефіцієнтом кластеризації приблизно 0,45 і середньою довжиною найкоротшого шляху від 4 до 5. Модель оцінюється в різних задачах класифікації тексту, включаючи аналіз настроїв і категоризацію новин, і порівнюється з найсучаснішими моделями. Експериментальні результати підтверджують ефективність та конкурентоспроможність запропонованої моделі.",190,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07414,https://arxiv.org/pdf/2507.07414.pdf,true
2507.07416,Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation,"Jenifer Paulraj, Brindha Raghuraman, Nagarani Gopalakrishnan, Yazan Otoum","Critical infrastructure systems, including energy grids, healthcare facilities, transportation networks, and water distribution systems, are pivotal to societal stability and economic resilience. However, the increasing interconnectivity of these systems exposes them to various cyber threats, including ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent Threats (APTs). This paper examines cybersecurity vulnerabilities in critical infrastructure, highlighting the threat landscape, attack vectors, and the role of Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid AI-driven cybersecurity framework to enhance real-time vulnerability detection, threat modelling, and automated remediation. This study also addresses the complexities of adversarial AI, regulatory compliance, and integration. Our findings provide actionable insights to strengthen the security and resilience of critical infrastructure systems against emerging cyber threats.","Системи критичної інфраструктури, включаючи енергетичні мережі, заклади охорони здоров'я, транспортні мережі та системи водопостачання, мають вирішальне значення для суспільної стабільності та економічної стійкості. Однак зростаюча взаємопов'язаність цих систем наражає їх на різноманітні кіберзагрози, включаючи програми-вимагачі, атаки типу ""відмова в обслуговуванні"" (DoS) та сучасні постійні загрози (APT). У цьому документі розглядаються вразливості кібербезпеки критичної інфраструктури, висвітлюється ландшафт загроз, вектори атак та роль штучного інтелекту (ШІ) у зменшенні цих ризиків. Ми пропонуємо гібридну систему кібербезпеки на основі штучного інтелекту для покращення виявлення вразливостей у режимі реального часу, моделювання загроз та автоматизованого їх усунення. У цьому дослідженні також розглядаються складнощі, пов'язані з ворожим штучним інтелектом, дотриманням нормативних вимог та інтеграцією. Наші висновки надають практичні рекомендації щодо посилення безпеки та стійкості систем критичної інфраструктури до нових кіберзагроз.",119,Cryptography and Security (cs.CR),https://arxiv.org/abs/2507.07416,https://arxiv.org/pdf/2507.07416.pdf,true
2507.07417,May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks,"Nishit V. Pandya, Andrey Labunets, Sicun Gao, Earlence Fernandes","A popular class of defenses against prompt injection attacks on large language models (LLMs) relies on fine-tuning the model to separate instructions and data, so that the LLM does not follow instructions that might be present with data. There are several academic systems and production-level implementations of this idea. We evaluate the robustness of this class of prompt injection defenses in the whitebox setting by constructing strong optimization-based attacks and showing that the defenses do not provide the claimed security properties. Specifically, we construct a novel attention-based attack algorithm for text-based LLMs and apply it to two recent whitebox defenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks with success rates of up to 70% with modest increase in attacker budget in terms of tokens. Our findings make fundamental progress towards understanding the robustness of prompt injection defenses in the whitebox setting. We release our code and attacks at ","Популярний клас захистів від атак на великі мовні моделі (БММ) заснований на точному налаштуванні моделі для розділення інструкцій і даних, щоб БММ не виконувала інструкції, які можуть бути присутніми разом з даними. Існує декілька академічних систем та реалізацій цієї ідеї на промисловому рівні. Ми оцінюємо надійність цього класу захистів від швидких ін'єкцій в умовах ""білого ящика"" шляхом побудови сильних атак на основі оптимізації і показуємо, що ці захисти не забезпечують заявлених властивостей безпеки. Зокрема, ми побудували новий алгоритм атаки на основі уваги для текстових LLM і застосували його до двох нещодавніх захистів ""білого ящика"" SecAlign (CCS 2025) і StruQ (USENIX Security 2025), продемонструвавши атаки з рівнем успішності до 70% при незначному збільшенні бюджету зловмисника в токенах. Наші результати є фундаментальним кроком до розуміння надійності захисту від швидких ін'єкцій в умовах ""білого ящика"". Ми випускаємо наш код і атаки на",151,Cryptography and Security (cs.CR),https://arxiv.org/abs/2507.07417,https://arxiv.org/pdf/2507.07417.pdf,true
2507.07418,Optimal Auction Design in the Joint Advertising,"Yang Li, Yuchao Ma, Qi Qi","Online advertising is a vital revenue source for major internet platforms. Recently, joint advertising, which assigns a bundle of two advertisers in an ad slot instead of allocating a single advertiser, has emerged as an effective method for enhancing allocation efficiency and revenue. However, existing mechanisms for joint advertising fail to realize the optimality, as they tend to focus on individual advertisers and overlook bundle structures. This paper identifies an optimal mechanism for joint advertising in a single-slot setting. For multi-slot joint advertising, we propose \textbf{BundleNet}, a novel bundle-based neural network approach specifically designed for joint advertising. Our extensive experiments demonstrate that the mechanisms generated by \textbf{BundleNet} approximate the theoretical analysis results in the single-slot setting and achieve state-of-the-art performance in the multi-slot setting. This significantly increases platform revenue while ensuring approximate dominant strategy incentive compatibility and individual rationality.","Інтернет-реклама є життєво важливим джерелом доходу для великих інтернет-платформ. Нещодавно спільна реклама, яка передбачає розміщення пакету з двох рекламодавців в одному рекламному слоті замість розміщення одного рекламодавця, стала ефективним методом підвищення ефективності розміщення та збільшення доходу. Однак існуючі механізми спільної реклами не досягають своєї оптимальності, оскільки вони, як правило, зосереджуються на окремих рекламодавцях та ігнорують структури пакетів. Ця стаття визначає оптимальний механізм для спільної реклами в однослотовому середовищі. Для багатослотової спільної реклами ми пропонуємо \textbf{BundleNet}, новий нейромережевий підхід на основі пакетів, спеціально розроблений для спільної реклами. Наші численні експерименти демонструють, що механізми, згенеровані \textbf{BundleNet}, наближаються до результатів теоретичного аналізу в умовах одного слоту і досягають найсучаснішої продуктивності в умовах декількох слотів. Це значно збільшує дохід платформи, забезпечуючи при цьому приблизну сумісність стимулів домінуючої стратегії та індивідуальну раціональність.",139,Computer Science and Game Theory (cs.GT),https://arxiv.org/abs/2507.07418,https://arxiv.org/pdf/2507.07418.pdf,true
2507.07419,MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning,"Hieu Tran, Zonghai Yao, Won Seok Jang, Sharmin Sultana, Allen Chang, Yuan Zhang, Hong Yu","Generative AI has demonstrated strong potential in healthcare, from clinical decision support to patient-facing chatbots that improve outcomes. A critical challenge for deployment is effective human-AI communication, where content must be both personalized and understandable. We introduce MedReadCtrl, a readability-controlled instruction tuning framework that enables LLMs to adjust output complexity without compromising meaning. Evaluations of nine datasets and three tasks across medical and general domains show that MedReadCtrl achieves significantly lower readability instruction-following errors than GPT-4 (e.g., 1.39 vs. 1.59 on ReadMe, p<0.001) and delivers substantial gains on unseen clinical tasks (e.g., +14.7 ROUGE-L, +6.18 SARI on MTSamples). Experts consistently preferred MedReadCtrl (71.7% vs. 23.3%), especially at low literacy levels. These gains reflect MedReadCtrl's ability to restructure clinical content into accessible, readability-aligned language while preserving medical intent, offering a scalable solution to support patient education and expand equitable access to AI-enabled care.","Генеративний ШІ продемонстрував потужний потенціал у сфері охорони здоров'я - від підтримки прийняття клінічних рішень до чат-ботів, які покращують результати лікування. Важливою проблемою для впровадження є ефективна комунікація між людиною та ШІ, де контент повинен бути персоналізованим та зрозумілим. Ми представляємо MedReadCtrl, фреймворк для налаштування інструкцій з контролем читабельності, який дозволяє LLMs регулювати складність вихідних даних без шкоди для сенсу. Оцінювання дев'яти наборів даних і трьох завдань у медичній і загальній галузях показало, що MedReadCtrl досягає значно нижчого рівня помилок при виконанні інструкцій, ніж GPT-4 (наприклад, 1,39 проти 1,59 на ReadMe, p<0,001), і забезпечує значний приріст у невидимих клінічних завданнях (наприклад, +14,7 ROUGE-L, +6,18 SARI на MTSamples). Експерти незмінно віддавали перевагу MedReadCtrl (71,7% проти 23,3%), особливо на низьких рівнях грамотності. Ці результати відображають здатність MedReadCtrl реструктурувати клінічний контент у доступну, зручну для читання мову, зберігаючи при цьому медичну мету, пропонуючи масштабоване рішення для підтримки навчання пацієнтів і розширення рівного доступу до медичної допомоги зі штучним інтелектом.",142,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07419,https://arxiv.org/pdf/2507.07419.pdf,true
2507.00951,Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact,"Rizwan Qureshi, Ranjan Sapkota, Abbas Shah, Amgad Muneer, Anas Zafar, Ashmal Vayani, Maged Shoman, Abdelrahman B. M. Eldaly, Kai Zhang, Ferhat Sadak, Shaina Raza, Xinqi Fan, Ravid Shwartz-Ziv, Hong Yan, Vinjia Jain, Aman Chadha, Manoj Karkee, Jia Wu, Philip Torr, Seyedali Mirjalili","Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.","Чи можуть машини мислити, міркувати і діяти так само, як люди? Це вічне питання продовжує визначати розвиток штучного загального інтелекту (ШЗІ). Незважаючи на зростаючі можливості таких моделей, як GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4 і Grok 3, які демонструють мультимодальну плавність і часткове міркування, ці системи залишаються фундаментально обмеженими через їхню залежність від прогнозування на рівні токенів і відсутність обґрунтованої волі. Ця стаття пропонує міждисциплінарний синтез розробки AGI, що охоплює штучний інтелект, когнітивну нейронауку, психологію, генеративні моделі та системи на основі агентів. Ми аналізуємо архітектурні та когнітивні основи загального інтелекту, підкреслюючи роль модульного мислення, постійної пам'яті та мультиагентної координації. Зокрема, ми наголошуємо на зростанні агентних фреймворків RAG, які поєднують пошук, планування та динамічне використання інструментів для забезпечення більш адаптивної поведінки. Ми обговорюємо стратегії узагальнення, включаючи стиснення інформації, адаптацію до часу тестування та методи, що не потребують навчання, як критичні шляхи до гнучкого доменно-діагностичного інтелекту. Мовні моделі бачення (VLM) розглядаються не просто як модулі сприйняття, а як еволюціонуючі інтерфейси для втіленого розуміння і спільного виконання завдань. Ми також стверджуємо, що справжній інтелект виникає не лише завдяки масштабу, але й завдяки інтеграції пам'яті та міркувань: оркестровці модульних, інтерактивних та самовдосконалюваних компонентів, де стиснення забезпечує адаптивну поведінку. Спираючись на досягнення в нейросимволічних системах, навчанні з підкріпленням і когнітивних риштуваннях, ми досліджуємо, як новітні архітектури починають долати розрив між статистичним навчанням і цілеспрямованим пізнанням. Нарешті, ми визначаємо ключові наукові, технічні та етичні виклики на шляху до AGI.",241,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.00951,https://arxiv.org/pdf/2507.00951.pdf,true
2507.07421,SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data,"Zonghai Yao, Youxia Zhao, Avijit Mitra, David A. Levy, Emily Druhl, Jack Tsai, Hong Yu","Eviction is a significant yet understudied social determinants of health (SDoH), linked to housing instability, unemployment, and mental health. While eviction appears in unstructured electronic health records (EHRs), it is rarely coded in structured fields, limiting downstream applications. We introduce SynthEHR-Eviction, a scalable pipeline combining LLMs, human-in-the-loop annotation, and automated prompt optimization (APO) to extract eviction statuses from clinical notes. Using this pipeline, we created the largest public eviction-related SDoH dataset to date, comprising 14 fine-grained categories. Fine-tuned LLMs (e.g., Qwen2.5, LLaMA3) trained on SynthEHR-Eviction achieved Macro-F1 scores of 88.8% (eviction) and 90.3% (other SDoH) on human validated data, outperforming GPT-4o-APO (87.8%, 87.3%), GPT-4o-mini-APO (69.1%, 78.1%), and BioBERT (60.7%, 68.3%), while enabling cost-effective deployment across various model sizes. The pipeline reduces annotation effort by over 80%, accelerates dataset creation, enables scalable eviction detection, and generalizes to other information extraction tasks.","Виселення є важливою, але недостатньо вивченою соціальною детермінантою здоров'я (СДЗ), пов'язаною з нестабільністю житла, безробіттям і психічним здоров'ям. Хоча виселення з'являється в неструктурованих електронних медичних картах (ЕМК), воно рідко кодується в структурованих полях, що обмежує подальше застосування. Ми представляємо SynthEHR-Eviction, масштабований конвеєр, що поєднує в собі LLM, анотацію ""людина в циклі"" та автоматизовану оперативну оптимізацію (APO) для вилучення статусів виселення з клінічних записів. Використовуючи цей конвеєр, ми створили найбільший на сьогоднішній день публічний набір даних SDoH, пов'язаний з виселенням, що складається з 14 дрібнозернистих категорій. Точно налаштовані LLM (наприклад, Qwen2.5, LLaMA3), навчені на SynthEHR-Eviction, досягли показників Macro-F1 88,8% (виселення) і 90,3% (інші SDoH) на даних, підтверджених людьми, перевершуючи GPT-4o-APO (87,8%, 87,3%), GPT-4o-mini-APO (69,1%, 78,1%) і BioBERT (60,7%, 68,3%), забезпечуючи при цьому економічно ефективне розгортання в моделях різних розмірів. Пайплайн зменшує зусилля з анотування на понад 80%, прискорює створення наборів даних, дає змогу масштабувати виявлення виселення та узагальнювати для інших завдань з вилучення інформації.",140,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07421,https://arxiv.org/pdf/2507.07421.pdf,true
2507.07439,Towards Interpretable Time Series Foundation Models,"Matthieu Boileau, Philippe Helluy, Jeremy Pawlus, Svitlana Vyetrenko","In this paper, we investigate the distillation of time series reasoning capabilities into small, instruction-tuned language models as a step toward building interpretable time series foundation models. Leveraging a synthetic dataset of mean-reverting time series with systematically varied trends and noise levels, we generate natural language annotations using a large multimodal model and use these to supervise the fine-tuning of compact Qwen models. We introduce evaluation metrics that assess the quality of the distilled reasoning - focusing on trend direction, noise intensity, and extremum localization - and show that the post-trained models acquire meaningful interpretive capabilities. Our results highlight the feasibility of compressing time series understanding into lightweight, language-capable models suitable for on-device or privacy-sensitive deployment. This work contributes a concrete foundation toward developing small, interpretable models that explain temporal patterns in natural language.","У цій статті ми досліджуємо перегонку можливостей міркувань часових рядів у невеликі, налаштовані на інструкції мовні моделі як крок до побудови фундаментальних моделей часових рядів, що піддаються інтерпретації. Використовуючи синтетичний набір даних часових рядів із систематично змінюваними трендами та рівнями шуму, ми генеруємо природні мовні анотації за допомогою великої мультимодальної моделі та використовуємо їх для нагляду за точним налаштуванням компактних моделей Qwen. Ми вводимо метрики оцінювання, які оцінюють якість дистильованих міркувань, зосереджуючись на напрямку тренду, інтенсивності шуму та локалізації екстремуму, і показуємо, що пост-навчені моделі набувають значущих інтерпретаційних здібностей. Наші результати підкреслюють можливість стиснення розуміння часових рядів у легкі, мовні моделі, придатні для розгортання на пристроях або з урахуванням вимог до конфіденційності. Ця робота закладає конкретний фундамент для розробки невеликих інтерпретованих моделей, які пояснюють часові патерни природною мовою.",134,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07439,https://arxiv.org/pdf/2507.07439.pdf,true
2507.07453,Bluish Veil Detection and Lesion Classification using Custom Deep Learnable Layers with Explainable Artificial Intelligence (XAI),"M. A. Rasel, Sameem Abdul Kareem, Zhenli Kwan, Shin Shen Yong, Unaizah Obaidellah","Melanoma, one of the deadliest types of skin cancer, accounts for thousands of fatalities globally. The bluish, blue-whitish, or blue-white veil (BWV) is a critical feature for diagnosing melanoma, yet research into detecting BWV in dermatological images is limited. This study utilizes a non-annotated skin lesion dataset, which is converted into an annotated dataset using a proposed imaging algorithm based on color threshold techniques on lesion patches and color palettes. A Deep Convolutional Neural Network (DCNN) is designed and trained separately on three individual and combined dermoscopic datasets, using custom layers instead of standard activation function layers. The model is developed to categorize skin lesions based on the presence of BWV. The proposed DCNN demonstrates superior performance compared to conventional BWV detection models across different datasets. The model achieves a testing accuracy of 85.71% on the augmented PH2 dataset, 95.00% on the augmented ISIC archive dataset, 95.05% on the combined augmented (PH2+ISIC archive) dataset, and 90.00% on the Derm7pt dataset. An explainable artificial intelligence (XAI) algorithm is subsequently applied to interpret the DCNN's decision-making process regarding BWV detection. The proposed approach, coupled with XAI, significantly improves the detection of BWV in skin lesions, outperforming existing models and providing a robust tool for early melanoma diagnosis.","Меланома, один з найсмертоносніших видів раку шкіри, є причиною тисяч смертей у всьому світі. Синювата, синювато-білувата або синьо-біла вуаль (СБВ) є критично важливою ознакою для діагностики меланоми, проте дослідження щодо виявлення СБВ на дерматологічних зображеннях є обмеженими. У цьому дослідженні використовується неанотований набір даних про ураження шкіри, який перетворюється на анотований набір даних за допомогою запропонованого алгоритму візуалізації, заснованого на методах колірного порогу для ділянок ураження і кольорових палітр. Глибока згорткова нейронна мережа (DCNN) розроблена і навчена окремо на трьох індивідуальних і комбінованих наборах дерматологічних даних, з використанням користувацьких шарів замість стандартних шарів функції активації. Модель розроблено для класифікації уражень шкіри на основі наявності вірусу ВПГ. Запропонована DCNN демонструє вищу продуктивність порівняно з традиційними моделями виявлення BWV на різних наборах даних. Модель досягає точності тестування 85,71% на розширеному наборі даних PH2, 95,00% на розширеному архівному наборі даних ISIC, 95,05% на комбінованому розширеному наборі даних (PH2 + архів ISIC) і 90,00% на наборі даних Derm7pt. Алгоритм штучного інтелекту (XAI), що піддається поясненню, був застосований для інтерпретації процесу прийняття рішень DCNN щодо виявлення BWV. Запропонований підхід у поєднанні з XAI значно покращує виявлення BWV в ураженнях шкіри, перевершуючи існуючі моделі та забезпечуючи надійний інструмент для ранньої діагностики меланоми.",205,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07453,https://arxiv.org/pdf/2507.07453.pdf,true
2507.07460,Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision,"Jeonghoon Song, Sunghun Kim, Jaegyun Im, Byeongjoon Noh","Out-of-Distribution (OoD) segmentation is critical for safety-sensitive applications like autonomous driving. However, existing mask-based methods often suffer from boundary imprecision, inconsistent anomaly scores within objects, and false positives from background noise. We propose \textbf{\textit{Objectomaly}}, an objectness-aware refinement framework that incorporates object-level priors. Objectomaly consists of three stages: (1) Coarse Anomaly Scoring (CAS) using an existing OoD backbone, (2) Objectness-Aware Score Calibration (OASC) leveraging SAM-generated instance masks for object-level score normalization, and (3) Meticulous Boundary Precision (MBP) applying Laplacian filtering and Gaussian smoothing for contour refinement. Objectomaly achieves state-of-the-art performance on key OoD segmentation benchmarks, including SMIYC AnomalyTrack/ObstacleTrack and RoadAnomaly, improving both pixel-level (AuPRC up to 96.99, FPR$_{95}$ down to 0.07) and component-level (F1$-$score up to 83.44) metrics. Ablation studies and qualitative results on real-world driving videos further validate the robustness and generalizability of our method. Code will be released upon publication.","Сегментація за межами розподілу (OoD) є критично важливою для чутливих до безпеки додатків, таких як автономне водіння. Однак, існуючі методи на основі масок часто страждають від неточності меж, непослідовних оцінок аномалій всередині об'єктів і хибних спрацьовувань через фоновий шум. Ми пропонуємо \textbf{\textit{Objectomaly}}, систему уточнення з урахуванням об'єктності, яка включає попередні оцінки на рівні об'єктів. Objectomaly складається з трьох етапів: (1) Грубе оцінювання аномалій (CAS) з використанням існуючого ядра OoD, (2) Калібрування оцінок з урахуванням об'єктності (OASC) з використанням згенерованих SAM масок екземплярів для нормалізації оцінок на рівні об'єктів, і (3) Ретельна точність меж (MBP) із застосуванням лапласіанської фільтрації та гауссового згладжування для уточнення контурів. Objectomaly досягає найсучасніших показників у ключових бенчмарках сегментації OoD, включаючи SMIYC AnomalyTrack/ObstacleTrack і RoadAnomaly, покращуючи показники як на рівні пікселів (AuPRC до 96,99, FPR$_{95}$ до 0,07), так і на рівні компонентів (F1$-$score до 83,44). Дослідження абляції та якісні результати на реальних відеозаписах водіння ще більше підтверджують надійність та узагальнюваність нашого методу. Код буде доступний після публікації.",141,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07460,https://arxiv.org/pdf/2507.07460.pdf,true
2507.07484,Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models,"Kaiqu Liang, Haimin Hu, Xuandong Zhao, Dawn Song, Thomas L. Griffiths, Jaime Fernández Fisac","Bullshit, as conceptualized by philosopher Harry Frankfurt, refers to statements made without regard to their truth value. While previous work has explored large language model (LLM) hallucination and sycophancy, we propose machine bullshit as an overarching conceptual framework that can allow researchers to characterize the broader phenomenon of emergent loss of truthfulness in LLMs and shed light on its underlying mechanisms. We introduce the Bullshit Index, a novel metric quantifying LLMs' indifference to truth, and propose a complementary taxonomy analyzing four qualitative forms of bullshit: empty rhetoric, paltering, weasel words, and unverified claims. We conduct empirical evaluations on the Marketplace dataset, the Political Neutrality dataset, and our new BullshitEval benchmark (2,400 scenarios spanning 100 AI assistants) explicitly designed to evaluate machine bullshit. Our results demonstrate that model fine-tuning with reinforcement learning from human feedback (RLHF) significantly exacerbates bullshit and inference-time chain-of-thought (CoT) prompting notably amplify specific bullshit forms, particularly empty rhetoric and paltering. We also observe prevalent machine bullshit in political contexts, with weasel words as the dominant strategy. Our findings highlight systematic challenges in AI alignment and provide new insights toward more truthful LLM behavior.","За визначенням філософа Гаррі Франкфурта, ""фігня"" - це твердження, зроблені без огляду на їхню істинність. У попередніх роботах ми досліджували галюцинації та підлабузництво у великих мовних моделях (ВММ), а тепер пропонуємо машинну брехню як загальну концептуальну основу, яка може дозволити дослідникам охарактеризувати ширший феномен втрати правдивості у ВММ та пролити світло на його основні механізми. Ми представили Індекс брехні, новий показник, що кількісно вимірює байдужість LLMs до правди, і запропонували додаткову таксономію, яка аналізує чотири якісні форми брехні: порожню риторику, обмовки, лайливі слова та неперевірені твердження. Ми провели емпіричне оцінювання на основі набору даних Marketplace, набору даних Political Neutrality та нашого нового бенчмарку BullshitEval (2400 сценаріїв, що охоплюють 100 асистентів ШІ), спеціально розробленого для оцінювання машинної брехні. Наші результати демонструють, що точне налаштування моделі за допомогою навчання з підкріпленням на основі зворотного зв'язку з людиною (RLHF) значно посилює брехню, а підказки в часі висновку (CoT) помітно посилюють специфічні форми брехні, зокрема порожню риторику і пересмикування фактів. Ми також спостерігаємо переважання машинної нісенітниці в політичному контексті, де домінуючою стратегією є ""лайливі слова"". Наші висновки висвітлюють систематичні проблеми в узгодженні ШІ та надають нові ідеї щодо більш правдивої поведінки LLM.",186,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07484,https://arxiv.org/pdf/2507.07484.pdf,true
2507.07485,Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning,"Wooseong Jeong, Kuk-Jin Yoon","Multi-Task Learning (MTL) enables multiple tasks to be learned within a shared network, but differences in objectives across tasks can cause negative transfer, where the learning of one task degrades another task's performance. While pre-trained transformers significantly improve MTL performance, their fixed network capacity and rigid structure limit adaptability. Previous dynamic network architectures attempt to address this but are inefficient as they directly convert shared parameters into task-specific ones. We propose Dynamic Token Modulation and Expansion (DTME-MTL), a framework applicable to any transformer-based MTL architecture. DTME-MTL enhances adaptability and reduces overfitting by identifying gradient conflicts in token space and applying adaptive solutions based on conflict type. Unlike prior methods that mitigate negative transfer by duplicating network parameters, DTME-MTL operates entirely in token space, enabling efficient adaptation without excessive parameter growth. Extensive experiments demonstrate that DTME-MTL consistently improves multi-task performance with minimal computational overhead, offering a scalable and effective solution for enhancing transformer-based MTL models.","Багатозадачне навчання (MTL) дає змогу вивчати кілька завдань у спільній мережі, але відмінності в цілях різних завдань можуть спричинити негативне перенесення, коли навчання одного завдання погіршує виконання іншого завдання. Хоча попередньо навчені трансформатори значно покращують продуктивність MTL, їх фіксована пропускна здатність мережі та жорстка структура обмежують адаптивність. Попередні динамічні мережеві архітектури намагаються вирішити цю проблему, але вони неефективні, оскільки безпосередньо перетворюють спільні параметри в специфічні для конкретної задачі. Ми пропонуємо Dynamic Token Modulation and Expansion (DTME-MTL) - фреймворк, який можна застосувати до будь-якої архітектури MTL на основі трансформатора. DTME-MTL покращує адаптивність та зменшує надмірну адаптацію шляхом виявлення градієнтних конфліктів у просторі токенів та застосування адаптивних рішень на основі типу конфлікту. На відміну від попередніх методів, які пом'якшують негативну передачу шляхом дублювання параметрів мережі, DTME-MTL працює повністю в просторі токенів, що дозволяє ефективно адаптуватися без надмірного зростання параметрів. Широкі експерименти демонструють, що DTME-MTL послідовно покращує багатозадачну продуктивність з мінімальними обчислювальними накладними витратами, пропонуючи масштабоване і ефективне рішення для вдосконалення трансформаторних моделей MTL.",154,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07485,https://arxiv.org/pdf/2507.07485.pdf,true
2507.07495,PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving,"Mihir Parmar, Palash Goyal, Xin Liu, Yiwen Song, Mingyang Ling, Chitta Baral, Hamid Palangi, Tomas Pfister","Recently, decomposing complex problems into simple subtasks--a crucial part of human-like natural planning--to solve the given problem has significantly boosted the performance of large language models (LLMs). However, leveraging such planning structures during post-training to boost the performance of smaller open-source LLMs remains underexplored. Motivated by this, we introduce PLAN-TUNING, a unified post-training framework that (i) distills synthetic task decompositions (termed ""planning trajectories"") from large-scale LLMs and (ii) fine-tunes smaller models via supervised and reinforcement-learning objectives designed to mimic these planning processes to improve complex reasoning. On GSM8k and the MATH benchmarks, plan-tuned models outperform strong baselines by an average $\sim7\%$. Furthermore, plan-tuned models show better generalization capabilities on out-of-domain datasets, with average $\sim10\%$ and $\sim12\%$ performance improvements on OlympiadBench and AIME 2024, respectively. Our detailed analysis demonstrates how planning trajectories improves complex reasoning capabilities, showing that PLAN-TUNING is an effective strategy for improving task-specific performance of smaller LLMs.","Нещодавно декомпозиція складних задач на прості підзадачі - важлива частина людиноподібного природного планування - для вирішення поставленої проблеми значно підвищила продуктивність великих мовних моделей (БММ). Однак використання таких структур планування під час пост-навчання для підвищення продуктивності менших ЛММ з відкритим вихідним кодом залишається недостатньо дослідженим. Враховуючи це, ми представляємо PLAN-TUNING - уніфіковану систему післятренінгового навчання, яка (i) виокремлює синтетичні декомпозиції задач (так звані ""траєкторії планування"") з великомасштабних ЛММ та (ii) допрацьовує менші моделі за допомогою контрольованих та підкріплених навчальних завдань, розроблених для імітації цих процесів планування для покращення складних міркувань. На тестах GSM8k та математичних тестах оптимізовані моделі перевершують сильні базові моделі в середньому на $\sim7\%$. Крім того, моделі з налаштуванням плану демонструють кращі можливості узагальнення на наборах даних, що не належать до домену, із середнім покращенням продуктивності на $\sim10\%$ та $\sim12\%$ на OlympiadBench та AIME 2024, відповідно. Наш детальний аналіз демонструє, як планування траєкторій покращує можливості складних міркувань, показуючи, що PLAN-TUNING є ефективною стратегією для покращення специфічної продуктивності менших LLM.",149,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07495,https://arxiv.org/pdf/2507.07495.pdf,true
2507.07505,Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models,"Varin Sikka, Vishal Sikka","With widespread adoption of transformer-based language models in AI, there is significant interest in the limits of LLMs capabilities, specifically so-called hallucinations, occurrences in which LLMs provide spurious, factually incorrect or nonsensical information when prompted on certain subjects. Furthermore, there is growing interest in agentic uses of LLMs - that is, using LLMs to create agents that act autonomously or semi-autonomously to carry out various tasks, including tasks with applications in the real world. This makes it important to understand the types of tasks LLMs can and cannot perform. We explore this topic from the perspective of the computational complexity of LLM inference. We show that LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity, and further that LLMs are incapable of verifying the accuracy of tasks beyond a certain complexity. We present examples of both, then discuss some consequences of this work.","З широким розповсюдженням трансформантних мовних моделей в ШІ зростає інтерес до меж можливостей НМ, зокрема до так званих галюцинацій - випадків, коли НМ надають неправдиву, фактично невірну або безглузду інформацію у відповідь на запити на певні теми. Крім того, зростає інтерес до агентського використання LLM - тобто використання LLM для створення агентів, які діють автономно або напівавтономно для виконання різних завдань, у тому числі завдань із застосуванням у реальному світі. Це робить важливим розуміння типів завдань, які LLM можуть і не можуть виконувати. Ми досліджуємо цю тему з точки зору обчислювальної складності виведення LLM. Ми показуємо, що LLM не здатні виконувати обчислювальні та агентні завдання вище певної складності, а також, що LLM не здатні перевіряти точність завдань вище певної складності. Ми наводимо приклади обох тез, а потім обговорюємо деякі наслідки цієї роботи.",148,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07505,https://arxiv.org/pdf/2507.07505.pdf,true
2507.07509,Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System,"Yuanchen Shi, Longyin Zhang, Fang Kong","The growing need for psychological support due to increasing pressures has exposed the scarcity of relevant datasets, particularly in non-English languages. To address this, we propose a framework that leverages limited real-world data and expert knowledge to fine-tune two large language models: Dialog Generator and Dialog Modifier. The Generator creates large-scale psychological counseling dialogues based on predefined paths, which guide system response strategies and user interactions, forming the basis for effective support. The Modifier refines these dialogues to align with real-world data quality. Through both automated and manual review, we construct the Chinese Psychological support Dialogue Dataset (CPsDD), containing 68K dialogues across 13 groups, 16 psychological problems, 13 causes, and 12 support focuses. Additionally, we introduce the Comprehensive Agent Dialogue Support System (CADSS), where a Profiler analyzes user characteristics, a Summarizer condenses dialogue history, a Planner selects strategies, and a Supporter generates empathetic responses. The experimental results of the Strategy Prediction and Emotional Support Conversation (ESC) tasks demonstrate that CADSS achieves state-of-the-art performance on both CPsDD and ESConv datasets.","Зростаюча потреба в психологічній підтримці через посилення тиску виявила дефіцит відповідних наборів даних, особливо неангломовних. Щоб вирішити цю проблему, ми пропонуємо фреймворк, який використовує обмежені реальні дані та експертні знання для доопрацювання двох великих мовних моделей: Генератора діалогів та Модифікатора діалогів. Генератор створює широкомасштабні діалоги психологічного консультування на основі заздалегідь визначених шляхів, які керують стратегіями реагування системи та взаємодією з користувачем, формуючи основу для ефективної підтримки. Модифікатор допрацьовує ці діалоги відповідно до якості реальних даних. Шляхом автоматизованого та ручного перегляду ми створили Китайський набір даних діалогів психологічної підтримки (CPsDD), що містить 68 тис. діалогів у 13 групах, 16 психологічних проблем, 13 причин та 12 напрямків підтримки. Крім того, ми представили Комплексну агентну систему підтримки діалогів (CADSS), де Профайлер аналізує характеристики користувачів, Узагальнювач конденсує історію діалогів, Планувальник обирає стратегії, а Підтримувач генерує емпатичні відповіді. Експериментальні результати завдань прогнозування стратегій та емоційної підтримки діалогу (ESC) демонструють, що CADSS досягає найсучаснішої продуктивності як на наборах даних CPsDD, так і на ESConv.",169,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07509,https://arxiv.org/pdf/2507.07509.pdf,true
2507.07532,Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings,"Berkant Turan, Suhrab Asadulla, David Steinmann, Wolfgang Stammer, Sebastian Pokutta","While Prover-Verifier Games (PVGs) offer a promising path toward verifiability in nonlinear classification models, they have not yet been applied to complex inputs such as high-dimensional images. Conversely, Concept Bottleneck Models (CBMs) effectively translate such data into interpretable concepts but are limited by their reliance on low-capacity linear predictors. In this work, we introduce the Neural Concept Verifier (NCV), a unified framework combining PVGs with concept encodings for interpretable, nonlinear classification in high-dimensional settings. NCV achieves this by utilizing recent minimally supervised concept discovery models to extract structured concept encodings from raw inputs. A prover then selects a subset of these encodings, which a verifier -- implemented as a nonlinear predictor -- uses exclusively for decision-making. Our evaluations show that NCV outperforms CBM and pixel-based PVG classifier baselines on high-dimensional, logically complex datasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV as a promising step toward performative, verifiable AI.","Хоча ігри ""верифікатор-верифікатор"" (Prover-Verifier Games, PVG) пропонують багатообіцяючий шлях до верифікації нелінійних моделей класифікації, їх ще не застосовували до складних вхідних даних, таких як високорозмірні зображення. З іншого боку, моделі ""вузьких місць"" (Concept Bottleneck Models, CBM) ефективно перетворюють такі дані на концепції, які можна інтерпретувати, але їхня залежність від лінійних предикторів з низькою пропускною здатністю є обмеженою. У цій роботі ми представляємо нейронний верифікатор концептів (Neural Concept Verifier, NCV) - уніфікований фреймворк, що поєднує PVG з кодуванням концептів для інтерпретованої нелінійної класифікації в умовах високої розмірності. NCV досягає цього, використовуючи новітні моделі виявлення концептів з мінімальним наглядом для вилучення структурованих кодувань концептів з необроблених вхідних даних. Потім виокремлюється підмножина цих кодувань, яку верифікатор, реалізований як нелінійний предиктор, використовує виключно для прийняття рішень. Наші оцінки показують, що NCV перевершує базові класифікатори CBM та PVG на основі пікселів на високовимірних, логічно складних наборах даних, а також допомагає зменшити поведінку ярликів. Загалом, ми демонструємо, що NCV є перспективним кроком на шляху до продуктивного, верифікованого ШІ.",151,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07532,https://arxiv.org/pdf/2507.07532.pdf,true
2507.07539,CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text,"Akram Elbouanani, Evan Dufraisse, Aboubacar Tuo, Adrian Popescu","This paper presents a competitive approach to multilingual subjectivity detection using large language models (LLMs) with few-shot prompting. We participated in Task 1: Subjectivity of the CheckThat! 2025 evaluation campaign. We show that LLMs, when paired with carefully designed prompts, can match or outperform fine-tuned smaller language models (SLMs), particularly in noisy or low-quality data settings. Despite experimenting with advanced prompt engineering techniques, such as debating LLMs and various example selection strategies, we found limited benefit beyond well-crafted standard few-shot prompts. Our system achieved top rankings across multiple languages in the CheckThat! 2025 subjectivity detection task, including first place in Arabic and Polish, and top-four finishes in Italian, English, German, and multilingual tracks. Notably, our method proved especially robust on the Arabic dataset, likely due to its resilience to annotation inconsistencies. These findings highlight the effectiveness and adaptability of LLM-based few-shot learning for multilingual sentiment tasks, offering a strong alternative to traditional fine-tuning, particularly when labeled data is scarce or inconsistent.","У цій статті представлено змагальний підхід до виявлення багатомовної суб'єктивності з використанням великих мовних моделей (ВММ) з кількома підказками. Ми брали участь у завданні 1: Суб'єктивність оціночної кампанії CheckThat! 2025. Ми показали, що LLM у поєднанні з ретельно розробленими підказками можуть відповідати або перевершувати точно налаштовані малі мовні моделі (SLM), особливо в умовах шуму або низької якості даних. Незважаючи на експерименти з передовими методами інженерії підказок, такими як дебати LLM і різні стратегії підбору прикладів, ми виявили обмежену користь від добре продуманих стандартних підказок з кількома варіантами відповідей. Наша система досягла найвищих результатів на різних мовах у завданні на виявлення суб'єктивності CheckThat! 2025, зокрема перше місце арабською та польською мовами, а також перші чотири місця в італійській, англійській, німецькій та багатомовній версіях. Примітно, що наш метод виявився особливо надійним на арабському наборі даних, ймовірно, завдяки його стійкості до невідповідностей в анотаціях. Ці результати підкреслюють ефективність і адаптивність навчання на основі LLM для багатомовних завдань з виявлення настроїв, пропонуючи сильну альтернативу традиційному точному налаштуванню, особливо коли маркованих даних недостатньо або вони суперечливі.",161,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07539,https://arxiv.org/pdf/2507.07539.pdf,true
2507.07543,The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora,"Chen Amiraz, Yaroslav Fyodorov, Elad Haramaty, Zohar Karnin, Liane Lewin-Eytan","Cross-lingual retrieval-augmented generation (RAG) is a critical capability for retrieving and generating answers across languages. Prior work in this context has mostly focused on generation and relied on benchmarks derived from open-domain sources, most notably Wikipedia. In such settings, retrieval challenges often remain hidden due to language imbalances, overlap with pretraining data, and memorized content. To address this gap, we study Arabic-English RAG in a domain-specific setting using benchmarks derived from real-world corporate datasets. Our benchmarks include all combinations of languages for the user query and the supporting document, drawn independently and uniformly at random. This enables a systematic study of multilingual retrieval behavior. Our findings reveal that retrieval is a critical bottleneck in cross-lingual domain-specific scenarios, with significant performance drops occurring when the user query and supporting document languages differ. A key insight is that these failures stem primarily from the retriever's difficulty in ranking documents across languages. Finally, we propose a simple retrieval strategy that addresses this source of failure by enforcing equal retrieval from both languages, resulting in substantial improvements in cross-lingual and overall performance. These results highlight meaningful opportunities for improving multilingual retrieval, particularly in practical, real-world RAG applications.","Міжмовний пошук з доповненим генеруванням (RAG) є критично важливою можливістю для пошуку та генерування відповідей різними мовами. Попередні дослідження в цьому контексті здебільшого зосереджувалися на генерації та спиралися на еталони, отримані з відкритих джерел, зокрема з Вікіпедії. У таких умовах проблеми пошуку часто залишаються прихованими через мовний дисбаланс, збіг з даними попереднього навчання та запам'ятовування контенту. Щоб заповнити цю прогалину, ми досліджуємо арабсько-англійський RAG у конкретному доменному середовищі, використовуючи бенчмарки, отримані з реальних корпоративних наборів даних. Наші бенчмарки включають всі комбінації мов для запиту користувача і супровідного документа, які були отримані незалежно і рівномірно у випадковому порядку. Це дає змогу систематично вивчати поведінку багатомовного пошуку. Наші результати показують, що пошук є критичним вузьким місцем у багатомовних сценаріях для конкретних доменів зі значним падінням продуктивності, коли мови користувацького запиту і супровідного документа відрізняються. Основний висновок полягає в тому, що ці збої виникають насамперед через труднощі, які виникають у ретрівера при ранжуванні документів різними мовами. Нарешті, ми пропонуємо просту стратегію пошуку, яка усуває це джерело помилок, забезпечуючи однаковий пошук з обох мов, що призводить до значного покращення міжмовної та загальної продуктивності. Ці результати висвітлюють значні можливості для покращення багатомовного пошуку, особливо в практичних, реальних застосуваннях RAG.",193,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07543,https://arxiv.org/pdf/2507.07543.pdf,true
2507.07551,ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing,"Line Abele, Gerrit Anders, Tolgahan Aydın, Jürgen Buder, Helen Fischer, Dominik Kimmel, Markus Huff","The accelerating growth of photographic collections has outpaced manual cataloguing, motivating the use of vision language models (VLMs) to automate metadata generation. This study examines whether Al-generated catalogue descriptions can approximate human-written quality and how generative Al might integrate into cataloguing workflows in archival and museum collections. A VLM (InternVL2) generated catalogue descriptions for photographic prints on labelled cardboard mounts with archaeological content, evaluated by archive and archaeology experts and non-experts in a human-centered, experimental framework. Participants classified descriptions as AI-generated or expert-written, rated quality, and reported willingness to use and trust in AI tools. Classification performance was above chance level, with both groups underestimating their ability to detect Al-generated descriptions. OCR errors and hallucinations limited perceived quality, yet descriptions rated higher in accuracy and usefulness were harder to classify, suggesting that human review is necessary to ensure the accuracy and quality of catalogue descriptions generated by the out-of-the-box model, particularly in specialized domains like archaeological cataloguing. Experts showed lower willingness to adopt AI tools, emphasizing concerns on preservation responsibility over technical performance. These findings advocate for a collaborative approach where AI supports draft generation but remains subordinate to human verification, ensuring alignment with curatorial values (e.g., provenance, transparency). The successful integration of this approach depends not only on technical advancements, such as domain-specific fine-tuning, but even more on establishing trust among professionals, which could both be fostered through a transparent and explainable AI pipeline.","Прискорене зростання фотографічних колекцій випередило ручну каталогізацію, що спонукає до використання моделей мови технічного зору (МЗ) для автоматизації генерації метаданих. У цьому дослідженні розглядається, чи можуть каталожні описи, згенеровані ШМ, наблизитися до якості написаних людиною, і як генеративний ШМ може інтегруватися в робочі процеси каталогізації в архівних і музейних колекціях. В рамках проекту VLM (InternVL2) було створено каталожні описи для фотографічних відбитків на етикетках з картону з археологічним змістом, які оцінювалися експертами з архівної справи та археології і неекспертами в експериментальній, орієнтованій на людину, структурі. Учасники класифікували описи як створені штучним інтелектом або написані експертами, оцінювали якість і повідомляли про готовність використовувати інструменти штучного інтелекту та довіру до них. Ефективність класифікації була вищою за рівень випадковості, причому обидві групи недооцінювали свою здатність розпізнавати описи, створені ШІ. Помилки розпізнавання та галюцинації обмежували сприйняття якості, проте описи з вищими оцінками точності та корисності було важче класифікувати, що свідчить про те, що для забезпечення точності та якості каталогових описів, згенерованих нестандартною моделлю, особливо у спеціалізованих галузях, таких як археологічна каталогізація, необхідна людська перевірка. Експерти продемонстрували меншу готовність впроваджувати інструменти штучного інтелекту, наголошуючи на тому, що відповідальність за збереження має переважати над технічними характеристиками. Ці висновки свідчать на користь спільного підходу, коли ШІ підтримує створення проєктів, але залишається підпорядкованим людській перевірці, забезпечуючи відповідність кураторським цінностям (наприклад, походження, прозорість). Успішна інтеграція цього підходу залежить не лише від технічного прогресу, як-от точне налаштування для конкретного домену, але й від встановлення довіри між професіоналами, чому може сприяти прозорий і зрозумілий конвеєр штучного інтелекту.",235,Human-Computer Interaction (cs.HC),https://arxiv.org/abs/2507.07551,https://arxiv.org/pdf/2507.07551.pdf,true
2507.07572,Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation,"Yupu Liang, Yaping Zhang, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou","Document Image Machine Translation (DIMT) aims to translate text within document images, facing generalization challenges due to limited training data and the complex interplay between visual and textual information. To address these challenges, we introduce M4Doc, a novel single-to-mix modality alignment framework leveraging Multimodal Large Language Models (MLLMs). M4Doc aligns an image-only encoder with the multimodal representations of an MLLM, pre-trained on large-scale document image datasets. This alignment enables a lightweight DIMT model to learn crucial visual-textual correlations during training. During inference, M4Doc bypasses the MLLM, maintaining computational efficiency while benefiting from its multimodal knowledge. Comprehensive experiments demonstrate substantial improvements in translation quality, especially in cross-domain generalization and challenging document image scenarios.","Машинний переклад зображень документів (DIMT) має на меті перекладати текст всередині зображень документів, стикаючись з проблемами узагальнення через обмеженість навчальних даних і складну взаємодію між візуальною та текстовою інформацією. Щоб вирішити ці проблеми, ми представляємо M4Doc - нову систему вирівнювання модальностей, яка використовує мультимодальні великі мовні моделі (MLLM). M4Doc узгоджує кодер, що кодує лише зображення, з мультимодальними представленнями MLLM, попередньо навченими на великих наборах даних зображень документів. Таке узгодження дозволяє легкій моделі DIMT вивчати важливі візуально-текстові кореляції під час навчання. Під час виведення M4Doc оминає MLLM, зберігаючи обчислювальну ефективність і отримуючи вигоду від своїх мультимодальних знань. Комплексні експерименти продемонстрували значне покращення якості перекладу, особливо в міждоменних узагальненнях і складних сценаріях із зображеннями документів.",112,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07572,https://arxiv.org/pdf/2507.07572.pdf,true
2507.07579,NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning,"Tianwei Mu, Feiyu Duan, Bo Zhou, Dan Xue, Manhong Huang","This paper presents a novel few-shot cross-domain anomaly detection framework, Nexus Vision Transformer for Anomaly Detection (NexViTAD), based on vision foundation models, which effectively addresses domain-shift challenges in industrial anomaly detection through innovative shared subspace projection mechanisms and multi-task learning (MTL) module. The main innovations include: (1) a hierarchical adapter module that adaptively fuses complementary features from Hiera and DINO-v2 pre-trained models, constructing more robust feature representations; (2) a shared subspace projection strategy that enables effective cross-domain knowledge transfer through bottleneck dimension constraints and skip connection mechanisms; (3) a MTL Decoder architecture supports simultaneous processing of multiple source domains, significantly enhancing model generalization capabilities; (4) an anomaly score inference method based on Sinkhorn-K-means clustering, combined with Gaussian filtering and adaptive threshold processing for precise pixel level. Valuated on the MVTec AD dataset, NexViTAD delivers state-of-the-art performance with an AUC of 97.5%, AP of 70.4%, and PRO of 95.2% in the target domains, surpassing other recent models, marking a transformative advance in cross-domain defect detection.","У цій статті представлено нову систему виявлення міждоменних аномалій Nexus Vision Transformer for Anomaly Detection (NexViTAD), засновану на моделях фундаменту зору, яка ефективно вирішує проблеми зсуву доменів при виявленні промислових аномалій за допомогою інноваційних механізмів проекції спільного підпростору та модуля багатозадачного навчання (MTL). Основні інновації включають: (1) ієрархічний модуль адаптера, який адаптивно об'єднує взаємодоповнюючі ознаки з попередньо навчених моделей Hiera і DINO-v2, створюючи більш надійні представлення ознак; (2) стратегію проекції спільного підпростору, яка дозволяє ефективно передавати знання між доменами за допомогою обмежень на розмірність вузьких місць і механізмів пропускання з'єднань; (3) архітектура MTL-декодера підтримує одночасну обробку декількох вихідних областей, що значно розширює можливості узагальнення моделі; (4) метод виведення оцінки аномалій на основі кластеризації за методом Sinkhorn-K-середніх у поєднанні з гауссовою фільтрацією та адаптивною пороговою обробкою для точного рівня пікселів. Оцінений на наборі даних MVTec AD, NexViTAD забезпечує найсучаснішу продуктивність з AUC 97,5%, AP 70,4% і PRO 95,2% в цільових доменах, перевершуючи інші останні моделі, що знаменує собою трансформаційний прогрес у виявленні міждоменних дефектів.",164,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07579,https://arxiv.org/pdf/2507.07579.pdf,true
2507.07586,Bayesian Discrete Diffusion Beats Autoregressive Perplexity,Cooper Doyle,"We reveal a hidden Bayesian core of discrete-diffusion language models by showing that the expected denoiser output under the forward masking distribution recovers the exact posterior over clean tokens. Under minimal assumptions, Monte Carlo marginalization over K independent corruptions converges to this posterior at rate O(1/sqrt(K)), yielding a simple proof of consistency and finite-sample error bounds. Building on this insight, we introduce a lightweight inference-time ensemble that averages K mask-and-denoise passes to obtain posterior-aware token probabilities and uncertainty estimates at no extra training cost. On WikiText-2, our method achieves test perplexity 8.8 with K=8, versus 20.3 for GPT-2 Small, despite using a model of comparable size. Code is available at .","Ми розкриваємо приховане байєсівське ядро моделей дискретно-дифузійних мов, показуючи, що очікувана продуктивність денотатора за прямим розподілом маскування відновлює точну апостеріорну оцінку для чистих токенів. За мінімальних припущень, маргіналізація Монте-Карло для K незалежних спотворень збігається до цієї апостеріори зі швидкістю O(1/sqrt(K)), що дає простий доказ узгодженості та межі похибки для скінченної вибірки. Спираючись на це розуміння, ми вводимо полегшений ансамбль часу виведення, який усереднює K проходів маски і зашумлення для отримання апостеріорних оцінок ймовірностей токенів і оцінок невизначеності без додаткових витрат на навчання. На WikiText-2 наш метод досягає тестової заплутаності 8.8 з K=8, проти 20.3 для GPT-2 Small, незважаючи на використання моделі порівнянного розміру. Код доступний за адресою .",111,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07586,https://arxiv.org/pdf/2507.07586.pdf,true
2507.07668,Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation,"Felix Frohnert, Denny Lane B. Sombrillo, Evert van Nieuwenburg, Patrick Emonts","Matching theoretical predictions to experimental data remains a central challenge in hadron spectroscopy. In particular, the identification of new hadronic states is difficult, as exotic signals near threshold can arise from a variety of physical mechanisms. A key diagnostic in this context is the pole structure of the scattering amplitude, but different configurations can produce similar signatures. The mapping between pole configurations and line shapes is especially ambiguous near the mass threshold, where analytic control is limited. In this work, we introduce an uncertainty-aware machine learning approach for classifying pole structures in $S$-matrix elements. Our method is based on an ensemble of classifier chains that provide both epistemic and aleatoric uncertainty estimates. We apply a rejection criterion based on predictive uncertainty, achieving a validation accuracy of nearly $95\%$ while discarding only a small fraction of high-uncertainty predictions. Trained on synthetic data with known pole structures, the model generalizes to previously unseen experimental data, including enhancements associated with the $P_{c\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole structure, representing the presence of a genuine compact pentaquark in the presence of a higher channel virtual state pole with non-vanishing width. While evaluated on this particular state, our framework is broadly applicable to other candidate hadronic states and offers a scalable tool for pole structure inference in scattering amplitudes.","Узгодження теоретичних передбачень з експериментальними даними залишається головною проблемою в адронній спектроскопії. Зокрема, ідентифікація нових адронних станів є складною, оскільки екзотичні сигнали біля порогу можуть виникати внаслідок різних фізичних механізмів. Ключовим діагностичним критерієм у цьому контексті є полюсна структура амплітуди розсіяння, але різні конфігурації можуть давати схожі сигнатури. Зв'язок між конфігурацією полюсів і формою ліній є особливо неоднозначним поблизу порога маси, де аналітичний контроль є обмеженим. У цій роботі ми представляємо підхід машинного навчання з урахуванням невизначеності для класифікації полюсних структур в елементах $S$-матриці. Наш метод базується на ансамблі ланцюгів класифікаторів, які надають як епістемічні, так і алеаторичні оцінки невизначеності. Ми застосовуємо критерій відбраковування на основі прогнозної невизначеності, досягаючи точності перевірки майже $95\%$, відкидаючи при цьому лише невелику частину прогнозів з високою невизначеністю. Навчена на синтетичних даних з відомими полюсними структурами, модель узагальнює раніше небачені експериментальні дані, включно з покращеннями, пов'язаними зі станом $P_{c\bar{c}}(4312)^+$, який спостерігається на LHCb. У цій роботі ми виявили чотириполюсну структуру, що репрезентує присутність справжнього компактного пентакварка в присутності вищого полюса віртуального стану з незникаючою шириною каналу. Хоча ми оцінювали цей конкретний стан, наша концепція широко застосовна до інших адронних станів-кандидатів і пропонує масштабований інструмент для висновку про полюсну структуру за амплітудами розсіяння.",219,High Energy Physics - Phenomenology (hep-ph),https://arxiv.org/abs/2507.07668,https://arxiv.org/pdf/2507.07668.pdf,true
2507.07685,Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought,"Shin'ya Yamaguchi, Kosuke Nishida, Daiki Chijiwa","Large vision-language models (LVLMs) have demonstrated remarkable capabilities by integrating pre-trained vision encoders with large language models (LLMs). Similar to single-modal LLMs, chain-of-thought (CoT) prompting has been adapted for LVLMs to enhance multi-modal reasoning by generating intermediate rationales based on visual and textual inputs. While CoT is assumed to improve grounding and accuracy in LVLMs, our experiments reveal a key challenge: existing LVLMs often ignore the contents of generated rationales in CoT reasoning. To address this, we re-formulate multi-modal CoT reasoning as a KL-constrained reward maximization focused on rationale-conditional log-likelihood. As the optimal solution, we propose rationale-enhanced decoding (RED), a novel plug-and-play inference-time decoding strategy. RED harmonizes visual and rationale information by multiplying distinct image-conditional and rationale-conditional next token distributions. Extensive experiments show that RED consistently and significantly improves reasoning over standard CoT and other decoding methods across multiple benchmarks and LVLMs. Our work offers a practical and effective approach to improve both the faithfulness and accuracy of CoT reasoning in LVLMs, paving the way for more reliable rationale-grounded multi-modal systems.","Великі зорово-мовні моделі (LVLM) продемонстрували чудові можливості завдяки інтеграції попередньо навчених зорових кодерів з великими мовними моделями (LLM). Подібно до одномодальних LLM, для LVLM було адаптовано підказку ""ланцюжок думок"" (CoT) для покращення мультимодальних міркувань шляхом генерування проміжних обґрунтувань на основі візуальних і текстових вхідних даних. Хоча передбачається, що CoT покращує обґрунтованість і точність LVLM, наші експерименти виявили ключову проблему: існуючі LVLM часто ігнорують зміст згенерованих обґрунтувань у міркуваннях CoT. Щоб вирішити цю проблему, ми переформулювали мультимодальні міркування CoT як максимізацію винагороди, обмежену КЛ, орієнтовану на умовну лог-вірогідність обґрунтування. В якості оптимального рішення ми пропонуємо декодування з покращеною аргументацією (RED), нову стратегію декодування в часі виводу, що працює за принципом ""підключи і працюй"". RED гармонізує візуальну та аргументовану інформацію, перемножуючи різні розподіли наступних токенів, зумовлені зображенням та аргументацією, зумовленою зображенням. Широкі експерименти показують, що RED послідовно і значно покращує аргументацію порівняно зі стандартним CoT та іншими методами декодування на багатьох бенчмарках і LVLM. Наша робота пропонує практичний і ефективний підхід для підвищення достовірності і точності міркувань CoT в LVLM, прокладаючи шлях до більш надійних мультимодальних систем, що ґрунтуються на обґрунтуванні.",171,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07685,https://arxiv.org/pdf/2507.07685.pdf,true
2507.07695,KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities,"Hruday Markondapatnaikuni, Basem Suleiman, Abdelkarim Erradi, Shijing Chen","Fine-tuning is an immensely resource-intensive process when retraining Large Language Models (LLMs) to incorporate a larger body of knowledge. Although many fine-tuning techniques have been developed to reduce the time and computational cost involved, the challenge persists as LLMs continue to grow in size and complexity. To address this, a new approach to knowledge expansion in LLMs is needed. Retrieval-Augmented Generation (RAG) offers one such alternative by storing external knowledge in a database and retrieving relevant chunks to support question answering. However, naive implementations of RAG face significant limitations in scalability and answer accuracy. This paper introduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome these limitations. Inspired by the divide-and-conquer paradigm, K2RAG integrates dense and sparse vector search, knowledge graphs, and text summarization to improve retrieval quality and system efficiency. The framework also includes a preprocessing step that summarizes the training data, significantly reducing the training time. K2RAG was evaluated using the MultiHopRAG dataset, where the proposed pipeline was trained on the document corpus and tested on a separate evaluation set. Results demonstrated notable improvements over common naive RAG implementations. K2RAG achieved the highest mean answer similarity score of 0.57, and reached the highest third quartile (Q3) similarity of 0.82, indicating better alignment with ground-truth answers. In addition to improved accuracy, the framework proved highly efficient. The summarization step reduced the average training time of individual components by 93%, and execution speed was up to 40% faster than traditional knowledge graph-based RAG systems. K2RAG also demonstrated superior scalability, requiring three times less VRAM than several naive RAG implementations tested in this study.","Точне налаштування є надзвичайно ресурсномістким процесом при перенавчанні великих мовних моделей (ВММ) для включення більшого обсягу знань. Хоча було розроблено багато методів доопрацювання, щоб зменшити час та обчислювальні витрати, проблема залишається актуальною, оскільки LLM продовжують зростати в розмірі та складності. Щоб вирішити цю проблему, потрібен новий підхід до розширення знань у магістерських програмах. Генерація на основі пошуку та доповнення (Retrieval-Augmented Generation, RAG) пропонує одну з таких альтернатив, зберігаючи зовнішні знання в базі даних і витягуючи відповідні фрагменти для підтримки відповідей на запитання. Однак наївні реалізації RAG стикаються зі значними обмеженнями в масштабованості та точності відповідей. Ця стаття представляє KeyKnowledgeRAG (K2RAG), новий фреймворк, розроблений для подолання цих обмежень. Натхненний парадигмою ""розділяй і володарюй"", K2RAG інтегрує щільний та розріджений векторний пошук, графіки знань та узагальнення тексту для покращення якості пошуку та ефективності системи. Фреймворк також включає етап попередньої обробки, який узагальнює навчальні дані, значно скорочуючи час навчання. K2RAG було оцінено за допомогою набору даних MultiHopRAG, де запропонований пайплайн був навчений на корпусі документів і протестований на окремому оціночному наборі. Результати продемонстрували помітні покращення порівняно з поширеними наївними реалізаціями RAG. K2RAG досяг найвищого середнього показника схожості відповідей - 0,57, а також найвищого показника схожості в третьому квартилі (Q3) - 0,82, що свідчить про краще узгодження з правдивими відповідями. На додаток до підвищення точності, система виявилася дуже ефективною. Крок узагальнення скоротив середній час навчання окремих компонентів на 93%, а швидкість виконання була на 40% вищою, ніж у традиційних RAG-систем на основі графів знань. K2RAG також продемонстрував чудову масштабованість, вимагаючи втричі менше оперативної пам'яті, ніж кілька наївних реалізацій RAG, протестованих у цьому дослідженні.",263,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07695,https://arxiv.org/pdf/2507.07695.pdf,true
2411.11984,Understanding Chain-of-Thought in LLMs through Information Theory,"Jean-Francois Ton, Muhammad Faaiz Taufiq, Yang Liu","Large Language Models (LLMs) have shown impressive performance in complex reasoning tasks through the use of Chain-of-Thought (CoT) reasoning, allowing models to break down problems into manageable sub-tasks. However, existing CoT evaluation techniques either require annotated CoT data or fall short in accurately assessing intermediate reasoning steps, leading to high rates of false positives. In this paper, we formalize CoT reasoning in LLMs through an information-theoretic lens. Specifically, our framework quantifies the `information-gain' at each reasoning step, enabling the identification of failure modes in LLMs without the need for expensive annotated datasets. We demonstrate the efficacy of our approach through extensive experiments on toy arithmetic, GSM8K and PRM800k datasets, where it significantly outperforms existing outcome-based methods by providing more accurate insights into model performance on individual subtasks.","Великі мовні моделі (ВММ) продемонстрували вражаючу продуктивність у складних міркувальних завданнях завдяки використанню ланцюжка міркувань (ЛМ), що дозволяє моделям розбивати проблеми на керовані підзадачі. Однак, існуючі методи оцінювання ШПМ або вимагають анотованих даних ШПМ, або не можуть точно оцінити проміжні кроки міркувань, що призводить до високого рівня помилкових спрацьовувань. У цій статті ми формалізуємо міркування CoT в LLM через інформаційно-теоретичну призму. Зокрема, наша система кількісно оцінює ""приріст інформації"" на кожному кроці міркувань, що дозволяє ідентифікувати режими відмов у LLM без необхідності використання дорогих анотованих наборів даних. Ми демонструємо ефективність нашого підходу за допомогою обширних експериментів з іграшковою арифметикою, наборами даних GSM8K і PRM800k, де він значно перевершує існуючі методи, що базуються на результатах, надаючи більш точне уявлення про продуктивність моделі на окремих підзадачах.",127,Computation and Language (cs.CL),https://arxiv.org/abs/2411.11984,https://arxiv.org/pdf/2411.11984.pdf,true
2507.07780,Where are we with calibration under dataset shift in image classification?,"Mélanie Roschewitz, Raghav Mehta, Fabio de Sousa Ribeiro, Ben Glocker","We conduct an extensive study on the state of calibration under real-world dataset shift for image classification. Our work provides important insights on the choice of post-hoc and in-training calibration techniques, and yields practical guidelines for all practitioners interested in robust calibration under shift. We compare various post-hoc calibration methods, and their interactions with common in-training calibration strategies (e.g., label smoothing), across a wide range of natural shifts, on eight different classification tasks across several imaging domains. We find that: (i) simultaneously applying entropy regularisation and label smoothing yield the best calibrated raw probabilities under dataset shift, (ii) post-hoc calibrators exposed to a small amount of semantic out-of-distribution data (unrelated to the task) are most robust under shift, (iii) recent calibration methods specifically aimed at increasing calibration under shifts do not necessarily offer significant improvements over simpler post-hoc calibration methods, (iv) improving calibration under shifts often comes at the cost of worsening in-distribution calibration. Importantly, these findings hold for randomly initialised classifiers, as well as for those finetuned from foundation models, the latter being consistently better calibrated compared to models trained from scratch. Finally, we conduct an in-depth analysis of ensembling effects, finding that (i) applying calibration prior to ensembling (instead of after) is more effective for calibration under shifts, (ii) for ensembles, OOD exposure deteriorates the ID-shifted calibration trade-off, (iii) ensembling remains one of the most effective methods to improve calibration robustness and, combined with finetuning from foundation models, yields best calibration results overall.","Ми провели масштабне дослідження стану калібрування в реальних умовах зсуву наборів даних для класифікації зображень. Наша робота надає важливу інформацію про вибір методів калібрування постфактум і калібрування під час навчання, а також практичні рекомендації для всіх фахівців, зацікавлених у надійному калібруванні в умовах зсуву. Ми порівнюємо різні методи калібрування постфактум і їхню взаємодію з поширеними стратегіями калібрування під час навчання (наприклад, згладжування міток) у широкому діапазоні природних зсувів для восьми різних завдань класифікації в декількох областях зображень. Ми виявили, що (i) одночасне застосування регуляризації ентропії та згладжування міток дає найкращі відкалібровані вихідні ймовірності при зсуві набору даних, (ii) постфактум калібратори, які піддаються впливу невеликої кількості семантичних даних, що виходять за межі розподілу (не пов'язаних із завданням), є найстійкішими при зсуві, (iii) нещодавні методи калібрування, спеціально спрямовані на покращення калібрування при зсувах, не обов'язково дають значні покращення порівняно з простішими методами постфактум калібрування, (iv) покращення калібрування при зсувах часто досягається ціною погіршення калібрування при внутрішньому розподілі. Важливо, що ці висновки справедливі як для випадково ініціалізованих класифікаторів, так і для класифікаторів, доопрацьованих на основі базових моделей, причому останні постійно краще відкалібровані порівняно з моделями, навченими з нуля. Нарешті, ми провели поглиблений аналіз ефектів ансамблювання і виявили, що (i) застосування калібрування до ансамблювання (а не після) є більш ефективним для калібрування зі зсувами, (ii) для ансамблів вплив OOD погіршує компроміс калібрування зі зсувом ідентифікатора, (iii) ансамблювання залишається одним з найефективніших методів підвищення надійності калібрування, а в поєднанні з доналаштуванням на основі базових моделей дає найкращі результати калібрування в цілому.",245,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07780,https://arxiv.org/pdf/2507.07780.pdf,true
2507.07714,Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots,"Julio Garrido, Javier Vales, Diego Silva-Muñiz, Enrique Riveiro, Pablo López-Matencio, Josué Rivera-Andrade","Cable-Driven Parallel Robots (CDPRs) are increasingly used for load manipulation tasks involving predefined toolpaths with intermediate stops. At each stop, where the platform maintains a fixed pose and the motors keep the cables under tension, the system must evaluate whether it is safe to proceed by detecting anomalies that could compromise performance (e.g., wind gusts or cable impacts). This paper investigates whether anomalies can be detected using only motor torque data, without additional sensors. It introduces an adaptive, unsupervised outlier detection algorithm based on Gaussian Mixture Models (GMMs) to identify anomalies from torque signals. The method starts with a brief calibration period, just a few seconds, during which a GMM is fit on known anomaly-free data. Real-time torque measurements are then evaluated using Mahalanobis distance from the GMM, with statistically derived thresholds triggering anomaly flags. Model parameters are periodically updated using the latest segments identified as anomaly-free to adapt to changing conditions. Validation includes 14 long-duration test sessions simulating varied wind intensities. The proposed method achieves a 100% true positive rate and 95.4% average true negative rate, with 1-second detection latency. Comparative evaluation against power threshold and non-adaptive GMM methods indicates higher robustness to drift and environmental variation.","Паралельні роботи з кабельним приводом (CDPR) все частіше використовуються для маніпуляцій з вантажами, що передбачають попередньо визначену траєкторію руху з проміжними зупинками. На кожній зупинці, коли платформа зберігає фіксовану позицію, а двигуни тримають кабелі в натягнутому стані, система повинна оцінити, чи безпечно продовжувати рух, виявляючи аномалії, які можуть поставити під загрозу продуктивність (наприклад, пориви вітру або удари кабелю). У цій статті досліджується, чи можна виявити аномалії, використовуючи лише дані про крутний момент двигуна, без додаткових датчиків. Вона представляє адаптивний, неконтрольований алгоритм виявлення відхилень, заснований на моделях гауссової суміші (GMM) для виявлення аномалій за сигналами крутного моменту. Метод починається з короткого періоду калібрування, всього кілька секунд, під час якого GMM підганяється під відомі дані без аномалій. Потім вимірювання крутного моменту в реальному часі оцінюються за допомогою відстані Махаланобіса від GMM зі статистично отриманими пороговими значеннями, які запускають прапори аномалій. Параметри моделі періодично оновлюються з використанням останніх сегментів, визначених як вільні від аномалій, щоб адаптуватися до мінливих умов. Валідація включає 14 тривалих тестових сесій, що імітують різну інтенсивність вітру. Запропонований метод досягає 100% істинно позитивного результату і 95,4% середнього істинно негативного результату з затримкою виявлення в 1 секунду. Порівняльна оцінка з методами порогової потужності та неадаптивними методами GMM вказує на вищу стійкість до дрейфу та змін у навколишньому середовищі.",198,Robotics (cs.RO),https://arxiv.org/abs/2507.07714,https://arxiv.org/pdf/2507.07714.pdf,true
2507.07725,Not All Preferences are What You Need for Post-Training: Selective Alignment Strategy for Preference Optimization,Zhijin Dong,"Post-training alignment of large language models (LLMs) is a critical challenge, as not all tokens contribute equally to model performance. This paper introduces a selective alignment strategy that prioritizes high-impact tokens within preference pairs, leveraging token-level log-probability differences between the current policy and a reference model. By focusing on these informative tokens, our approach reduces computational overhead and enhances alignment fidelity. We further explore the role of reference model quality, demonstrating that stronger reference models significantly improve token selection accuracy and overall optimization effectiveness. Comprehensive experiments on benchmarks such as Arena-Hard and MT-Bench validate the superiority of our Selective-DPO method over standard DPO and distillation-based baselines. Our findings highlight the importance of token-level optimization and reference model selection in advancing preference alignment for LLMs. The code is available at .","Вирівнювання великих мовних моделей (ВММ) після навчання є критично важливим завданням, оскільки не всі лексеми однаково впливають на продуктивність моделі. У цій статті представлено стратегію вибіркового вирівнювання, яка надає пріоритет лексемам з високим впливом у парах преференцій, використовуючи різницю в лог-вірогідності на рівні лексеми між поточною політикою та еталонною моделлю. Зосереджуючись на цих інформативних токенах, наш підхід зменшує обчислювальні витрати і підвищує точність вирівнювання. Ми також досліджуємо роль якості еталонної моделі, демонструючи, що сильніші еталонні моделі значно покращують точність вибору токенів і загальну ефективність оптимізації. Комплексні експерименти на таких тестах, як Arena-Hard і MT-Bench, підтверджують перевагу нашого методу Selective-DPO над стандартними DPO і базовими моделями на основі дистиляції. Наші результати підкреслюють важливість оптимізації на рівні токенів та вибору еталонної моделі для вирівнювання переваг для LLM. Код доступний за адресою .",130,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07725,https://arxiv.org/pdf/2507.07725.pdf,true
2507.07748,"When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance","Peizhang Shao, Linrui Xu, Jinxi Wang, Wei Zhou, Xingyu Wu","This paper establishes the first comprehensive review of Large Language Models (LLMs) applied within the legal domain. It pioneers an innovative dual lens taxonomy that integrates legal reasoning frameworks and professional ontologies to systematically unify historical research and contemporary breakthroughs. Transformer-based LLMs, which exhibit emergent capabilities such as contextual reasoning and generative argumentation, surmount traditional limitations by dynamically capturing legal semantics and unifying evidence reasoning. Significant progress is documented in task generalization, reasoning formalization, workflow integration, and addressing core challenges in text processing, knowledge integration, and evaluation rigor via technical innovations like sparse attention mechanisms and mixture-of-experts architectures. However, widespread adoption of LLM introduces critical challenges: hallucination, explainability deficits, jurisdictional adaptation difficulties, and ethical asymmetry. This review proposes a novel taxonomy that maps legal roles to NLP subtasks and computationally implements the Toulmin argumentation framework, thus systematizing advances in reasoning, retrieval, prediction, and dispute resolution. It identifies key frontiers including low-resource systems, multimodal evidence integration, and dynamic rebuttal handling. Ultimately, this work provides both a technical roadmap for researchers and a conceptual framework for practitioners navigating the algorithmic future, laying a robust foundation for the next era of legal artificial intelligence. We have created a GitHub repository to index the relevant papers: .","Ця стаття є першим всебічним оглядом великих мовних моделей (ВММ), що застосовуються в юридичній сфері. Вона започатковує інноваційну таксономію з подвійною лінзою, яка інтегрує юридичні системи міркувань і професійні онтології для систематичного об'єднання історичних досліджень і сучасних досягнень. Трансформаторні ЛПМ, які демонструють нові можливості, такі як контекстуальна аргументація та генеративна аргументація, долають традиційні обмеження, динамічно фіксуючи правову семантику та уніфікуючи доказову аргументацію. Задокументовано значний прогрес в узагальненні завдань, формалізації міркувань, інтеграції робочих процесів і вирішенні основних проблем в обробці текстів, інтеграції знань і строгості оцінювання за допомогою технічних інновацій, таких як механізми розрідженої уваги і архітектури зі змішаним складом експертів. Однак широке впровадження LLM створює критичні виклики: галюцинації, дефіцит пояснюваності, труднощі юрисдикційної адаптації та етична асиметрія. У цьому огляді пропонується нова таксономія, яка співвідносить юридичні ролі з підзадачами НЛП і комп'ютерно реалізує структуру аргументації Тулміна, таким чином систематизуючи досягнення в аргументації, пошуку, прогнозуванні та вирішенні спорів. Вона визначає ключові межі, включаючи системи з низькими ресурсами, інтеграцію мультимодальних доказів і динамічну обробку спростувань. Зрештою, ця робота надає як технічну дорожню карту для дослідників, так і концептуальну основу для практиків, які орієнтуються в алгоритмічному майбутньому, закладаючи міцний фундамент для наступної ери правового штучного інтелекту. Ми створили репозиторій на GitHub для індексації відповідних статей: .",203,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07748,https://arxiv.org/pdf/2507.07748.pdf,true
2507.07754,OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting,"Jaeheun Jung, Bosung Jung, Suhyun Bae, Donghun Lee","Machine unlearning seeks to remove the influence of particular data or class from trained models to meet privacy, legal, or ethical requirements. Existing unlearning methods tend to forget shallowly: phenomenon of an unlearned model pretend to forget by adjusting only the model response, while its internal representations retain information sufficiently to restore the forgotten data or behavior. We empirically confirm the widespread shallowness by reverting the forgetting effect of various unlearning methods via training-free performance recovery attack and gradient-inversion-based data reconstruction attack. To address this vulnerability fundamentally, we define a theoretical criterion of ``deep forgetting'' based on one-point-contraction of feature representations of data to forget. We also propose an efficient approximation algorithm, and use it to construct a novel general-purpose unlearning algorithm: One-Point-Contraction (OPC). Empirical evaluations on image classification unlearning benchmarks show that OPC achieves not only effective unlearning performance but also superior resilience against both performance recovery attack and gradient-inversion attack. The distinctive unlearning performance of OPC arises from the deep feature forgetting enforced by its theoretical foundation, and recaps the need for improved robustness of machine unlearning methods.","Машинне розучування має на меті усунути вплив певних даних або класів на навчені моделі, щоб задовольнити вимоги щодо конфіденційності, юридичні або етичні вимоги. Існуючі методи розучування мають тенденцію до неглибокого забування: феномен ненавченої моделі вдає, що вона забула, коригуючи лише реакцію моделі, тоді як її внутрішні репрезентації зберігають інформацію, достатню для відновлення забутих даних або поведінки. Ми емпірично підтверджуємо поширену неглибокість, повертаючи ефект забування різних методів розучування за допомогою атаки на відновлення продуктивності без навчання та атаки на реконструкцію даних на основі градієнтної інверсії. Для фундаментального усунення цієї вразливості ми визначили теоретичний критерій ""глибокого забування"", який базується на одноточковому стисненні представлень ознак даних, що підлягають забуванню. Ми також пропонуємо ефективний алгоритм апроксимації і використовуємо його для побудови нового алгоритму розучування загального призначення: Одноточкове скорочення (One-Point-Contraction, OPC). Емпіричні оцінки на тестах класифікації зображень показують, що OPC не тільки ефективно навчається, але й має чудову стійкість до атак на відновлення продуктивності та градієнтно-інверсійних атак. Відмінна ефективність перенавчання КДК пояснюється глибоким забуванням ознак, що закладено в його теоретичній основі, і нагадує про необхідність покращення надійності методів машинного перенавчання.",180,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07754,https://arxiv.org/pdf/2507.07754.pdf,true
2507.07778,Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training,"Wooseong Jeong, Jegyeong Cho, Youngho Yoon, Kuk-Jin Yoon","Generalizing neural networks to unseen target domains is a significant challenge in real-world deployments. Test-time training (TTT) addresses this by using an auxiliary self-supervised task to reduce the domain gap caused by distribution shifts between the source and target. However, we find that when models are required to perform multiple tasks under domain shifts, conventional TTT methods suffer from unsynchronized task behavior, where the adaptation steps needed for optimal performance in one task may not align with the requirements of other tasks. To address this, we propose a novel TTT approach called Synchronizing Tasks for Test-time Training (S4T), which enables the concurrent handling of multiple tasks. The core idea behind S4T is that predicting task relations across domain shifts is key to synchronizing tasks during test time. To validate our approach, we apply S4T to conventional multi-task benchmarks, integrating it with traditional TTT protocols. Our empirical results show that S4T outperforms state-of-the-art TTT methods across various benchmarks.","Узагальнення нейронних мереж для невидимих цільових областей є значною проблемою при розгортанні в реальних умовах. Навчання в реальному часі (Test-time training, TTT) вирішує цю проблему за допомогою допоміжного самоконтролюючого завдання для зменшення розриву між доменами, спричиненого зміщенням розподілу між джерелом і ціллю. Однак ми виявили, що коли моделі повинні виконувати кілька завдань в умовах зсуву доменів, традиційні методи TTT страждають від несинхронізованої поведінки завдань, коли кроки адаптації, необхідні для оптимальної продуктивності в одному завданні, можуть не відповідати вимогам інших завдань. Щоб вирішити цю проблему, ми пропонуємо новий підхід TTT під назвою ""Синхронізація завдань для тестового навчання"" (Synchronizing Tasks for Test-time Training, S4T), який дозволяє одночасно обробляти кілька завдань. Основна ідея S4T полягає в тому, що прогнозування взаємозв'язків між завданнями при зміні доменів є ключовим для синхронізації завдань під час тестування. Щоб перевірити наш підхід, ми застосували S4T до звичайних багатозадачних бенчмарків, інтегрувавши його з традиційними протоколами TTT. Наші емпіричні результати показують, що S4T перевершує найсучасніші методи TTT у різних тестах.",157,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07778,https://arxiv.org/pdf/2507.07778.pdf,true
2507.07796,Visual Instance-aware Prompt Tuning,"Xi Xiao, Yunbei Zhang, Xingjian Li, Tianyang Wang, Xiao Wang, Yuxiang Wei, Jihun Hamm, Min Xu","Visual Prompt Tuning (VPT) has emerged as a parameter-efficient fine-tuning paradigm for vision transformers, with conventional approaches utilizing dataset-level prompts that remain the same across all input instances. We observe that this strategy results in sub-optimal performance due to high variance in downstream datasets. To address this challenge, we propose Visual Instance-aware Prompt Tuning (ViaPT), which generates instance-aware prompts based on each individual input and fuses them with dataset-level prompts, leveraging Principal Component Analysis (PCA) to retain important prompting information. Moreover, we reveal that VPT-Deep and VPT-Shallow represent two corner cases based on a conceptual understanding, in which they fail to effectively capture instance-specific information, while random dimension reduction on prompts only yields performance between the two extremes. Instead, ViaPT overcomes these limitations by balancing dataset-level and instance-level knowledge, while reducing the amount of learnable parameters compared to VPT-Deep. Extensive experiments across 34 diverse datasets demonstrate that our method consistently outperforms state-of-the-art baselines, establishing a new paradigm for analyzing and optimizing visual prompts for vision transformers.","Візуальне налаштування підказок (VPT) з'явилося як ефективна парадигма точного налаштування параметрів для трансформаторів технічного зору, при цьому традиційні підходи використовують підказки на рівні набору даних, які залишаються однаковими для всіх вхідних екземплярів. Ми спостерігаємо, що ця стратегія призводить до неоптимальної продуктивності через високу дисперсію в наступних наборах даних. Щоб вирішити цю проблему, ми запропонували візуальне налаштування підказок (Visual Instance-aware Prompt Tuning, ViaPT), яке генерує підказки на основі кожного окремого введення і об'єднує їх з підказками на рівні набору даних, використовуючи аналіз головних компонент (PCA) для збереження важливої інформації підказок. Більше того, ми виявили, що VPT-Deep і VPT-Shallow представляють два крайні випадки, засновані на концептуальному розумінні, в яких вони не здатні ефективно фіксувати специфічну інформацію, тоді як випадкове зменшення розмірності підказок дає продуктивність лише між цими двома крайнощами. Натомість ViaPT долає ці обмеження, балансуючи між знаннями на рівні набору даних і на рівні екземплярів, водночас зменшуючи кількість параметрів, що вивчаються, порівняно з VPT-Deep. Широкі експерименти на 34 різноманітних наборах даних демонструють, що наш метод постійно перевершує найсучасніші базові показники, встановлюючи нову парадигму для аналізу та оптимізації візуальних підказок для трансформаторів зору.",166,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07796,https://arxiv.org/pdf/2507.07796.pdf,true
2507.07808,Bridging Logic and Learning: Decoding Temporal Logic Embeddings via Transformers,"Sara Candussio, Gaia Saveri, Gabriele Sarti, Luca Bortolussi","Continuous representations of logic formulae allow us to integrate symbolic knowledge into data-driven learning algorithms. If such embeddings are semantically consistent, i.e. if similar specifications are mapped into nearby vectors, they enable continuous learning and optimization directly in the semantic space of formulae. However, to translate the optimal continuous representation into a concrete requirement, such embeddings must be invertible. We tackle this issue by training a Transformer-based decoder-only model to invert semantic embeddings of Signal Temporal Logic (STL) formulae. STL is a powerful formalism that allows us to describe properties of signals varying over time in an expressive yet concise way. By constructing a small vocabulary from STL syntax, we demonstrate that our proposed model is able to generate valid formulae after only 1 epoch and to generalize to the semantics of the logic in about 10 epochs. Additionally, the model is able to decode a given embedding into formulae that are often simpler in terms of length and nesting while remaining semantically close (or equivalent) to gold references. We show the effectiveness of our methodology across various levels of training formulae complexity to assess the impact of training data on the model's ability to effectively capture the semantic information contained in the embeddings and generalize out-of-distribution. Finally, we deploy our model for solving a requirement mining task, i.e. inferring STL specifications that solve a classification task on trajectories, performing the optimization directly in the semantic space.","Неперервні представлення логічних формул дозволяють інтегрувати символічні знання в алгоритми навчання на основі даних. Якщо такі вбудовування є семантично узгодженими, тобто якщо подібні специфікації відображаються в сусідні вектори, вони дозволяють здійснювати безперервне навчання та оптимізацію безпосередньо в семантичному просторі формул. Однак, щоб перетворити оптимальне неперервне представлення в конкретну вимогу, такі вбудовування повинні бути інвертованими. Ми вирішуємо цю проблему, навчаючи модель, що базується на трансформаторах, інвертувати семантичні вкладки формул сигнальної часової логіки (STL). STL - це потужний формалізм, який дозволяє нам описувати властивості сигналів, що змінюються з часом, у виразний, але стислий спосіб. Побудувавши невеликий словник із синтаксису STL, ми продемонстрували, що запропонована нами модель здатна генерувати правильні формули лише після 1 епохи і узагальнювати до семантики логіки приблизно за 10 епох. Крім того, модель здатна декодувати задане вкладання у формули, які часто є простішими з точки зору довжини та вкладеності, залишаючись при цьому семантично близькими (або еквівалентними) до золотих посилань. Ми показуємо ефективність нашої методології на різних рівнях складності навчальних формул, щоб оцінити вплив навчальних даних на здатність моделі ефективно вловлювати семантичну інформацію, що міститься у вбудовуваннях, та узагальнювати її поза розподілом. Нарешті, ми розгортаємо нашу модель для розв'язання задачі інтелектуального аналізу вимог, тобто виведення STL-специфікацій, які розв'язують задачу класифікації на траєкторіях, виконуючи оптимізацію безпосередньо в семантичному просторі.",237,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07808,https://arxiv.org/pdf/2507.07808.pdf,true
2507.07817,On the Effect of Instruction Tuning Loss on Generalization,"Anwoy Chatterjee, H S V N S Kowndinya Renduchintala, Sumit Bhatia, Tanmoy Chakraborty","Instruction Tuning has emerged as a pivotal post-training paradigm that enables pre-trained language models to better follow user instructions. Despite its significance, little attention has been given to optimizing the loss function used. A fundamental, yet often overlooked, question is whether the conventional auto-regressive objective - where loss is computed only on response tokens, excluding prompt tokens - is truly optimal for instruction tuning. In this work, we systematically investigate the impact of differentially weighting prompt and response tokens in instruction tuning loss, and propose Weighted Instruction Tuning (WIT) as a better alternative to conventional instruction tuning. Through extensive experiments on five language models of different families and scale, three finetuning datasets of different sizes, and five diverse evaluation benchmarks, we show that the standard instruction tuning loss often yields suboptimal performance and limited robustness to input prompt variations. We find that a low-to-moderate weight for prompt tokens coupled with a moderate-to-high weight for response tokens yields the best-performing models across settings and also serve as better starting points for the subsequent preference alignment training. These findings highlight the need to reconsider instruction tuning loss and offer actionable insights for developing more robust and generalizable models. Our code is open-sourced at .","Налаштування інструкцій стало ключовою парадигмою після навчання, яка дає змогу попередньо навченим мовним моделям краще виконувати інструкції користувача. Незважаючи на її важливість, оптимізації функції втрат, що використовується, приділялося мало уваги. Фундаментальне питання, яке часто ігнорується, полягає в тому, чи є звичайна авторегресійна задача, де втрати обчислюються лише для лексем відповіді, не враховуючи лексем підказки, дійсно оптимальною для налаштування інструкцій. У цій роботі ми систематично досліджуємо вплив різного зважування лексем підказки та відповіді на втрати при налаштуванні інструкцій і пропонуємо зважене налаштування інструкцій (WIT) як кращу альтернативу звичайному налаштуванню інструкцій. За допомогою обширних експериментів на п'яти мовних моделях різних сімейств і масштабів, трьох наборів даних різного розміру та п'яти різноманітних оціночних тестів ми показали, що стандартна втрата при налаштуванні інструкцій часто призводить до неоптимальної продуктивності та обмеженої стійкості до варіацій підказок на вході. Ми виявили, що низька або помірна вага маркерів підказок у поєднанні з помірною або високою вагою маркерів відповідей забезпечує найкращу продуктивність моделей у різних умовах, а також слугує кращою відправною точкою для подальшого навчання вирівнюванню переваг. Ці висновки підкреслюють необхідність переглянути втрати при налаштуванні інструкцій і пропонують практичні ідеї для розробки більш надійних і узагальнюючих моделей. Наш код доступний з відкритим вихідним кодом за адресою .",202,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07817,https://arxiv.org/pdf/2507.07817.pdf,true
2501.07964,Derivation of Output Correlation Inferences for Multi-Output (aka Multi-Task) Gaussian Process,Shuhei Watanabe,"Gaussian process (GP) is arguably one of the most widely used machine learning algorithms in practice. One of its prominent applications is Bayesian optimization (BO). Although the vanilla GP itself is already a powerful tool for BO, it is often beneficial to be able to consider the dependencies of multiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it is not trivial to fully understand the derivations of its formulations and their gradients from the previous literature. This paper serves friendly derivations of the MTGP formulations and their gradients.","Гауссів процес (ГП) є, мабуть, одним з найпоширеніших алгоритмів машинного навчання на практиці. Одне з його важливих застосувань - байєсівська оптимізація (БО). Хоча сам по собі ГП вже є потужним інструментом для БО, часто корисно мати можливість враховувати залежності декількох виходів. Для цього було сформульовано багатозадачний ГП (БЗГП), але повне розуміння похідних його формулювань та їх градієнтів з попередньої літератури не є тривіальною задачею. У цій статті подано дружні похідні формулювань MTGP та їх градієнтів.",91,Machine Learning (cs.LG),https://arxiv.org/abs/2501.07964,https://arxiv.org/pdf/2501.07964.pdf,true
2507.07828,Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles,"Richard Dirauf, Florian Wolz, Dario Zanca, Björn Eskofier","Content-based puzzle solvers have been extensively studied, demonstrating significant progress in computational techniques. However, their evaluation often lacks realistic challenges crucial for real-world applications, such as the reassembly of fragmented artefacts or shredded documents. In this work, we investigate the robustness of State-Of-The-Art content-based puzzle solvers introducing three types of jigsaw puzzle corruptions: missing pieces, eroded edges, and eroded contents. Evaluating both heuristic and deep learning-based solvers, we analyse their ability to handle these corruptions and identify key limitations. Our results show that solvers developed for standard puzzles have a rapid decline in performance if more pieces are corrupted. However, deep learning models can significantly improve their robustness through fine-tuning with augmented data. Notably, the advanced Positional Diffusion model adapts particularly well, outperforming its competitors in most experiments. Based on our findings, we highlight promising research directions for enhancing the automated reconstruction of real-world artefacts.","Розв'язувачі головоломок на основі вмісту широко вивчаються, демонструючи значний прогрес в обчислювальних технологіях. Однак, при їх оцінці часто не враховуються реалістичні виклики, що мають вирішальне значення для реальних застосувань, такі як відновлення фрагментованих артефактів або подрібнених документів. У цій роботі ми досліджуємо надійність сучасних контент-орієнтованих розв'язувачів головоломок, використовуючи три типи пошкоджень пазлів: відсутні шматочки, розмиті краї та розмитий вміст. Оцінюючи як евристичні, так і засновані на глибокому навчанні розв'язувачі, ми проаналізували їхню здатність справлятися з цими пошкодженнями та визначили ключові обмеження. Наші результати показують, що розв'язувачі, розроблені для стандартних головоломок, мають швидке зниження продуктивності, якщо більше частин пошкоджено. Однак моделі глибокого навчання можуть значно підвищити свою надійність завдяки точному налаштуванню за допомогою доповнених даних. Зокрема, просунута модель позиційної дифузії адаптується особливо добре, перевершуючи своїх конкурентів у більшості експериментів. На основі отриманих результатів ми виділяємо перспективні напрямки досліджень для покращення автоматизованої реконструкції реальних артефактів.",145,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07828,https://arxiv.org/pdf/2507.07828.pdf,true
2507.07847,From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems,"Youngjoon Jang, Seongtae Hong, Junyoung Son, Sungjin Park, Chanjun Park, Heuiseok Lim","Retrieval-Augmented Generation (RAG) has emerged as a crucial framework in natural language processing (NLP), improving factual consistency and reducing hallucinations by integrating external document retrieval with large language models (LLMs). However, the effectiveness of RAG is often hindered by coreferential complexity in retrieved documents, introducing ambiguity that disrupts in-context learning. In this study, we systematically investigate how entity coreference affects both document retrieval and generative performance in RAG-based systems, focusing on retrieval relevance, contextual understanding, and overall response quality. We demonstrate that coreference resolution enhances retrieval effectiveness and improves question-answering (QA) performance. Through comparative analysis of different pooling strategies in retrieval tasks, we find that mean pooling demonstrates superior context capturing ability after applying coreference resolution. In QA tasks, we discover that smaller models benefit more from the disambiguation process, likely due to their limited inherent capacity for handling referential ambiguity. With these findings, this study aims to provide a deeper understanding of the challenges posed by coreferential complexity in RAG, providing guidance for improving retrieval and generation in knowledge-intensive AI applications.","Генерація, доповнена пошуком (Retrieval-Augmented Generation, RAG), стала важливою основою в обробці природної мови (NLP), покращуючи узгодженість фактів і зменшуючи галюцинації шляхом інтеграції зовнішнього пошуку документів з великими мовними моделями (LLMs). Однак ефективності RAG часто перешкоджає складність референтних зв'язків у знайдених документах, що вносить неоднозначність, яка порушує навчання в контексті. У цьому дослідженні ми систематично вивчаємо, як кореферентність об'єктів впливає як на пошук документів, так і на продуктивність генерації в системах на основі RAG, зосереджуючись на релевантності пошуку, контекстному розумінні та загальній якості відповідей. Ми демонструємо, що розв'язання основних посилань підвищує ефективність пошуку та покращує якість відповідей на запитання (QA). За допомогою порівняльного аналізу різних стратегій об'єднання в пошукових задачах ми виявили, що середнє об'єднання демонструє кращу здатність до захоплення контексту після застосування методу розпізнавання посилань. У завданнях контролю якості ми виявили, що менші моделі отримують більше користі від процесу розпізнавання, ймовірно, через їхню обмежену здатність обробляти неоднозначність посилань. Завдяки цим висновкам це дослідження має на меті забезпечити глибше розуміння проблем, пов'язаних зі складністю кореферентних зв'язків у RAG, та надати рекомендації щодо покращення пошуку та генерації у наукомістких додатках ШІ.",172,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07847,https://arxiv.org/pdf/2507.07847.pdf,true
2507.07871,Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking,"Toluwani Aremu, Noor Hussein, Munachiso Nwadike, Samuele Poppi, Jie Zhang, Karthik Nandakumar, Neil Gong, Nils Lukas","Watermarking offers a promising solution for GenAI providers to establish the provenance of their generated content. A watermark is a hidden signal embedded in the generated content, whose presence can later be verified using a secret watermarking key. A threat to GenAI providers are \emph{watermark stealing} attacks, where users forge a watermark into content that was \emph{not} generated by the provider's models without access to the secret key, e.g., to falsely accuse the provider. Stealing attacks collect \emph{harmless} watermarked samples from the provider's model and aim to maximize the expected success rate of generating \emph{harmful} watermarked samples. Our work focuses on mitigating stealing attacks while treating the underlying watermark as a black-box. Our contributions are: (i) Proposing a multi-key extension to mitigate stealing attacks that can be applied post-hoc to any watermarking method across any modality. (ii) We provide theoretical guarantees and demonstrate empirically that our method makes forging substantially less effective across multiple datasets, and (iii) we formally define the threat of watermark forging as the task of generating harmful, watermarked content and model this threat via security games.","Нанесення водяних знаків є перспективним рішенням для провайдерів GenAI для встановлення походження створеного ними контенту. Водяний знак - це прихований сигнал, вбудований у створений контент, наявність якого згодом можна перевірити за допомогою секретного ключа водяного знаку. Загрозою для провайдерів GenAI є атаки \emph{крадіжка водяних знаків}, коли користувачі підробляють водяні знаки у контенті, який не був \emph{згенерований моделями провайдера без доступу до секретного ключа, наприклад, щоб неправдиво звинуватити провайдера. Атаки викрадення збирають \emph{нешкідливі} зразки з водяними знаками з моделі провайдера і мають на меті максимізувати очікуваний відсоток успішності генерації \emph{шкідливих} зразків з водяними знаками. Наша робота зосереджена на запобіганні атакам крадіжки, розглядаючи базовий водяний знак як ""чорний ящик"". Наш внесок полягає у наступному: (i) Запропоновано багатоключове розширення для протидії атакам крадіжки, яке може бути застосовано постфактум до будь-якого методу нанесення водяних знаків у будь-якій модальності. (ii) Ми надали теоретичні гарантії та емпірично продемонстрували, що наш метод робить підробку значно менш ефективною для багатьох наборів даних, і (iii) ми формально визначили загрозу підробки водяних знаків як завдання генерування шкідливого контенту з водяними знаками та змоделювали цю загрозу за допомогою ігор з безпеки.",180,Cryptography and Security (cs.CR),https://arxiv.org/abs/2507.07871,https://arxiv.org/pdf/2507.07871.pdf,true
2507.07885,UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs,"Ashe Neth, Sawinder kaur, Mohammad Nur Hossain Khan, Subrata Biswas, Asif Salekin, Bashima Islam","Existing pruning methods are typically applied during training or compile time and often rely on structured sparsity. While compatible with low-power microcontrollers (MCUs), structured pruning underutilizes the opportunity for fine-grained efficiency on devices without SIMD support or parallel compute. To address these limitations, we introduce UnIT (Unstructured Inference-Time pruning), a lightweight method that dynamically identifies and skips unnecessary multiply-accumulate (MAC) operations during inference, guided by input-specific activation patterns. Unlike structured pruning, UnIT embraces irregular sparsity and does not require retraining or hardware specialization. It transforms pruning decisions into lightweight comparisons, replacing multiplications with threshold checks and approximated divisions. UnIT further optimizes compute by reusing threshold computations across multiple connections and applying layer- and group-specific pruning sensitivity. We present three fast, hardware-friendly division approximations tailored to the capabilities of common embedded platforms. Demonstrated on the MSP430 microcontroller, UnIT achieves 11.02% to 82.03% MAC reduction, 27.30% to 84.19% faster inference, and 27.33% to 84.38% lower energy consumption compared to training-time pruned models, while maintaining accuracy with 0.48-7%. Under domain shift, UnIT matches or exceeds the accuracy of retrained models while requiring significantly fewer MACs. These results establish unstructured inference-time pruning as a viable and practical solution for efficient, retraining-free deployment of deep neural networks on MCUs.","Існуючі методи обрізання зазвичай застосовуються під час навчання або компіляції і часто покладаються на структуровану розрідженість. Хоча вони сумісні з малопотужними мікроконтролерами (MCU), структуроване обрізання недостатньо використовує можливості дрібнозернистої ефективності на пристроях без підтримки SIMD або паралельних обчислень. Для усунення цих обмежень ми представляємо UnIT (Unstructured Inference-Time pruning) - полегшений метод, який динамічно визначає і пропускає непотрібні операції множення-акумуляції (MAC) під час виведення, керуючись специфічними для входу шаблонами активації. На відміну від структурованого обрізання, UnIT охоплює нерегулярну розрідженість і не вимагає перенавчання або апаратної спеціалізації. Він перетворює рішення про обрізання на легкі порівняння, замінюючи множення пороговими перевірками та наближеним діленням. UnIT ще більше оптимізує обчислення, повторно використовуючи порогові обчислення для декількох з'єднань і застосовуючи чутливість до відсікання, специфічну для шарів і груп. Ми представляємо три швидкі, дружні до апаратного забезпечення наближені способи ділення, адаптовані до можливостей поширених вбудованих платформ. Продемонстрований на мікроконтролері MSP430, UnIT досягає зниження середньоквадратичного відхилення від 11,02% до 82,03%, прискорення виведення на 27,30%-84,19% та зниження енергоспоживання на 27,33%-84,38% порівняно з моделями, що обрізаються за час навчання, при збереженні точності на рівні 0,48-7%. При зміщенні домену UnIT досягає або перевищує точність перенавчених моделей, вимагаючи при цьому значно менших MAC. Ці результати свідчать про те, що неструктуроване обрізання за часом виведення є життєздатним і практичним рішенням для ефективного розгортання глибоких нейронних мереж на MCU без перенавчання.",204,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07885,https://arxiv.org/pdf/2507.07885.pdf,true
2507.07906,Agentic Retrieval of Topics and Insights from Earnings Calls,"Anant Gupta, Rajarshi Bhowmik, Geoffrey Gunow","Tracking the strategic focus of companies through topics in their earnings calls is a key task in financial analysis. However, as industries evolve, traditional topic modeling techniques struggle to dynamically capture emerging topics and their relationships. In this work, we propose an LLM-agent driven approach to discover and retrieve emerging topics from quarterly earnings calls. We propose an LLM-agent to extract topics from documents, structure them into a hierarchical ontology, and establish relationships between new and existing topics through a topic ontology. We demonstrate the use of extracted topics to infer company-level insights and emerging trends over time. We evaluate our approach by measuring ontology coherence, topic evolution accuracy, and its ability to surface emerging financial trends.","Відстеження стратегічного фокусу компаній через теми їхніх звітів про прибутки є ключовим завданням фінансового аналізу. Однак, оскільки галузі розвиваються, традиційні методи моделювання тем намагаються динамічно фіксувати нові теми та їхні взаємозв'язки. У цій роботі ми пропонуємо підхід, керований LLM-агентами, для виявлення та вилучення нових тем із щоквартальних дзвінків про прибутки. Ми пропонуємо LLM-агент для вилучення тем з документів, структурування їх в ієрархічну онтологію та встановлення взаємозв'язків між новими та існуючими темами за допомогою онтології тем. Ми продемонструємо використання витягнутих тем для отримання інсайтів на рівні компанії та нових тенденцій з плином часу. Ми оцінюємо наш підхід, вимірюючи узгодженість онтології, точність еволюції тем та її здатність виявляти нові фінансові тенденції.",117,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07906,https://arxiv.org/pdf/2507.07906.pdf,true
2507.07910,DTECT: Dynamic Topic Explorer & Context Tracker,"Suman Adhya, Debarshi Kumar Sanyal","The explosive growth of textual data over time presents a significant challenge in uncovering evolving themes and trends. Existing dynamic topic modeling techniques, while powerful, often exist in fragmented pipelines that lack robust support for interpretation and user-friendly exploration. We introduce DTECT (Dynamic Topic Explorer & Context Tracker), an end-to-end system that bridges the gap between raw textual data and meaningful temporal insights. DTECT provides a unified workflow that supports data preprocessing, multiple model architectures, and dedicated evaluation metrics to analyze the topic quality of temporal topic models. It significantly enhances interpretability by introducing LLM-driven automatic topic labeling, trend analysis via temporally salient words, interactive visualizations with document-level summarization, and a natural language chat interface for intuitive data querying. By integrating these features into a single, cohesive platform, DTECT empowers users to more effectively track and understand thematic dynamics. DTECT is open-source and available at .","Вибухове зростання обсягу текстових даних у часі створює значні труднощі у виявленні тем і тенденцій, що еволюціонують. Існуючі методи динамічного моделювання тем, хоча й потужні, часто існують у вигляді фрагментарних конвеєрів, яким бракує надійної підтримки для інтерпретації та зручного для користувача дослідження. Ми представляємо DTECT (Dynamic Topic Explorer & Context Tracker) - наскрізну систему, яка заповнює прогалину між сирими текстовими даними та змістовними часовими інсайтами. DTECT забезпечує уніфікований робочий процес, який підтримує попередню обробку даних, кілька архітектур моделей і спеціальні метрики оцінки для аналізу якості тем темних моделей. Він значно покращує інтерпретованість завдяки автоматичному маркуванню тем на основі LLM, аналізу тенденцій за допомогою часових слів, інтерактивним візуалізаціям з узагальненням на рівні документа та інтерфейсу чату природною мовою для інтуїтивно зрозумілого запиту даних. Інтегруючи ці функції в єдину, цілісну платформу, DTECT дає користувачам можливість ефективніше відстежувати і розуміти тематичну динаміку. DTECT має відкритий вихідний код і доступний за адресою .",146,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07910,https://arxiv.org/pdf/2507.07910.pdf,true
2507.07929,Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and Identification Strategies for Laboratory Mice,"Juan Pablo Oberhauser, Daniel Grzenda","Continuous, automated monitoring of laboratory mice enables more accurate data collection and improves animal welfare through real-time insights. Researchers can achieve a more dynamic and clinically relevant characterization of disease progression and therapeutic effects by integrating behavioral and physiological monitoring in the home cage. However, providing individual mouse metrics is difficult because of their housing density, similar appearances, high mobility, and frequent interactions. To address these challenges, we develop a real-time identification (ID) algorithm that accurately assigns ID predictions to mice wearing custom ear tags in digital home cages monitored by cameras. Our pipeline consists of three parts: (1) a custom multiple object tracker (MouseTracks) that combines appearance and motion cues from mice; (2) a transformer-based ID classifier (Mouseformer); and (3) a tracklet associator linear program to assign final ID predictions to tracklets (MouseMap). Our models assign an animal ID based on custom ear tags at 30 frames per second with 24/7 cage coverage. We show that our custom tracking and ID pipeline improves tracking efficiency and lowers ID switches across mouse strains and various environmental factors compared to current mouse tracking methods.","Безперервний автоматизований моніторинг лабораторних мишей дозволяє збирати точніші дані та покращує добробут тварин завдяки інформації в режимі реального часу. Дослідники можуть отримати більш динамічну і клінічно релевантну характеристику прогресування хвороби і терапевтичних ефектів, інтегруючи поведінковий і фізіологічний моніторинг в домашній клітці. Однак, отримання індивідуальних показників мишей є складним завданням через щільність їхнього розміщення, схожий зовнішній вигляд, високу рухливість та часті взаємодії. Щоб вирішити ці проблеми, ми розробляємо алгоритм ідентифікації в реальному часі, який точно призначає прогнози ідентифікації мишам, що носять спеціальні вушні мітки в цифрових домашніх клітках, які контролюються камерами. Наш конвеєр складається з трьох частин: (1) спеціального трекера для відстеження декількох об'єктів (MouseTracks), який поєднує зовнішність і сигнали руху мишей; (2) класифікатора ідентифікації на основі трансформатора (Mouseformer); і (3) лінійної програми-асоціатора треклерів для присвоєння остаточних прогнозів ідентифікації трекетам (MouseMap). Наші моделі визначають ідентифікатор тварини на основі спеціальних вушних бирок зі швидкістю 30 кадрів на секунду при цілодобовому спостереженні за кліткою. Ми показали, що наш власний конвеєр відстеження та ідентифікації підвищує ефективність відстеження та зменшує кількість перемикань ідентифікаторів між штамами мишей та різними факторами навколишнього середовища порівняно з поточними методами відстеження мишей.",183,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07929,https://arxiv.org/pdf/2507.07929.pdf,true
2507.07930,Probing Experts' Perspectives on AI-Assisted Public Speaking Training,"Nesrine Fourati, Alisa Barkar, Marion Dragée, Liv Danthon-Lefebvre, Mathieu Chollet","Background: Public speaking is a vital professional skill, yet it remains a source of significant anxiety for many individuals. Traditional training relies heavily on expert coaching, but recent advances in AI has led to novel types of commercial automated public speaking feedback tools. However, most research has focused on prototypes rather than commercial applications, and little is known about how public speaking experts perceive these tools. Objectives: This study aims to evaluate expert opinions on the efficacy and design of commercial AI-based public speaking training tools and to propose guidelines for their improvement. Methods: The research involved 16 semi-structured interviews and 2 focus groups with public speaking experts. Participants discussed their views on current commercial tools, their potential integration into traditional coaching, and suggestions for enhancing these systems. Results and Conclusions: Experts acknowledged the value of AI tools in handling repetitive, technical aspects of training, allowing coaches to focus on higher-level skills. However they found key issues in current tools, emphasising the need for personalised, understandable, carefully selected feedback and clear instructional design. Overall, they supported a hybrid model combining traditional coaching with AI-supported exercises.","Передумови: Ораторське мистецтво є життєво важливою професійною навичкою, проте для багатьох людей воно залишається джерелом значного занепокоєння. Традиційне навчання значною мірою спирається на коучинг експертів, але нещодавні досягнення в галузі штучного інтелекту призвели до появи нових типів комерційних автоматизованих інструментів зворотного зв'язку для публічних виступів. Однак більшість досліджень зосереджені на прототипах, а не на комерційному застосуванні, і мало що відомо про те, як фахівці з ораторського мистецтва сприймають ці інструменти. Цілі: Це дослідження має на меті оцінити думки експертів щодо ефективності та дизайну комерційних інструментів для навчання ораторському мистецтву на основі штучного інтелекту та запропонувати рекомендації щодо їхнього вдосконалення. Методи: Дослідження включало 16 напівструктурованих інтерв'ю та 2 фокус-групи з експертами з ораторського мистецтва. Учасники обговорили свої погляди на сучасні комерційні інструменти, їхню потенційну інтеграцію в традиційний коучинг та пропозиції щодо вдосконалення цих систем. Результати та висновки: Експерти визнали цінність інструментів штучного інтелекту в роботі з повторюваними технічними аспектами навчання, що дозволяє тренерам зосередитися на навичках вищого рівня. Однак вони виявили ключові проблеми в існуючих інструментах, наголосивши на необхідності персоналізованого, зрозумілого, ретельно підібраного зворотного зв'язку та чіткого навчального дизайну. Загалом, вони підтримали гібридну модель, що поєднує традиційний коучинг із вправами з підтримкою штучного інтелекту.",185,Human-Computer Interaction (cs.HC),https://arxiv.org/abs/2507.07930,https://arxiv.org/pdf/2507.07930.pdf,true
2507.07947,Low Resource Reconstruction Attacks Through Benign Prompts,"Sol Yarkoni, Roi Livni","The recent advances in generative models such as diffusion models have raised several risks and concerns related to privacy, copyright infringements and data stewardship. To better understand and control the risks, various researchers have created techniques, experiments and attacks that reconstruct images, or part of images, from the training set. While these techniques already establish that data from the training set can be reconstructed, they often rely on high-resources, excess to the training set as well as well-engineered and designed prompts. In this work, we devise a new attack that requires low resources, assumes little to no access to the actual training set, and identifies, seemingly, benign prompts that lead to potentially-risky image reconstruction. This highlights the risk that images might even be reconstructed by an uninformed user and unintentionally. For example, we identified that, with regard to one existing model, the prompt ``blue Unisex T-Shirt'' can generate the face of a real-life human model. Our method builds on an intuition from previous works which leverages domain knowledge and identifies a fundamental vulnerability that stems from the use of scraped data from e-commerce platforms, where templated layouts and images are tied to pattern-like prompts.","Нещодавні досягнення в генеративних моделях, таких як дифузійні моделі, викликали низку ризиків і занепокоєнь, пов'язаних з конфіденційністю, порушенням авторських прав і управлінням даними. Щоб краще зрозуміти і контролювати ризики, різні дослідники створили методи, експерименти і атаки, які реконструюють зображення або частину зображень з навчального набору. Хоча ці методи вже встановлюють, що дані з навчального набору можуть бути відновлені, вони часто покладаються на високі ресурси, надлишковість навчального набору, а також на добре продумані та розроблені підказки. У цій роботі ми розробляємо нову атаку, яка вимагає невеликих ресурсів, майже не має доступу до фактичного навчального набору і виявляє, здавалося б, безпечні підказки, які призводять до потенційно ризикованої реконструкції зображень. Це підкреслює ризик того, що зображення можуть бути реконструйовані навіть необізнаним користувачем і ненавмисно. Наприклад, ми виявили, що для однієї з існуючих моделей підказка ""блакитна футболка унісекс"" може згенерувати обличчя реальної людської моделі. Наш метод ґрунтується на інтуїції з попередніх робіт, яка використовує знання предметної області та виявляє фундаментальну вразливість, що виникає внаслідок використання вилучених даних з платформ електронної комерції, де шаблонні макети та зображення прив'язуються до шаблонних підказок.",194,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07947,https://arxiv.org/pdf/2507.07947.pdf,true
2507.07957,MIRIX: Multi-Agent Memory System for LLM-Based Agents,"Yu Wang, Xi Chen","Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy.","Хоча можливості пам'яті ШІ-агентів привертають все більше уваги, існуючі рішення залишаються принципово обмеженими. Більшість з них покладаються на плоскі, вузькоспеціалізовані компоненти пам'яті, що обмежує їхню здатність персоналізувати, абстрагувати та надійно відтворювати специфічну для користувача інформацію з плином часу. З цією метою ми представляємо MIRIX - модульну мультиагентну систему пам'яті, яка переосмислює майбутнє пам'яті штучного інтелекту, вирішуючи найважливішу проблему в цій галузі: надання мовним моделям можливості по-справжньому запам'ятовувати. На відміну від попередніх підходів, MIRIX виходить за межі тексту, щоб охопити багатий візуальний та мультимодальний досвід, що робить пам'ять дійсно корисною в реальних сценаріях. MIRIX складається з шести різних, ретельно структурованих типів пам'яті: Основної, Епізодичної, Семантичної, Процедурної, Ресурсної пам'яті та Сховища знань, поєднаних з мультиагентною платформою, яка динамічно контролює та координує оновлення та пошук. Такий дизайн дозволяє агентам зберігати, аналізувати та точно отримувати різноманітні довгострокові дані користувачів у великих масштабах. Ми перевіряємо MIRIX у двох складних умовах. По-перше, в ScreenshotVQA, складному мультимодальному тесті, що складається з майже 20 000 знімків екрану комп'ютера з високою роздільною здатністю, що вимагає глибокого розуміння контексту і де не може бути застосована жодна з існуючих систем пам'яті, MIRIX досягає на 35% вищої точності, ніж базова лінія RAG, при цьому знижуючи вимоги до зберігання на 99,9%. По-друге, на LOCOMO, тесті розмовної мови з одномодальним введенням тексту, MIRIX досягає найсучаснішої продуктивності на рівні 85,4%, що значно перевищує існуючі базові показники. Ці результати показують, що MIRIX встановлює новий стандарт продуктивності для агентів LLM з розширеною пам'яттю. Щоб користувачі могли випробувати нашу систему пам'яті, ми надаємо пакетний додаток на базі MIRIX. Він відстежує екран в режимі реального часу, створює персоналізовану базу пам'яті, пропонує інтуїтивно зрозумілу візуалізацію та безпечне локальне сховище для забезпечення конфіденційності.",259,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07957,https://arxiv.org/pdf/2507.07957.pdf,true
2507.07966,Scaling RL to Long Videos,"Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov, Jan Kautz, Xiaojuan Qi, Sifei Liu, Hongxu Yin, Yao Lu, Song Han","We introduce a full-stack framework that scales up reasoning in vision-language models (VLMs) to long videos, leveraging reinforcement learning. We address the unique challenges of long video reasoning by integrating three critical components: (1) a large-scale dataset, LongVideo-Reason, comprising 52K long video QA pairs with high-quality reasoning annotations across diverse domains such as sports, games, and vlogs; (2) a two-stage training pipeline that extends VLMs with chain-of-thought supervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a training infrastructure for long video RL, named Multi-modal Reinforcement Sequence Parallelism (MR-SP), which incorporates sequence parallelism and a vLLM-based engine tailored for long video, using cached video embeddings for efficient rollout and prefilling. In experiments, LongVILA-R1-7B achieves strong performance on long video QA benchmarks such as VideoMME. It also outperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporal reasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning on our LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to 2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistent performance gains as the number of input video frames scales. LongVILA-R1 marks a firm step towards long video reasoning in VLMs. In addition, we release our training system for public availability that supports RL training on various modalities (video, text, and audio), various models (VILA and Qwen series), and even image and video generation models. On a single A100 node (8 GPUs), it supports RL training on hour-long videos (e.g., 3,600 frames / around 256k tokens).","Ми представляємо повностековий фреймворк, який масштабує міркування в моделях мови зору (VLM) до довгих відео, використовуючи навчання з підкріпленням. Ми вирішуємо унікальні проблеми, пов'язані з міркуваннями на основі довгих відео, інтегруючи три найважливіші компоненти: (1) великомасштабний набір даних LongVideo-Reason, що складається з 52 тис. пар довгих відео з високоякісними анотаціями міркувань у різних сферах, таких як спорт, ігри та відеоблоги; (2) двоетапний навчальний конвеєр, який розширює VLM за допомогою точного налаштування під контролем ланцюжка думок (CoT-SFT) та навчання з підкріпленням (RL); і (3) навчальна інфраструктура для навчання з підкріпленням для довгого відео, названа Мультимодальний паралелізм послідовності підкріплення (MR-SP), яка включає в себе паралелізм послідовності і рушій на основі vLLM, пристосований для довгого відео, з використанням кешованих відео-вставок для ефективного розгортання і попереднього заповнення. В експериментах LongVILA-R1-7B демонструє високу продуктивність у таких тестах контролю якості довгого відео, як VideoMME. Він також перевершує Video-R1-7B і навіть зрівнявся з Gemini-1.5-Pro в часових міркуваннях, міркуваннях цілей і завдань, просторових міркуваннях і міркуваннях сюжету в нашому бенчмарку LongVideo-Reason-eval. Примітно, що наша система MR-SP досягає прискорення до 2,1 разів на тренуваннях з довгого відео RL. LongVILA-R1 демонструє послідовне зростання продуктивності зі збільшенням кількості вхідних відеокадрів. LongVILA-R1 знаменує собою впевнений крок до довгих відео-міркувань у VLM. Крім того, ми випускаємо у відкритий доступ нашу навчальну систему, яка підтримує навчання ШНМ на різних модальностях (відео, текст і аудіо), різних моделях (серії VILA і Qwen), і навіть на моделях генерації зображень і відео. На одному вузлі A100 (8 графічних процесорів) вона підтримує навчання RL на годинних відео (наприклад, 3600 кадрів / близько 256 тис. токенів).",241,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07966,https://arxiv.org/pdf/2507.07966.pdf,true
2507.07969,Reinforcement Learning with Action Chunking,"Qiyang Li, Zhiyuan Zhou, Sergey Levine","We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks.","Ми представляємо Q-чанкування - простий, але ефективний рецепт покращення алгоритмів навчання з підкріпленням (RL) для довготривалих завдань з рідкісною винагородою. Наш рецепт розроблений для навчання з офлайну в онлайн, де метою є використання попереднього набору даних з офлайну, щоб максимізувати ефективність навчання на вибірці в онлайні. Ефективна розвідка і навчання на вибірці залишаються головними викликами в цьому середовищі, оскільки не очевидно, як слід використовувати офлайн-дані, щоб отримати хорошу дослідницьку політику. Наше ключове розуміння полягає в тому, що метод ""chunking"" (розбиття дій на частини), популярний в імітаційному навчанні, де прогнозуються послідовності майбутніх дій, а не одна дія на кожному часовому кроці, може бути застосований до методів машинного навчання, заснованих на часовій різниці (TD), для пом'якшення проблеми дослідження. Q-чанкінг застосовує фрагментацію дій шляхом безпосереднього запуску RL у ""фрагментованому"" просторі дій, що дозволяє агенту (1) використовувати узгоджену в часі поведінку з офлайн-даних для більш ефективного дослідження в онлайні та (2) використовувати незміщені резервні копії $n$-кроків для більш стабільного та ефективного навчання на основі часової різниці. Наші експериментальні результати демонструють, що Q-чанкінг демонструє високу продуктивність в автономному режимі та ефективність онлайн-вибірки, перевершуючи попередні найкращі методи переходу з автономного режиму в онлайн у низці задач маніпулювання з довгими горизонтами та розрідженою винагородою.",185,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07969,https://arxiv.org/pdf/2507.07969.pdf,true
2507.07981,Why is Your Language Model a Poor Implicit Reward Model?,"Noam Razin, Yong Lin, Jiarui Yao, Sanjeev Arora","Reward models are key to language model post-training and inference pipelines. Conveniently, recent work showed that every language model defines an implicit reward model (IM-RM), without requiring any architectural changes. However, such IM-RMs tend to generalize worse, especially out-of-distribution, compared to explicit reward models (EX-RMs) that apply a dedicated linear head over the hidden representations of a language model. The existence of a generalization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They can be trained using the same data, loss function, and language model, and differ only in how the reward is computed. Towards a fundamental understanding of the implicit biases underlying different reward model types, we investigate the root cause of this gap. Our main finding, backed by theory and experiments, is that IM-RMs rely more heavily on superficial token-level cues. Consequently, they often generalize worse than EX-RMs under token-level distribution shifts, as well as in-distribution. Furthermore, we provide evidence against alternative hypotheses for the generalization gap. Most notably, we challenge the intuitive claim that IM-RMs struggle in tasks where generation is harder than verification because they can operate both as a verifier and a generator. Taken together, our results highlight that seemingly minor design choices can substantially impact the generalization behavior of reward models.","Моделі винагороди є ключовими для конвеєрів пост-навчання мовної моделі та виведення. Нещодавні дослідження показали, що кожна мовна модель визначає неявну модель винагороди (IM-RM), не вимагаючи жодних архітектурних змін. Однак, такі IM-RM мають тенденцію до гіршого узагальнення, особливо поза розподілом, порівняно з явними моделями винагороди (EX-RM), які застосовують спеціальну лінійну голову над прихованими представленнями мовної моделі. Існування розриву в узагальненні викликає подив, оскільки EX-RM та IM-RM майже ідентичні. Їх можна навчати, використовуючи однакові дані, функцію втрат і мовну модель, і вони відрізняються лише тим, як обчислюється винагорода. На шляху до фундаментального розуміння неявних упереджень, що лежать в основі різних типів моделей винагороди, ми досліджуємо першопричину цього розриву. Наш основний висновок, підкріплений теорією та експериментами, полягає в тому, що IM-RM більше покладаються на поверхневі підказки на рівні токенів. Як наслідок, вони часто узагальнюють гірше, ніж EX-RM, при зміні розподілу на рівні токенів, а також при внутрішньому розподілі. Крім того, ми наводимо докази проти альтернативних гіпотез щодо розриву узагальнення. Зокрема, ми заперечуємо інтуїтивне твердження про те, що IM-RM не справляються із завданнями, де генерація складніша за верифікацію, оскільки вони можуть працювати і як верифікатор, і як генератор. Взяті разом, наші результати підкреслюють, що, здавалося б, незначний вибір дизайну може суттєво вплинути на поведінку узагальнення в моделях винагороди.",209,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07981,https://arxiv.org/pdf/2507.07981.pdf,true
2507.06795,ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining,"Seonwu Kim, Yohan Na, Kihun Kim, Hanhee Cho, Geun Lim, Mintae Kim, Seongik Park, Ki Hyun Kim, Youngsub Han, Byoung-Ki Jeon","The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative, despite their inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been previously explored as a method for domain adaptation, its utility in commercial applications remains under-examined. In this study, we validate the effectiveness of applying a DACP-based recipe across diverse foundation models and service domains. Through extensive experiments and real-world evaluations, we demonstrate that DACP-applied sLLMs achieve substantial gains in target domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.","Поява великих мовних моделей (LLM) з відкритим вихідним кодом розширила можливості для корпоративних додатків, однак багатьом організаціям все ще бракує інфраструктури для розгортання та підтримки великомасштабних моделей. Як результат, малі LLM (sLLM) стали практичною альтернативою, незважаючи на притаманні їм обмеження продуктивності. Хоча доменне адаптивне безперервне попереднє навчання (DACP) раніше досліджувалося як метод адаптації домену, його корисність у комерційних додатках залишається недостатньо вивченою. У цьому дослідженні ми перевіряємо ефективність застосування рецепту, заснованого на DACP, у різних фундаментальних моделях і сервісних доменах. За допомогою обширних експериментів і реальних оцінок ми демонструємо, що SLLM, які застосовують DACP, досягають значного підвищення продуктивності цільового домену, зберігаючи при цьому загальні можливості, пропонуючи економічно ефективне і масштабоване рішення для розгортання на рівні підприємства.",116,Computation and Language (cs.CL),https://arxiv.org/abs/2507.06795,https://arxiv.org/pdf/2507.06795.pdf,true
2507.07982,Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling,"Haoyu Wu, Diankun Wu, Tianyu He, Junliang Guo, Yang Ye, Yueqi Duan, Jiang Bian","Videos inherently represent 2D projections of a dynamic 3D world. However, our analysis suggests that video diffusion models trained solely on raw video data often fail to capture meaningful geometric-aware structure in their learned representations. To bridge this gap between video diffusion models and the underlying 3D nature of the physical world, we propose Geometry Forcing, a simple yet effective method that encourages video diffusion models to internalize latent 3D representations. Our key insight is to guide the model's intermediate representations toward geometry-aware structure by aligning them with features from a pretrained geometric foundation model. To this end, we introduce two complementary alignment objectives: Angular Alignment, which enforces directional consistency via cosine similarity, and Scale Alignment, which preserves scale-related information by regressing unnormalized geometric features from normalized diffusion representation. We evaluate Geometry Forcing on both camera view-conditioned and action-conditioned video generation tasks. Experimental results demonstrate that our method substantially improves visual quality and 3D consistency over the baseline methods. Project page: .","Відео за своєю суттю є двовимірною проекцією динамічного тривимірного світу. Однак наш аналіз показує, що моделі дифузії відео, навчені виключно на сирих відеоданих, часто не здатні вловити значущу геометричну структуру у своїх навчених репрезентаціях. Щоб подолати цей розрив між моделями дифузії відео та базовою 3D-природою фізичного світу, ми пропонуємо Geometry Forcing - простий, але ефективний метод, який заохочує моделі дифузії відео засвоювати латентні 3D-зображення. Наша основна ідея полягає в тому, щоб спрямувати проміжні представлення моделі до структури, що враховує геометрію, узгодивши їх з особливостями заздалегідь підготовленої геометричної базової моделі. З цією метою ми вводимо дві взаємодоповнюючі цілі вирівнювання: Кутове вирівнювання, яке забезпечує узгодженість напрямку за допомогою косинусної подібності, та Масштабне вирівнювання, яке зберігає інформацію, пов'язану з масштабом, шляхом регресії ненормованих геометричних об'єктів з нормалізованого представлення дифузії. Ми оцінюємо Geometry Forcing на задачах генерації відео, що залежать як від виду камери, так і від дії. Експериментальні результати демонструють, що наш метод суттєво покращує візуальну якість та 3D-когерентність порівняно з базовими методами. Сторінка проекту: .",162,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07982,https://arxiv.org/pdf/2507.07982.pdf,true
2507.07983,Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology,"Sabine Felde, Rüdiger Buchkremer, Gamal Chehab, Christian Thielscher, Jörg HW Distler, Matthias Schneider, Jutta G. Richter","Large language models (LLMs) show promise for supporting clinical decision-making in complex fields such as rheumatology. Our evaluation shows that smaller language models (SLMs), combined with retrieval-augmented generation (RAG), achieve higher diagnostic and therapeutic performance than larger models, while requiring substantially less energy and enabling cost-efficient, local deployment. These features are attractive for resource-limited healthcare. However, expert oversight remains essential, as no model consistently reached specialist-level accuracy in rheumatology.","Великі мовні моделі (ВММ) є перспективними для підтримки прийняття клінічних рішень у таких складних галузях, як ревматологія. Наша оцінка показує, що малі мовні моделі (МММ) у поєднанні з пошуково-доповненою генерацією (ПДГ) досягають вищих діагностичних і терапевтичних показників, ніж великі моделі, при цьому вимагаючи значно менше енергії і дозволяючи економічно ефективне локальне розгортання. Ці особливості є привабливими для охорони здоров'я з обмеженими ресурсами. Однак експертний нагляд залишається важливим, оскільки жодна модель не досягла стабільної точності на рівні спеціаліста в ревматології.",69,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07983,https://arxiv.org/pdf/2507.07983.pdf,true
2507.07986,EXPO: Stable Reinforcement Learning with Expressive Policies,"Perry Dong, Qiyang Li, Dorsa Sadigh, Chelsea Finn","We study the problem of training and fine-tuning expressive policies with online reinforcement learning (RL) given an offline dataset. Training expressive policy classes with online RL present a unique challenge of stable value maximization. Unlike simpler Gaussian policies commonly used in online RL, expressive policies like diffusion and flow-matching policies are parameterized by a long denoising chain, which hinders stable gradient propagation from actions to policy parameters when optimizing against some value function. Our key insight is that we can address stable value maximization by avoiding direct optimization over value with the expressive policy and instead construct an on-the-fly RL policy to maximize Q-value. We propose Expressive Policy Optimization (EXPO), a sample-efficient online RL algorithm that utilizes an on-the-fly policy to maximize value with two parameterized policies -- a larger expressive base policy trained with a stable imitation learning objective and a light-weight Gaussian edit policy that edits the actions sampled from the base policy toward a higher value distribution. The on-the-fly policy optimizes the actions from the base policy with the learned edit policy and chooses the value maximizing action from the base and edited actions for both sampling and temporal-difference (TD) backup. Our approach yields up to 2-3x improvement in sample efficiency on average over prior methods both in the setting of fine-tuning a pretrained policy given offline data and in leveraging offline data to train online.","Ми вивчаємо проблему навчання та тонкого налаштування виразних політик за допомогою онлайн-навчання з підкріпленням (НВ) на офлайн-наборі даних. Навчання класів експресивних політик за допомогою онлайн-навчання з підкріпленням представляє унікальну проблему стабільної максимізації значення. На відміну від простіших гауссівських політик, які зазвичай використовуються в онлайн-навчанні, експресивні політики, такі як дифузія та політика узгодження потоку, параметризуються довгим ланцюжком згладжування, що перешкоджає стабільному поширенню градієнта від дій до параметрів політики при оптимізації за деякою функцією цінності. Наш ключовий висновок полягає в тому, що ми можемо вирішити проблему стабільної максимізації вартості, уникаючи прямої оптимізації за вартістю за допомогою експрес-політики і натомість будуючи політику RL ""на льоту"" для максимізації Q-вартості. Ми пропонуємо оптимізацію експресивної політики (EXPO), ефективний алгоритм онлайн RL, який використовує політику ""на льоту"" для максимізації вартості за допомогою двох параметризованих політик - більшої експресивної базової політики, навченої на стабільній імітаційній меті навчання, і полегшеної гауссової політики редагування, яка редагує дії, вибрані з базової політики, у бік вищого розподілу вартості. Політика ""на льоту"" оптимізує дії з базової політики за допомогою навченої політики редагування і вибирає дію, що максимізує значення, з базової та відредагованих дій як для вибірки, так і для резервного копіювання з тимчасовою різницею (ТР). Наш підхід дає в середньому 2-3-кратне покращення ефективності вибірки порівняно з попередніми методами, як в умовах точного налаштування попередньо навченої політики на основі офлайн-даних, так і в умовах використання офлайн-даних для навчання в режимі онлайн.",229,Machine Learning (cs.LG),https://arxiv.org/abs/2507.07986,https://arxiv.org/pdf/2507.07986.pdf,true
2507.07990,Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs,"Jeongseok Hyun, Sukjun Hwang, Su Ho Han, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Joon-Young Lee, Seon Joo Kim, Minho Shim","Video large language models (LLMs) achieve strong video understanding by leveraging a large number of spatio-temporal tokens, but suffer from quadratic computational scaling with token count. To address this, we propose a training-free spatio-temporal token merging method, named STTM. Our key insight is to exploit local spatial and temporal redundancy in video data which has been overlooked in prior work. STTM first transforms each frame into multi-granular spatial tokens using a coarse-to-fine search over a quadtree structure, then performs directed pairwise merging across the temporal dimension. This decomposed merging approach outperforms existing token reduction methods across six video QA benchmarks. Notably, STTM achieves a 2$\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, and a 3$\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM is query-agnostic, allowing KV cache reuse across different questions for the same video. The project page is available at .","Великі мовні моделі відео (ВМВ) досягають хорошого розуміння відео завдяки використанню великої кількості просторово-часових токенів, але страждають від квадратичного масштабування обчислень зі збільшенням кількості токенів. Щоб вирішити цю проблему, ми пропонуємо метод об'єднання просторово-часових токенів без навчання, названий STTM. Наша основна ідея полягає у використанні локальної просторової та часової надмірності відеоданих, яку не брали до уваги в попередніх роботах. STTM спочатку перетворює кожен кадр на багатогранні просторові маркери, використовуючи грубий і точний пошук у чотиридеревній структурі, а потім виконує спрямоване попарне злиття в часовому вимірі. Цей підхід декомпонованого злиття перевершує існуючі методи зменшення кількості токенів у шести тестах якості відео. Зокрема, STTM досягає прискорення в 2$\times$ з падінням точності лише на 0.5% при бюджеті в 50% токенів, і прискорення в 3$\times$ з падінням точності лише на 2% при бюджеті в 30%. Крім того, STTM є діагностикою запитів, що дозволяє повторно використовувати кеш KV для різних запитів для одного і того ж відео. Сторінка проекту доступна за адресою .",152,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07990,https://arxiv.org/pdf/2507.07990.pdf,true
2507.07993,Multigranular Evaluation for Brain Visual Decoding,"Weihao Xia, Cengiz Oztireli","Existing evaluation protocols for brain visual decoding predominantly rely on coarse metrics that obscure inter-model differences, lack neuroscientific foundation, and fail to capture fine-grained visual distinctions. To address these limitations, we introduce BASIC, a unified, multigranular evaluation framework that jointly quantifies structural fidelity, inferential alignment, and contextual coherence between decoded and ground truth images. For the structural level, we introduce a hierarchical suite of segmentation-based metrics, including foreground, semantic, instance, and component masks, anchored in granularity-aware correspondence across mask structures. For the semantic level, we extract structured scene representations encompassing objects, attributes, and relationships using multimodal large language models, enabling detailed, scalable, and context-rich comparisons with ground-truth stimuli. We benchmark a diverse set of visual decoding methods across multiple stimulus-neuroimaging datasets within this unified evaluation framework. Together, these criteria provide a more discriminative, interpretable, and comprehensive foundation for measuring brain visual decoding methods.","Існуючі протоколи оцінки візуального декодування мозку переважно покладаються на грубі метрики, які затушовують міжмодельні відмінності, не мають нейронаукового підґрунтя і не здатні вловити дрібнозернисті візуальні відмінності. Щоб подолати ці обмеження, ми представили BASIC - уніфіковану багатогранну систему оцінювання, яка спільно оцінює структурну точність, висновок та контекстуальну узгодженість між декодованими та базовими зображеннями. Для структурного рівня ми вводимо ієрархічний набір метрик на основі сегментації, включаючи маски переднього плану, семантичні маски, маски екземплярів і маски компонентів, що базуються на відповідності між структурами масок з урахуванням гранулярності. На семантичному рівні ми виділяємо структуровані представлення сцен, що охоплюють об'єкти, атрибути та зв'язки, використовуючи мультимодальні великі мовні моделі, що дозволяє проводити детальні, масштабовані та контекстно-багаті порівняння з істинними стимулами. Ми порівнюємо різноманітний набір методів візуального декодування з різними наборами даних стимульної нейровізуалізації в рамках цієї уніфікованої системи оцінювання. Разом ці критерії забезпечують більш дискримінативну, інтерпретовану та всебічну основу для вимірювання методів візуального декодування мозку.",143,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07993,https://arxiv.org/pdf/2507.07993.pdf,true
2507.07995,Single-pass Adaptive Image Tokenization for Minimum Program Search,"Shivam Duggal, Sanghyun Byun, William T. Freeman, Antonio Torralba, Phillip Isola","According to Algorithmic Information Theory (AIT) -- Intelligent representations compress data into the shortest possible program that can reconstruct its content, exhibiting low Kolmogorov Complexity (KC). In contrast, most visual representation learning systems use fixed-length representations for all inputs, ignoring variations in complexity or familiarity. Recent adaptive tokenization methods address this by allocating variable-length representations but typically require test-time search over multiple encodings to find the most predictive one. Inspired by Kolmogorov Complexity principles, we propose a single-pass adaptive tokenizer, KARL, which predicts the appropriate number of tokens for an image in a single forward pass, halting once its approximate KC is reached. The token count serves as a proxy for the minimum description length. KARL's training procedure closely resembles the Upside-Down Reinforcement Learning paradigm, as it learns to conditionally predict token halting based on a desired reconstruction quality. KARL matches the performance of recent adaptive tokenizers while operating in a single pass. We present scaling laws for KARL, analyzing the role of encoder/decoder size, continuous vs. discrete tokenization and more. Additionally, we offer a conceptual study drawing an analogy between Adaptive Image Tokenization and Algorithmic Information Theory, examining the predicted image complexity (KC) across axes such as structure vs. noise and in- vs. out-of-distribution familiarity -- revealing alignment with human intuition.","Згідно з алгоритмічною теорією інформації (AIT) - Інтелектуальні представлення стискають дані в найкоротшу можливу програму, яка може відновити їхній вміст, демонструючи низьку складність за Колмогоровим (KC). На противагу цьому, більшість систем навчання на основі візуального представлення використовують представлення фіксованої довжини для всіх вхідних даних, ігноруючи варіації складності або знайомства з ними. Нещодавні методи адаптивної токенізації вирішують цю проблему, виділяючи представлення змінної довжини, але, як правило, вимагають тестового перебору декількох кодувань для знаходження найбільш передбачуваного. Натхненні принципами складності Колмогорова, ми пропонуємо однопрохідний адаптивний токенізатор KARL, який пророкує відповідну кількість токенів для зображення за один прохід вперед, зупиняючись, коли досягається його приблизний КК. Кількість токенів слугує проксі для мінімальної довжини опису. Процедура навчання KARL дуже нагадує парадигму перевернутого навчання з підкріпленням, оскільки вона навчається умовно передбачати зупинку токенів на основі бажаної якості реконструкції. KARL відповідає продуктивності останніх адаптивних токенізаторів, працюючи за один прохід. Ми представляємо закони масштабування для KARL, аналізуючи роль розміру кодера/декодера, безперервної та дискретної токенізації тощо. Крім того, ми пропонуємо концептуальне дослідження, яке проводить аналогію між адаптивною токенізацією зображень та алгоритмічною теорією інформації, досліджуючи прогнозовану складність зображення (KC) за такими осями, як структура проти шуму та знайомство з розподіленим і нерозподіленим зображенням - виявляючи відповідність людській інтуїції.",212,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07995,https://arxiv.org/pdf/2507.07995.pdf,true
2507.07998,PyVision: Agentic Vision with Dynamic Tooling,"Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Ming Li, Qilong Wu, Kaipeng Zhang, Chen Wei","LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning.","LLM все частіше розгортаються як агенти, системи, здатні планувати, міркувати та динамічно викликати зовнішні інструменти. Однак у візуальному міркуванні попередні підходи здебільшого залишаються обмеженими заздалегідь визначеними робочими процесами та статичними наборами інструментів. У цій доповіді ми представляємо PyVision - інтерактивну багатооборотну платформу, яка дозволяє MLLM автономно генерувати, виконувати та вдосконалювати інструменти на основі Python, пристосовані до конкретного завдання, що відкриває можливості для гнучкого та інтерпретованого розв'язання проблем. Ми розробляємо таксономію інструментів, створених за допомогою PyVision, та аналізуємо їх використання за різноманітними критеріями. У кількісному вимірі PyVision демонструє стабільний приріст продуктивності, підвищуючи GPT-4.1 на +7,8% на V* і Claude-4.0-Sonnet на +31,1% на VLMsAreBlind-mini. Ці результати вказують на ширший зсув: динамічний інструментарій дозволяє моделям не просто використовувати інструменти, але й винаходити їх, просуваючись до більш агентного візуального мислення.",127,Computation and Language (cs.CL),https://arxiv.org/abs/2507.07998,https://arxiv.org/pdf/2507.07998.pdf,true
2507.07999,Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology,"Haochen Wang, Xiangtai Li, Zilong Huang, Anran Wang, Jiacong Wang, Tao Zhang, Jiani Zheng, Sule Bai, Zijian Kang, Jiashi Feng, Zhuochen Wang, Zhaoxiang Zhang","Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically referencing visual regions, just like human ""thinking with images"". However, no benchmark exists to evaluate these capabilities holistically. To bridge this gap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a diagnostic benchmark built on three principles: (1) focused visual perception of subtle targets in complex scenes, (2) traceable evidence via bounding box evaluation, and (3) second-order reasoning to test object interactions and spatial hierarchies beyond simple object localization. Prioritizing images with dense objects, we initially sample 1K high-quality images from SA-1B, and incorporate eight LMM experts to manually annotate questions, candidate options, and answers for each image. After three stages of quality control, TreeBench consists of 405 challenging visual question-answering pairs, even the most advanced models struggle with this benchmark, where none of them reach 60% accuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR (Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to supervise localization and reasoning jointly with reinforcement learning, enabling accurate localizations and explainable reasoning pathways. Initialized from Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and TreeBench (+13.4), proving traceability is key to advancing vision-grounded reasoning. The code is available at .","Такі моделі, як OpenAI-o3, є першопрохідцями у візуальному обґрунтуванні міркувань, динамічно посилаючись на візуальні регіони, подібно до людського ""мислення образами"". Однак, не існує бенчмарку для цілісної оцінки цих можливостей. Щоб заповнити цю прогалину, ми пропонуємо TreeBench (Traceable Evidence Evaluation Benchmark) - діагностичний бенчмарк, побудований на трьох принципах: (1) сфокусоване візуальне сприйняття малопомітних цілей у складних сценах, (2) простежувані докази за допомогою оцінки граничного поля, і (3) міркування другого порядку для перевірки взаємодії об'єктів і просторових ієрархій, що виходять за рамки простої локалізації об'єкта. Надаючи пріоритет зображенням з щільними об'єктами, ми спочатку вибираємо 1 тис. високоякісних зображень з SA-1B і залучаємо вісім експертів LMM для ручного коментування запитань, варіантів відповідей і відповідей для кожного зображення. Після трьох етапів контролю якості TreeBench складається з 405 складних візуальних пар запитань-відповідей, навіть найдосконаліші моделі борються з цим тестом, де жодна з них не досягає 60% точності, наприклад, OpenAI-o3 має лише 54,87 балів. Крім того, ми представляємо TreeVGR (Traceable Evidence Enhanced Visual Grounded Reasoning) - навчальну парадигму для контролю локалізації та міркувань спільно з навчанням з підкріпленням, що забезпечує точну локалізацію та пояснювані шляхи міркувань. Ініціалізований з Qwen2.5-VL-7B, він покращує V* Bench (+16.8), MME-RealWorld (+12.6) і TreeBench (+13.4), доводячи, що простежуваність є ключовим фактором для розвитку міркувань, заснованих на візуальному сприйнятті. Код доступний за адресою .",197,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.07999,https://arxiv.org/pdf/2507.07999.pdf,true
2406.14514,Solving a Stackelberg Game on Transportation Networks in a Dynamic Crime Scenario: A Mixed Approach on Multi-Layer Networks,"Sukanya Samanta, Kei Kimura, Makoto Yokoo","Interdicting a criminal with limited police resources is a challenging task as the criminal changes location over time. The size of the large transportation network further adds to the difficulty of this scenario. To tackle this issue, we consider the concept of a layered graph. At each time stamp, we create a copy of the entire transportation network to track the possible movements of both players, the attacker and the defenders. We consider a Stackelberg game in a dynamic crime scenario where the attacker changes location over time while the defenders attempt to interdict the attacker on his escape route. Given a set of defender strategies, the optimal attacker strategy is determined by applying Dijkstra's algorithm on the layered networks. Here, the attacker aims to minimize while the defenders aim to maximize the probability of interdiction. We develop an approximation algorithm on the layered networks to find near-optimal strategy for defenders. The efficacy of the developed approach is compared with the adopted MILP approach. We compare the results in terms of computational time and solution quality. The quality of the results demonstrates the need for the developed approach, as it effectively solves the complex problem within a short amount of time.","Затримання злочинця з обмеженими ресурсами поліції є складним завданням, оскільки злочинець з часом змінює своє місцезнаходження. Розмір великої транспортної мережі ще більше ускладнює цей сценарій. Щоб вирішити цю проблему, ми розглянемо концепцію шаруватого графа. У кожен момент часу ми створюємо копію всієї транспортної мережі, щоб відстежити можливі переміщення обох гравців, нападника і захисників. Ми розглянемо гру Стакельберга в динамічному сценарії злочину, де зловмисник змінює своє місцезнаходження з плином часу, а захисники намагаються перехопити нападника на шляху втечі. Маючи набір стратегій захисників, оптимальна стратегія зловмисника визначається шляхом застосування алгоритму Дейкстри для шаруватих мереж. Тут зловмисник прагне мінімізувати, а захисники - максимізувати ймовірність перехоплення. Ми розробляємо алгоритм апроксимації на шаруватих мережах для знаходження наближеної до оптимальної стратегії для захисників. Ефективність розробленого підходу порівнюється з прийнятим підходом MILP. Ми порівнюємо результати з точки зору часу обчислень та якості розв'язку. Якість результатів демонструє необхідність розробленого підходу, оскільки він ефективно розв'язує складну задачу за короткий проміжок часу.",201,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2406.14514,https://arxiv.org/pdf/2406.14514.pdf,true
2410.13973,MarineFormer: A Spatio-Temporal Attention Model for USV Navigation in Dynamic Marine Environments,"Ehsan Kazemi, Dechen Gao, Iman Soltani","Autonomous navigation in marine environments can be extremely challenging, especially in the presence of spatially varying flow disturbances and dynamic and static obstacles. In this work, we demonstrate that incorporating local flow field measurements fundamentally alters the nature of the problem, transforming otherwise unsolvable navigation scenarios into tractable ones. However, the mere availability of flow data is not sufficient; it must be effectively fused with conventional sensory inputs such as ego-state and obstacle states. To this end, we propose \textbf{MarineFormer}, a Transformer-based policy architecture that integrates two complementary attention mechanisms: spatial attention for sensor fusion, and temporal attention for capturing environmental dynamics. MarineFormer is trained end-to-end via reinforcement learning in a 2D simulated environment with realistic flow features and obstacles. Extensive evaluations against classical and state-of-the-art baselines show that our approach improves episode completion success rate by nearly 23\% while reducing path length. Ablation studies further highlight the critical role of flow measurements and the effectiveness of our proposed architecture in leveraging them.","Автономна навігація в морському середовищі може бути надзвичайно складною, особливо за наявності просторово змінних збурень течії та динамічних і статичних перешкод. У цій роботі ми демонструємо, що включення локальних вимірювань поля течії докорінно змінює природу проблеми, перетворюючи нерозв'язні в інший спосіб навігаційні сценарії на такі, що піддаються вирішенню. Однак, простої наявності даних про течію недостатньо; вони повинні бути ефективно поєднані з традиційними сенсорними даними, такими як его-стан і стан перешкод. З цією метою ми пропонуємо \textbf{MarineFormer}, архітектуру політики на основі трансформерів, яка інтегрує два взаємодоповнюючих механізми уваги: просторову увагу для злиття сенсорів і часову увагу для фіксації динаміки навколишнього середовища. MarineFormer навчається наскрізно за допомогою навчання з підкріпленням у 2D-симульованому середовищі з реалістичними характеристиками потоку та перешкодами. Широкі оцінки порівняно з класичними та найсучаснішими базовими лініями показують, що наш підхід покращує показник успішності завершення епізоду майже на 23\%, зменшуючи при цьому довжину шляху. Дослідження абляції ще раз підкреслюють критичну роль вимірювань потоку та ефективність запропонованої нами архітектури для їх використання.",163,Robotics (cs.RO),https://arxiv.org/abs/2410.13973,https://arxiv.org/pdf/2410.13973.pdf,true
2409.08936,SimSUM: Simulated Benchmark with Structured and Unstructured Medical Records,"Paloma Rabaey, Stefan Heytens, Thomas Demeester","Clinical information extraction, which involves structuring clinical concepts from unstructured medical text, remains a challenging problem that could benefit from the inclusion of tabular background information available in electronic health records. Existing open-source datasets lack explicit links between structured features and clinical concepts in the text, motivating the need for a new research dataset. We introduce SimSUM, a benchmark dataset of 10,000 simulated patient records that link unstructured clinical notes with structured background variables. Each record simulates a patient encounter in the domain of respiratory diseases and includes tabular data (e.g., symptoms, diagnoses, underlying conditions) generated from a Bayesian network whose structure and parameters are defined by domain experts. A large language model (GPT-4o) is prompted to generate a clinical note describing the encounter, including symptoms and relevant context. These notes are annotated with span-level symptom mentions. We conduct an expert evaluation to assess note quality and run baseline predictive models on both the tabular and textual data. The SimSUM dataset is primarily designed to support research on clinical information extraction in the presence of tabular background variables, which can be linked through domain knowledge to concepts of interest to be extracted from the text (symptoms, in the case of SimSUM). Secondary uses include research on the automation of clinical reasoning over both tabular data and text, causal effect estimation in the presence of tabular and/or textual confounders, and multi-modal synthetic data generation. SimSUM is not intended for training clinical decision support systems or production-grade models, but rather to facilitate reproducible research in a simplified and controlled setting. The dataset is available at .","Вилучення клінічної інформації, що передбачає структурування клінічних концепцій з неструктурованого медичного тексту, залишається складною проблемою, яка могла б виграти від включення табличної довідкової інформації, доступної в електронних медичних картах. Існуючі набори даних з відкритим вихідним кодом не мають явних зв'язків між структурованими ознаками та клінічними поняттями в тексті, що мотивує потребу в новому наборі даних для дослідження. Ми представляємо SimSUM - еталонний набір даних з 10 000 змодельованих історій хвороби, які пов'язують неструктуровані клінічні нотатки зі структурованими фоновими змінними. Кожен запис імітує зустріч з пацієнтом в області респіраторних захворювань і включає табличні дані (наприклад, симптоми, діагнози, основні стани), згенеровані за допомогою байєсівської мережі, структура і параметри якої визначаються експертами в цій галузі. Велика мовна модель (GPT-4o) генерує клінічну нотатку, що описує випадок, включаючи симптоми та відповідний контекст. Ці нотатки анотуються згадками симптомів на рівні діапазону. Ми проводимо експертне оцінювання для оцінки якості записів і запускаємо базові прогностичні моделі як на табличних, так і на текстових даних. Набір даних SimSUM в першу чергу призначений для підтримки досліджень з вилучення клінічної інформації за наявності табличних фонових змінних, які можуть бути пов'язані через знання предметної області з поняттями, що представляють інтерес для вилучення з тексту (симптоми, у випадку SimSUM). Вторинне використання включає дослідження з автоматизації клінічних міркувань як над табличними даними, так і над текстом, оцінку причинно-наслідкових зв'язків за наявності табличних і/або текстових перешкод, а також мультимодальне синтетичне генерування даних. SimSUM не призначений для навчання клінічних систем підтримки прийняття рішень або моделей виробничого рівня, а скоріше для сприяння відтворюваним дослідженням у спрощених і контрольованих умовах. Набір даних доступний за адресою .",264,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2409.08936,https://arxiv.org/pdf/2409.08936.pdf,true
2409.14993,"Multi-modal Generative AI: Multi-modal LLMs, Diffusions and the Unification","Xin Wang, Yuwei Zhou, Bin Huang, Hong Chen, Wenwu Zhu","Multi-modal generative AI (Artificial Intelligence) has attracted increasing attention from both academia and industry. Particularly, two dominant families of techniques have emerged: i) Multi-modal large language models (LLMs) demonstrate impressive ability for multi-modal understanding; and ii) Diffusion models exhibit remarkable multi-modal powers in terms of multi-modal generation. Therefore, this paper provides a comprehensive overview of multi-modal generative AI, including multi-modal LLMs, diffusions, and the unification for understanding and generation. To lay a solid foundation for unified models, we first provide a detailed review of both multi-modal LLMs and diffusion models respectively, including their probabilistic modeling procedure, multi-modal architecture design, and advanced applications to image/video LLMs as well as text-to-image/video generation. Furthermore, we explore the emerging efforts toward unified models for understanding and generation. To achieve the unification of understanding and generation, we investigate key designs including autoregressive-based and diffusion-based modeling, as well as dense and Mixture-of-Experts (MoE) architectures. We then introduce several strategies for unified models, analyzing their potential advantages and disadvantages. In addition, we summarize the common datasets widely used for multi-modal generative AI pretraining. Last but not least, we present several challenging future research directions which may contribute to the ongoing advancement of multi-modal generative AI.","Мультимодальний генеративний ШІ (штучний інтелект) привертає все більше уваги як з боку академічних кіл, так і з боку промисловості. Зокрема, з'явилося два домінуючих сімейства методів: i) мультимодальні великі мовні моделі (БММ) демонструють вражаючу здатність до мультимодального розуміння; і ii) дифузійні моделі демонструють чудові мультимодальні можливості з точки зору мультимодальної генерації. Таким чином, ця стаття надає всебічний огляд мультимодального генеративного ШІ, включаючи мультимодальні LLM, дифузії та уніфікацію для розуміння і генерації. Щоб закласти міцний фундамент для уніфікованих моделей, ми спочатку надаємо детальний огляд як мультимодальних ШНМ, так і дифузійних моделей, включаючи процедуру їх імовірнісного моделювання, дизайн мультимодальної архітектури, а також розширені додатки для зображення/відео ШНМ, а також для перетворення тексту в зображення/відео. Крім того, ми досліджуємо нові зусилля, спрямовані на створення уніфікованих моделей для розуміння і генерації. Щоб досягти уніфікації розуміння і генерації, ми досліджуємо ключові моделі, включаючи авторегресійне і дифузійне моделювання, а також щільні архітектури і архітектури на основі суміші експертів (MoE). Потім ми представляємо кілька стратегій для уніфікованих моделей, аналізуючи їхні потенційні переваги та недоліки. Крім того, ми узагальнюємо загальні набори даних, які широко використовуються для попереднього навчання мультимодального генеративного ШІ. І останнє, але не менш важливе: ми представляємо кілька перспективних напрямків майбутніх досліджень, які можуть сприяти подальшому розвитку мультимодального генеративного ШІ.",198,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2409.14993,https://arxiv.org/pdf/2409.14993.pdf,true
2411.07618,Constrain Alignment with Sparse Autoencoders,"Qingyu Yin, Chak Tou Leong, Minjun Zhu, Hanqi Yan, Qiang Zhang, Yulan He, Wenjie Li, Jun Wang, Yue Zhang, Linyi Yang","The alignment of large language models (LLMs) with human preferences remains a key challenge. While post-training techniques like Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO) have achieved notable success, they often introduce computational inefficiencies and training instability. In this paper, we propose Feature-level constrained Preference Optimization (FPO), a novel method designed to simplify the alignment process while ensuring stability. FPO leverages pre-trained Sparse Autoencoders (SAEs) and introduces feature-level constraints, allowing for efficient, sparsity-enforced alignment. Our approach enjoys efficiency by using sparse features activated in a well-trained sparse autoencoder and the quality of sequential KL divergence by using the feature-level offline reference. Experimental results on benchmark datasets demonstrate that FPO achieves a 5.08% absolute improvement in win rate with much lower computational cost compared to state-of-the-art baselines, making it a promising solution for efficient and controllable LLM alignments.","Узгодження великих мовних моделей (ВММ) з людськими вподобаннями залишається ключовим викликом. Хоча такі методи, як навчання з підкріпленням на основі зворотного зв'язку з людиною (RLHF) та пряма оптимізація вподобань (DPO) досягли значного успіху, вони часто призводять до обчислювальної неефективності та нестабільності в навчанні. У цій статті ми пропонуємо обмежену оптимізацію переваг на рівні ознак (Feature-level constrained Preference Optimization, FPO) - новий метод, розроблений для спрощення процесу вирівнювання, забезпечуючи при цьому стабільність. FPO використовує попередньо навчені розріджені автокодери (SAE) і вводить обмеження на рівні ознак, що дозволяє проводити ефективне вирівнювання з урахуванням розрідженості. Наш підхід відрізняється ефективністю завдяки використанню розріджених ознак, активованих у добре навченому розрідженому автокодері, і якістю послідовної розбіжності KL завдяки використанню офлайн-еталону на рівні ознак. Експериментальні результати на тестових наборах даних демонструють, що FPO досягає 5,08% абсолютного покращення виграшу при значно менших обчислювальних витратах порівняно з найсучаснішими базовими лініями, що робить його перспективним рішенням для ефективного та контрольованого вирівнювання LLM.",141,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2411.07618,https://arxiv.org/pdf/2411.07618.pdf,true
2501.02770,Multi-Agent Pathfinding Under Team-Connected Communication Constraint via Adaptive Path Expansion and Dynamic Leading,"Hoang-Dung Bui, Erion Plaku, Gregoy J. Stein","This paper proposes a novel planning framework to handle a multi-agent pathfinding problem under team-connected communication constraint, where all agents must have a connected communication channel to the rest of the team during their entire movements. Standard multi-agent path finding approaches (e.g., priority-based search) have potential in this domain but fail when neighboring configurations at start and goal differ. Their single-expansion approach -- computing each agent's path from the start to the goal in just a single expansion -- cannot reliably handle planning under communication constraints for agents as their neighbors change during navigating. Similarly, leader-follower approaches (e.g., platooning) are effective at maintaining team communication, but fixing the leader at the outset of planning can cause planning to become stuck in dense-clutter environments, limiting their practical utility. To overcome this limitation, we propose a novel two-level multi-agent pathfinding framework that integrates two techniques: adaptive path expansion to expand agent paths to their goals in multiple stages; and dynamic leading technique that enables the reselection of the leading agent during each agent path expansion whenever progress cannot be made. Simulation experiments show the efficiency of our planners, which can handle up to 25 agents across five environment types under a limited communication range constraint and up to 11-12 agents on three environment types under line-of-sight communication constraint, exceeding 90% success-rate where baselines routinely fail.","У цій статті пропонується нова система планування для розв'язання багатоагентної задачі пошуку шляху в умовах обмеження зв'язку в команді, де всі агенти повинні мати канал зв'язку з рештою команди протягом усього часу руху. Стандартні багатоагентні підходи до пошуку шляху (наприклад, пошук на основі пріоритетів) мають потенціал у цій області, але не працюють, коли сусідні конфігурації на старті та в кінцевій точці відрізняються. Їхній підхід з одним розширенням - обчислення шляху кожного агента від старту до мети лише за одне розширення - не може надійно впоратися з плануванням в умовах обмежень зв'язку між агентами, оскільки їхні сусіди змінюються під час навігації. Аналогічно, підходи ""лідер-послідовник"" (наприклад, взводний розподіл) ефективні для підтримки командної комунікації, але фіксація лідера на початку планування може призвести до того, що планування застрягне в щільному середовищі, що обмежує їх практичну корисність. Щоб подолати це обмеження, ми пропонуємо новий дворівневий багатоагентний фреймворк пошуку шляхів, який інтегрує дві техніки: адаптивне розширення шляхів для розширення шляхів агентів до їхніх цілей у кілька етапів; і техніку динамічного лідерства, яка дозволяє переобрати провідного агента під час кожного розширення шляхів агентів, якщо прогрес не може бути досягнутий. Імітаційні експерименти показують ефективність наших планувальників, які можуть обробляти до 25 агентів у п'яти типах середовища в умовах обмеженої дальності зв'язку і до 11-12 агентів у трьох типах середовища в умовах прямої видимості, перевищуючи 90% успіху там, де базові моделі зазвичай зазнають невдачі.",223,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2501.02770,https://arxiv.org/pdf/2501.02770.pdf,true
2411.00461,A Multi-Granularity Supervised Contrastive Framework for Remaining Useful Life Prediction of Aero-engines,"Zixuan He, Ziqian Kong, Zhengyu Chen, Yuling Zhan, Zijun Que, Zhengguo Xu","Accurate remaining useful life (RUL) predictions are critical to the safe operation of aero-engines. Currently, the RUL prediction task is mainly a regression paradigm with only mean square error as the loss function and lacks research on feature space structure, the latter of which has shown excellent performance in a large number of studies. This paper develops a multi-granularity supervised contrastive (MGSC) framework from plain intuition that samples with the same RUL label should be aligned in the feature space, and address the problems of too large minibatch size and unbalanced samples in the implementation. The RUL prediction with MGSC is implemented on using the proposed multi-phase training strategy. This paper also demonstrates a simple and scalable basic network structure and validates the proposed MGSC strategy on the CMPASS dataset using a convolutional long short-term memory network as a baseline, which effectively improves the accuracy of RUL prediction.","Точне прогнозування залишкового ресурсу (RUL) має вирішальне значення для безпечної експлуатації авіадвигунів. Наразі завдання прогнозування залишкового ресурсу є переважно регресійною парадигмою, яка використовує лише середньоквадратичну похибку як функцію втрат, і в якій бракує досліджень структури простору ознак, хоча останній метод показав чудову ефективність у великій кількості досліджень. У цій статті розроблено концепцію багатогранної керованої контрастності (MGSC) на основі простої інтуїції, що зразки з однаковою міткою RUL повинні бути вирівняні в просторі ознак, і вирішуються проблеми занадто великого розміру міні-партій і незбалансованих зразків у процесі реалізації. Прогнозування RUL за допомогою MGSC реалізовано з використанням запропонованої стратегії багатофазного навчання. Ця стаття також демонструє просту і масштабовану базову структуру мережі та перевіряє запропоновану стратегію MGSC на наборі даних CMPASS, використовуючи згорткову мережу з довгою короткочасною пам'яттю як базову лінію, що ефективно покращує точність передбачення RUL.",148,Machine Learning (cs.LG),https://arxiv.org/abs/2411.00461,https://arxiv.org/pdf/2411.00461.pdf,true
2501.05765,Deontic Temporal Logic for Formal Verification of AI Ethics,"Priya T.V., Shrisha Rao","Ensuring ethical behavior in Artificial Intelligence (AI) systems amidst their increasing ubiquity and influence is a major concern the world over. The use of formal methods in AI ethics is a possible crucial approach for specifying and verifying the ethical behavior of AI systems. This paper proposes a formalization based on deontic logic to define and evaluate the ethical behavior of AI systems, focusing on system-level specifications, contributing to this important goal. It introduces axioms and theorems to capture ethical requirements related to fairness and explainability. The formalization incorporates temporal operators to reason about the ethical behavior of AI systems over time. The authors evaluate the effectiveness of this formalization by assessing the ethics of the real-world COMPAS and loan prediction AI systems. Various ethical properties of the COMPAS and loan prediction systems are encoded using deontic logical formulas, allowing the use of an automated theorem prover to verify whether these systems satisfy the defined properties. The formal verification reveals that both systems fail to fulfill certain key ethical properties related to fairness and non-discrimination, demonstrating the effectiveness of the proposed formalization in identifying potential ethical issues in real-world AI applications.","Забезпечення етичної поведінки систем штучного інтелекту (ШІ) на тлі їхньої зростаючої повсюдності та впливу є головною проблемою в усьому світі. Використання формальних методів в етиці ШІ є можливим вирішальним підходом для визначення та перевірки етичної поведінки систем ШІ. Ця стаття пропонує формалізацію на основі деонтичної логіки для визначення та оцінки етичної поведінки систем ШІ, зосереджуючись на специфікаціях системного рівня, що сприяє досягненню цієї важливої мети. Вона вводить аксіоми і теореми, щоб відобразити етичні вимоги, пов'язані зі справедливістю і пояснюваністю. Формалізація включає темпоральні оператори для міркувань про етичну поведінку систем ШІ в часі. Автори оцінюють ефективність цієї формалізації, аналізуючи етичність реальних систем ШІ COMPAS та прогнозування кредитів. Різні етичні властивості систем COMPAS і прогнозування кредитів кодуються за допомогою деонтичних логічних формул, що дозволяє використовувати автоматизований теоретик для перевірки того, чи задовольняють ці системи визначеним властивостям. Формальна перевірка показує, що обидві системи не відповідають певним ключовим етичним властивостям, пов'язаним зі справедливістю та недискримінацією, демонструючи ефективність запропонованої формалізації для виявлення потенційних етичних проблем у реальних застосуваннях ШІ.",191,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2501.05765,https://arxiv.org/pdf/2501.05765.pdf,true
2504.02670,Affordable AI Assistants with Knowledge Graph of Thoughts,"Maciej Besta, Lorenzo Paleari, Jia Hao Andrea Jiang, Robert Gerstenberger, You Wu, Jón Gunnar Hannesson, Patrick Iff, Ales Kubicek, Piotr Nyczyk, Diana Khimey, Nils Blach, Haiqiang Zhang, Tao Zhang, Peiran Ma, Grzegorz Kwaśniewski, Marcin Copik, Hubert Niewiadomski, Torsten Hoefler","Large Language Models (LLMs) are revolutionizing the development of AI assistants capable of performing diverse tasks across domains. However, current state-of-the-art LLM-driven agents face significant challenges, including high operational costs and limited success rates on complex benchmarks like GAIA. To address these issues, we propose Knowledge Graph of Thoughts (KGoT), an innovative AI assistant architecture that integrates LLM reasoning with dynamically constructed knowledge graphs (KGs). KGoT extracts and structures task-relevant knowledge into a dynamic KG representation, iteratively enhanced through external tools such as math solvers, web crawlers, and Python scripts. Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively while also minimizing bias and noise. For example, KGoT achieves a 29% improvement in task success rates on the GAIA benchmark compared to Hugging Face Agents with GPT-4o mini. Moreover, harnessing a smaller model dramatically reduces operational costs by over 36x compared to GPT-4o. Improvements for other models (e.g., Qwen2.5-32B and Deepseek-R1-70B) and benchmarks (e.g., SimpleQA) are similar. KGoT offers a scalable, affordable, versatile, and high-performing solution for AI assistants.","Великі мовні моделі (LLM) революціонізують розробку асистентів штучного інтелекту, здатних виконувати різноманітні завдання в різних сферах. Однак сучасні агенти на основі LLM стикаються зі значними проблемами, включаючи високі операційні витрати та обмежені показники успішності в складних тестах, таких як GAIA. Для вирішення цих проблем ми пропонуємо Knowledge Graph of Thoughts (KGoT), інноваційну архітектуру асистента ШІ, яка інтегрує міркування LLM з динамічно побудованими графами знань (KG). KGoT витягує та структурує релевантні для задачі знання в динамічне представлення KG, яке ітеративно вдосконалюється за допомогою зовнішніх інструментів, таких як математичні розв'язувачі, веб-сканери та скрипти на мові Python. Таке структуроване представлення релевантних для завдання знань дозволяє недорогим моделям ефективно вирішувати складні завдання, мінімізуючи упередженість і шум. Наприклад, KGoT досягає 29% покращення показників успішності виконання завдань у тесті GAIA порівняно з агентами Hugging Face Agents з GPT-4o mini. Крім того, використання меншої моделі значно зменшує операційні витрати - у понад 36 разів порівняно з GPT-4o. Покращення для інших моделей (наприклад, Qwen2.5-32B і Deepseek-R1-70B) і бенчмарків (наприклад, SimpleQA) є аналогічними. KGoT пропонує масштабоване, доступне, універсальне та високопродуктивне рішення для асистентів зі штучним інтелектом.",174,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2504.02670,https://arxiv.org/pdf/2504.02670.pdf,true
2504.13554,Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning,"Xin Tang, Qian Chen, Wenjie Weng, Chao Jin, Zhang Liu, Jiacheng Wang, Geng Sun, Xiaohuan Li, Dusit Niyato","The integration of emerging uncrewed aerial vehicles (UAVs) with artificial intelligence (AI) and ground-embedded robots (GERs) has transformed emergency rescue operations in unknown environments. However, the high computational demands often exceed a single UAV's capacity, making it difficult to continuously provide stable high-level services. To address this, this paper proposes a cooperation framework involving UAVs, GERs, and airships. The framework enables resource pooling through UAV-to-GER (U2G) and UAV-to-airship (U2A) links, offering computing services for offloaded tasks. Specifically, we formulate the multi-objective problem of task assignment and exploration as a dynamic long-term optimization problem aiming to minimize task completion time and energy use while ensuring stability. Using Lyapunov optimization, we transform it into a per-slot deterministic problem and propose HG-MADDPG, which combines the Hungarian algorithm with a GDM-based multi-agent deep deterministic policy gradient. Simulations demonstrate significant improvements in offloading efficiency, latency, and system stability over baselines.","Інтеграція нових безпілотних літальних апаратів (БПЛА) зі штучним інтелектом (ШІ) і наземними роботами (НР) трансформувала аварійно-рятувальні операції в невідомих умовах. Однак високі обчислювальні вимоги часто перевищують можливості одного БПЛА, що ускладнює безперервне надання стабільних послуг високого рівня. Для вирішення цієї проблеми в цьому документі пропонується схема співпраці за участю БПЛА, ГПС і дирижаблів. Вона дозволяє об'єднати ресурси через зв'язок БПЛА з ГПС (U2G) і БПЛА з дирижаблем (U2A), пропонуючи обчислювальні послуги для розвантажених завдань. Зокрема, ми формулюємо багатоцільову задачу розподілу завдань та розвідки як динамічну довгострокову оптимізаційну задачу, що має на меті мінімізувати час виконання завдання та використання енергії, забезпечуючи при цьому стабільність. Використовуючи оптимізацію Ляпунова, ми перетворюємо її на детерміновану задачу для кожного слоту і пропонуємо HG-MADDPG, який поєднує угорський алгоритм з мультиагентним глибоко детермінованим градієнтом політики на основі GDM. Моделювання демонструє значне покращення ефективності розвантаження, затримки та стабільності системи порівняно з базовим варіантом.",145,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2504.13554,https://arxiv.org/pdf/2504.13554.pdf,true
2505.09341,Access Controls Will Solve the Dual-Use Dilemma,Evžen Wybitul,"AI safety systems face the dual-use dilemma: it can be unclear whether to refuse certain requests, since they could be either harmless or harmful depending on who made them and why. Determining this requires examining their real-world context, but current safety systems cannot access this contextual information. Instead, they make arbitrary decisions that end up hurting both utility and safety: they sometimes refuse legitimate queries and other times fail to refuse harmful ones. To address this, we propose a conceptual framework based on access controls in which only verified users can access dual-use outputs. We describe the framework's components, analyse its feasibility, and explain how it addresses both over-refusals and under-refusals. While only a high-level proposal, our work takes the first step toward enabling more nuanced safety decisions: with better tools for managing dual-use content, model providers could enable users to access more capabilities without sacrificing safety, and give regulators new options for more targeted policies.","Системи безпеки на основі ШІ стикаються з дилемою подвійного використання: може бути незрозуміло, чи слід відмовляти в певних запитах, оскільки вони можуть бути як нешкідливими, так і шкідливими, залежно від того, хто і чому їх зробив. Щоб визначити це, потрібно вивчити їхній реальний контекст, але сучасні системи безпеки не можуть отримати доступ до цієї контекстної інформації. Замість цього вони приймають довільні рішення, які в кінцевому підсумку шкодять як корисності, так і безпеці: іноді вони відкидають законні запити, а іноді не можуть відкинути шкідливі. Щоб вирішити цю проблему, ми пропонуємо концептуальну структуру, засновану на контролі доступу, в якій лише верифіковані користувачі можуть отримати доступ до результатів подвійного використання. Ми описуємо компоненти фреймворку, аналізуємо його реалістичність та пояснюємо, як він вирішує проблему надмірних та недостатніх відмов. Хоча наша робота є лише пропозицією високого рівня, вона робить перший крок до ухвалення більш тонких рішень щодо безпеки: завдяки кращим інструментам для управління контентом подвійного використання провайдери можуть надати користувачам більше можливостей без шкоди для безпеки, а регуляторам - нові можливості для більш цілеспрямованих політик.",156,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2505.09341,https://arxiv.org/pdf/2505.09341.pdf,true
2506.10281,Closer to Language than Steam: AI as the Cognitive Engine of a New Productivity Revolution,"Xinmin Fang, Lingfeng Tao, Zhengxiong Li","Artificial Intelligence (AI) is reframed as a cognitive engine driving a novel productivity revolution distinct from the Industrial Revolution's physical thrust. This paper develops a theoretical framing of AI as a cognitive revolution akin to written language - a transformative augmentation of human intellect rather than another mechanized tool. We compare AI's emergence to historical leaps in information technology to show how it amplifies knowledge work. Examples from various domains demonstrate AI's impact as a driver of productivity in cognitive tasks. We adopt a multidisciplinary perspective combining computer science advances with economic insights and sociological perspectives on how AI reshapes work and society. Through conceptual frameworks, we visualize the shift from manual to cognitive productivity. Our central argument is that AI functions as an engine of cognition - comparable to how human language revolutionized knowledge - heralding a new productivity paradigm. We discuss how this revolution demands rethinking of skills, organizations, and policies. This paper, balancing academic rigor with clarity, concludes that AI's promise lies in complementing human cognitive abilities, marking a new chapter in productivity evolution.","Штучний інтелект (ШІ) переосмислюється як когнітивний двигун, що рухає нову революцію продуктивності, відмінну від фізичної спрямованості промислової революції. У цій статті розвивається теоретичне бачення ШІ як когнітивної революції, подібної до писемності - трансформаційного доповнення людського інтелекту, а не ще одного механізованого інструменту. Ми порівнюємо появу ШІ з історичними стрибками в інформаційних технологіях, щоб показати, як він посилює роботу зі знаннями. Приклади з різних сфер демонструють вплив штучного інтелекту як рушія продуктивності у виконанні когнітивних завдань. Ми використовуємо міждисциплінарний підхід, що поєднує досягнення комп'ютерних наук з економічними та соціологічними поглядами на те, як штучний інтелект змінює роботу та суспільство. За допомогою концептуальних рамок ми візуалізуємо перехід від ручної праці до когнітивної продуктивності. Наш головний аргумент полягає в тому, що ШІ функціонує як двигун пізнання - подібно до того, як людська мова зробила революцію в пізнанні, провіщаючи нову парадигму продуктивності. Ми обговорюємо, як ця революція вимагає переосмислення навичок, організацій та політик. У цій статті, що поєднує академічну строгість і ясність, ми дійшли висновку, що ШІ доповнює когнітивні здібності людини, відкриваючи нову главу в еволюції продуктивності.",177,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2506.10281,https://arxiv.org/pdf/2506.10281.pdf,true
2506.23080,AI's Euclid's Elements Moment: From Language Models to Computable Thought,"Xinmin Fang, Lingfeng Tao, Zhengxiong Li","This paper presents a comprehensive five-stage evolutionary framework for understanding the development of artificial intelligence, arguing that its trajectory mirrors the historical progression of human cognitive technologies. We posit that AI is advancing through distinct epochs, each defined by a revolutionary shift in its capacity for representation and reasoning, analogous to the inventions of cuneiform, the alphabet, grammar and logic, mathematical calculus, and formal logical systems. This ""Geometry of Cognition"" framework moves beyond mere metaphor to provide a systematic, cross-disciplinary model that not only explains AI's past architectural shifts-from expert systems to Transformers-but also charts a concrete and prescriptive path forward. Crucially, we demonstrate that this evolution is not merely linear but reflexive: as AI advances through these stages, the tools and insights it develops create a feedback loop that fundamentally reshapes its own underlying architecture. We are currently transitioning into a ""Metalinguistic Moment,"" characterized by the emergence of self-reflective capabilities like Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the ""Mathematical Symbolism Moment"" and the ""Formal Logic System Moment,"" will be defined by the development of a computable calculus of thought, likely through neuro-symbolic architectures and program synthesis, culminating in provably aligned and reliable AI that reconstructs its own foundational representations. This work serves as the methodological capstone to our trilogy, which previously explored the economic drivers (""why"") and cognitive nature (""what"") of AI. Here, we address the ""how,"" providing a theoretical foundation for future research and offering concrete, actionable strategies for startups and developers aiming to build the next generation of intelligent systems.","У цій статті представлено комплексну п'ятиетапну еволюційну концепцію для розуміння розвитку штучного інтелекту, яка стверджує, що його траєкторія відображає історичний прогрес людських когнітивних технологій. Ми стверджуємо, що ШІ розвивається через окремі епохи, кожна з яких визначається революційним зрушенням у його здатності до репрезентації та міркування, аналогічно до винаходу клинопису, алфавіту, граматики та логіки, математичного обчислення та формальних логічних систем. Ця концепція ""Геометрії пізнання"" виходить за рамки простої метафори і пропонує системну, міждисциплінарну модель, яка не лише пояснює минулі архітектурні зміни в ШІ - від експертних систем до трансформерів - але й окреслює конкретний і передбачуваний шлях уперед. Важливо, що ми демонструємо, що ця еволюція є не просто лінійною, а рефлексивною: коли ШІ проходить ці етапи, інструменти та ідеї, які він розвиває, створюють петлю зворотного зв'язку, яка докорінно змінює його власну базову архітектуру. Наразі ми переходимо до ""Металінгвістичного моменту"", який характеризується появою саморефлексивних можливостей, таких як підказка ""Ланцюг думок"" і конституційний ШІ. Наступні етапи, ""Момент математичного символізму"" і ""Момент формальної логічної системи"", будуть визначатися розвитком обчислюваного обчислення думки, ймовірно, за допомогою нейро-символічних архітектур і синтезу програм, що завершиться створенням достовірно узгодженого і надійного ШІ, який реконструює свої власні фундаментальні уявлення. Ця робота слугує методологічним завершенням нашої трилогії, яка раніше досліджувала економічні чинники (""чому"") і когнітивну природу (""що"") ШІ. Тут ми розглядаємо питання ""як"", забезпечуючи теоретичну основу для майбутніх досліджень і пропонуючи конкретні, дієві стратегії для стартапів і розробників, які прагнуть створити наступне покоління інтелектуальних систем.",255,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2506.23080,https://arxiv.org/pdf/2506.23080.pdf,true
2507.02825,Establishing Best Practices for Building Rigorous Agentic Benchmarks,"Yuxuan Zhu, Tengjun Jin, Yada Pruksachatkun, Andy Zhang, Shu Liu, Sasha Cui, Sayash Kapoor, Shayne Longpre, Kevin Meng, Rebecca Weiss, Fazl Barez, Rahul Gupta, Jwala Dhamala, Jacob Merizian, Mario Giulianelli, Harry Coppock, Cozmin Ududec, Jasjeet Sekhon, Jacob Steinhardt, Antony Kellerman, Sarah Schwettmann, Matei Zaharia, Ion Stoica, Percy Liang, Daniel Kang","Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues in task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation of agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.","Бенчмарки мають важливе значення для кількісного відстеження прогресу в галузі штучного інтелекту. Оскільки ШІ-агенти стають дедалі потужнішими, дослідники і практики запроваджують агенційні бенчмарки для оцінювання агентів при виконанні складних реальних завдань. Ці бенчмарки зазвичай вимірюють можливості агентів, оцінюючи результати виконання завдань за допомогою певних схем винагороди. Однак ми показуємо, що багато агентних бенчмарків мають проблеми з налаштуванням завдань або дизайном винагороди. Наприклад, SWE-bench Verified використовує недостатню кількість тестових кейсів, а TAU-bench зараховує порожні відповіді як успішні. Такі проблеми можуть призвести до недооцінки або переоцінки роботи агентів на 100% у відносному вираженні. Щоб зробити оцінку агентів суворою, ми представили Контрольний список агентських еталонів (ABC), набір рекомендацій, які ми синтезували з нашого досвіду створення еталонів, огляду найкращих практик та раніше повідомлених проблем. При застосуванні до CVE-Bench, бенчмарку з особливо складним дизайном оцінювання, АВС зменшує завищену оцінку на 33%.",142,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.02825,https://arxiv.org/pdf/2507.02825.pdf,true
2507.05110,Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution Shift,"Shixuan Liu, Yue He, Yunfei Wang, Hao Zou, Haoxiang Cheng, Wenjing Yang, Peng Cui, Zhong Liu","Logical rule learning, a prominent category of knowledge graph (KG) reasoning methods, constitutes a critical research area aimed at learning explicit rules from observed facts to infer missing knowledge. However, like all KG reasoning methods, rule learning suffers from a critical weakness-its dependence on the I.I.D. assumption. This assumption can easily be violated due to selection bias during training or agnostic distribution shifts during testing (e.g., as in query shift scenarios), ultimately undermining model performance and reliability. To enable robust KG reasoning in wild environments, this study investigates logical rule learning in the presence of agnostic test-time distribution shifts. We formally define this challenge as out-of-distribution (OOD) KG reasoning-a previously underexplored problem, and propose the Stable Rule Learning (StableRule) framework as a solution. StableRule is an end-to-end framework that combines feature decorrelation with rule learning network, to enhance OOD generalization in KG reasoning. By leveraging feature decorrelation, StableRule mitigates the adverse effects of covariate shifts arising in OOD scenarios, improving the robustness of the rule learning network. Extensive experiments on seven benchmark KGs demonstrate the framework's superior effectiveness and stability across diverse heterogeneous environments, highlighting its practical significance for real-world applications.","Вивчення логічних правил, важлива категорія методів міркувань на основі графів знань (ГЗ), є важливою сферою досліджень, спрямованих на вивчення явних правил на основі спостережуваних фактів для виведення відсутніх знань. Однак, як і всі методи міркувань на основі графів знань, навчання правил страждає від критичного недоліку - його залежності від припущення I.I.D. Це припущення може бути легко порушене через упередженість відбору під час навчання або агностичні зсуви розподілу під час тестування (наприклад, як у сценаріях зсуву запитів), що в кінцевому підсумку підриває продуктивність і надійність моделі. Щоб уможливити надійні міркування КГ у диких умовах, це дослідження вивчає навчання логічних правил за наявності агностичних зсувів розподілу під час тестування. Ми формально визначаємо цю проблему як міркування КГ поза розподілом (OOD) - раніше недосліджену проблему, і пропонуємо фреймворк Stable Rule Learning (StableRule) для її вирішення. StableRule - це наскрізний фреймворк, який поєднує декорреляцію ознак з мережею навчання правил для покращення OOD-узагальнення в міркуваннях КГ. Використовуючи декорреляцію ознак, StableRule пом'якшує негативні наслідки зсувів коваріантів, що виникають у сценаріях OOD, покращуючи надійність мережі навчання правил. Широкі експерименти на семи еталонних КГ демонструють чудову ефективність і стабільність фреймворку в різноманітних гетерогенних середовищах, що підкреслює його практичну значущість для реальних застосувань.",191,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.05110,https://arxiv.org/pdf/2507.05110.pdf,true
2507.05791,GTA1: GUI Test-time Scaling Agent,"Yan Yang, Dongxu Li, Yutong Dai, Yuhao Yang, Ziyang Luo, Zirui Zhao, Zhiyuan Hu, Junzhe Huang, Amrita Saha, Zeyuan Chen, Ran Xu, Liyuan Pan, Caiming Xiong, Junnan Li","Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets. This paper investigates the two aforementioned challenges with our GUI Test-time Scaling Agent, namely GTA1. First, to select the most appropriate action proposal, we introduce a test-time scaling method. At each step, we sample multiple candidate action proposals and leverage a judge model to evaluate and select the most suitable one. It trades off computation for better decision quality by concurrent sampling, shortening task execution steps, and improving overall performance. Second, we propose a model that achieves improved accuracy when grounding the selected action proposal to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates visual grounding through inherent objective alignments, rewarding successful clicks on interface elements. Experimentally, our method establishes state-of-the-art performance across diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7% accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When paired with a planner applying our test-time scaling strategy, it exhibits state-of-the-art agentic performance (e.g., 45.2% task success rate on OSWorld). We open-source our code and models here.","Агенти графічного інтерфейсу користувача (GUI) автономно працюють на різних платформах (наприклад, Linux) для виконання завдань шляхом взаємодії з візуальними елементами. Зокрема, інструкція користувача розкладається на послідовність пропозицій дій, кожна з яких відповідає взаємодії з графічним інтерфейсом. Після кожної дії агент спостерігає за оновленим середовищем графічного інтерфейсу, щоб спланувати наступний крок. Однак виникають дві основні проблеми: i) вирішення неоднозначності планування завдань (тобто послідовності пропозицій дій), де вибір відповідного плану є нетривіальним, оскільки може існувати багато правильних планів; ii) точне обґрунтування дій у складних інтерфейсах з високою роздільною здатністю, тобто точна взаємодія з візуальними цілями. У цій статті досліджуються дві вищезгадані проблеми за допомогою нашого агента масштабування часу тестування графічного інтерфейсу, а саме GTA1. По-перше, щоб вибрати найбільш підходящу пропозицію дії, ми вводимо метод масштабування під час тестування. На кожному кроці ми відбираємо кілька пропозицій дій-кандидатів і використовуємо модель судді, щоб оцінити та вибрати найбільш підходящу з них. Це дає змогу зменшити кількість обчислень на користь кращої якості рішень завдяки одночасній вибірці, скороченню етапів виконання завдання та підвищенню загальної продуктивності. По-друге, ми пропонуємо модель, яка досягає підвищеної точності при підкріпленні обраної пропозиції дій відповідними візуальними елементами. Наша основна ідея полягає в тому, що навчання з підкріпленням (RL) полегшує візуальне підкріплення через властиве йому вирівнювання цілей, винагороджуючи успішне натискання на елементи інтерфейсу. Експериментально наш метод встановлює найсучаснішу продуктивність у різних тестах. Наприклад, GTA1-7B досягає точності 50,1%, 92,4% та 67,7% у Screenspot-Pro, Screenspot-V2 та OSWorld-G відповідно. У парі з планувальником, який застосовує нашу стратегію масштабування тестового часу, він демонструє найсучаснішу агентну продуктивність (наприклад, 45,2% успішного виконання завдань в OSWorld). Наш код і моделі доступні з відкритим вихідним кодом тут.",262,Artificial Intelligence (cs.AI),https://arxiv.org/abs/2507.05791,https://arxiv.org/pdf/2507.05791.pdf,true
2010.07990,An Algorithm for Learning Smaller Representations of Models With Scarce Data,Adrian de Wynter,"We present an algorithm for solving binary classification problems when the dataset is not fully representative of the problem being solved, and obtaining more data is not possible. It relies on a trained model with loose accuracy constraints, an iterative hyperparameter searching-and-pruning procedure over a search space $\Theta$, and a data-generating function. Our algorithm works by reconstructing up to homology the manifold on which lies the support of the underlying distribution. We provide an analysis on correctness and runtime complexity under ideal conditions and an extension to deep neural networks. In the former case, if $\size{\Theta}$ is the number of hyperparameter sets in the search space, this algorithm returns a solution that is up to $2(1 - {2^{-\size{\Theta}}})$ times better than simply training with an enumeration of $\Theta$ and picking the best model. As part of our analysis we also prove that an open cover of a dataset has the same homology as the manifold on which lies the support of the underlying probability distribution, if and only said dataset is learnable. This latter result acts as a formal argument to explain the effectiveness of data expansion techniques.","Ми представляємо алгоритм для розв'язання задач бінарної класифікації, коли набір даних не є повністю репрезентативним для розв'язуваної задачі, а отримати більше даних не є можливим. Він спирається на навчену модель з нечіткими обмеженнями на точність, ітераційну процедуру пошуку та відсікання гіперпараметрів у просторі пошуку $\Theta$ та функцію генерування даних. Наш алгоритм працює шляхом реконструкції з точністю до гомології многовиду, на якому лежить підтримка базового розподілу. Ми надаємо аналіз коректності та складності виконання за ідеальних умов, а також розширення на глибокі нейронні мережі. У першому випадку, якщо $\size{\Theta}$ - кількість наборів гіперпараметрів у просторі пошуку, цей алгоритм повертає розв'язок, який до $2(1 - {2^{-\size{\Theta}}})$ разів кращий, ніж просте навчання з перебором $\Theta$ і вибором найкращої моделі. В рамках нашого аналізу ми також доводимо, що відкрите покриття набору даних має таку ж гомологію, як і множина, на якій лежить підтримка базового розподілу ймовірностей, якщо і тільки якщо цей набір даних піддається навчанню. Цей останній результат слугує формальним аргументом для пояснення ефективності методів розширення даних.",188,Machine Learning (cs.LG),https://arxiv.org/abs/2010.07990,https://arxiv.org/pdf/2010.07990.pdf,true
2203.07861,Don't Get Me Wrong: How to Apply Deep Visual Interpretations to Time Series,"Christoffer Loeffler, Wei-Cheng Lai, Bjoern Eskofier, Dario Zanca, Lukas Schmidt, Christopher Mutschler","The correct interpretation of convolutional models is a hard problem for time series data. While saliency methods promise visual validation of predictions for image and language processing, they fall short when applied to time series. These tend to be less intuitive and represent highly diverse data, such as the tool-use time series dataset. Furthermore, saliency methods often generate varied, conflicting explanations, complicating the reliability of these methods. Consequently, a rigorous objective assessment is necessary to establish trust in them. This paper investigates saliency methods on time series data to formulate recommendations for interpreting convolutional models and implements them on the tool-use time series problem. To achieve this, we first employ nine gradient-, propagation-, or perturbation-based post-hoc saliency methods across six varied and complex real-world datasets. Next, we evaluate these methods using five independent metrics to generate recommendations. Subsequently, we implement a case study focusing on tool-use time series using convolutional classification models. Our results validate our recommendations that indicate that none of the saliency methods consistently outperforms others on all metrics, while some are sometimes ahead. Our insights and step-by-step guidelines allow experts to choose suitable saliency methods for a given model and dataset.","Правильна інтерпретація згорткових моделей є складною проблемою для даних часових рядів. Хоча методи значущості обіцяють візуальну перевірку прогнозів для обробки зображень і мови, вони не є ефективними, коли застосовуються до часових рядів. Вони, як правило, менш інтуїтивні і представляють дуже різноманітні дані, такі як набір даних часових рядів використання інструментів. Крім того, методи значущості часто дають різноманітні, суперечливі пояснення, що ускладнює надійність цих методів. Отже, для встановлення довіри до них необхідна ретельна об'єктивна оцінка. У цій статті ми досліджуємо методи значущості на даних часових рядів, щоб сформулювати рекомендації щодо інтерпретації згорткових моделей і застосувати їх до проблеми використання часових рядів. Для цього ми спочатку застосовуємо дев'ять постфактум методів значущості, заснованих на градієнті, поширенні або збуреннях, на шести різноманітних і складних наборах реальних даних. Потім ми оцінюємо ці методи за допомогою п'яти незалежних метрик, щоб сформувати рекомендації. Згодом ми реалізуємо тематичне дослідження, зосереджене на часових рядах використання інструментів з використанням згорткових моделей класифікації. Отримані результати підтверджують наші рекомендації, які вказують на те, що жоден з методів оцінки релевантності не перевершує інші за всіма показниками, тоді як деякі з них іноді випереджають їх. Наші висновки та покрокові інструкції дозволяють експертам обирати відповідні методи для конкретної моделі та набору даних.",194,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2203.07861,https://arxiv.org/pdf/2203.07861.pdf,true
2303.14111,Unsupervised Automata Learning via Discrete Optimization,"Simon Lutz, Daniil Kaminskyi, Florian Wittbold, Simon Dierl, Falk Howar, Barbara König, Emmanuel Müller, Daniel Neider","Automata learning is a successful tool for many application domains such as robotics and automatic verification. Typically, automata learning techniques operate in a supervised learning setting (active or passive) where they learn a finite state machine in contexts where additional information, such as labeled system executions, is available. However, other settings, such as learning from unlabeled data - an important aspect in machine learning - remain unexplored. To overcome this limitation, we propose a framework for learning a deterministic finite automaton (DFA) from a given multi-set of unlabeled words. We show that this problem is computationally hard and develop three learning algorithms based on constraint optimization. Moreover, we introduce novel regularization schemes for our optimization problems that improve the overall interpretability of our DFAs. Using a prototype implementation, we demonstrate practical feasibility in the context of unsupervised anomaly detection.","Автоматичне навчання є успішним інструментом для багатьох прикладних областей, таких як робототехніка та автоматична верифікація. Зазвичай методи машинного навчання працюють в умовах контрольованого навчання (активного або пасивного), коли вони вивчають скінченний автомат в контекстах, де доступна додаткова інформація, наприклад, марковані виконання системи. Однак інші умови, такі як навчання на немаркованих даних - важливий аспект машинного навчання - залишаються недослідженими. Щоб подолати це обмеження, ми пропонуємо фреймворк для навчання детермінованого скінченного автомата (ДСА) на заданій множині немаркованих слів. Ми показуємо, що ця задача є складною з обчислювальної точки зору, і розробляємо три алгоритми навчання, засновані на оптимізації обмежень. Крім того, ми вводимо нові схеми регуляризації для наших оптимізаційних задач, які покращують загальну інтерпретованість наших ДФА. Використовуючи прототип реалізації, ми демонструємо практичну здійсненність в контексті неконтрольованого виявлення аномалій.",139,Machine Learning (cs.LG),https://arxiv.org/abs/2303.14111,https://arxiv.org/pdf/2303.14111.pdf,true
2401.13796,Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning,"Andrea Apicella, Francesco Isgrò, Roberto Prevete","Machine Learning (ML) has revolutionized various domains, offering predictive capabilities in several areas. However, with the increasing accessibility of ML tools, many practitioners, lacking deep ML expertise, adopt a ""push the button"" approach, utilizing user-friendly interfaces without a thorough understanding of underlying algorithms. While this approach provides convenience, it raises concerns about the reliability of outcomes, leading to challenges such as incorrect performance evaluation. This paper addresses a critical issue in ML, known as data leakage, where unintended information contaminates the training data, impacting model performance evaluation. Users, due to a lack of understanding, may inadvertently overlook crucial steps, leading to optimistic performance estimates that may not hold in real-world scenarios. The discrepancy between evaluated and actual performance on new data is a significant concern. In particular, this paper categorizes data leakage in ML, discussing how certain conditions can propagate through the ML workflow. Furthermore, it explores the connection between data leakage and the specific task being addressed, investigates its occurrence in Transfer Learning, and compares standard inductive ML with transductive ML frameworks. The conclusion summarizes key findings, emphasizing the importance of addressing data leakage for robust and reliable ML applications.","Машинне навчання (МН) здійснило революцію в різних галузях, пропонуючи можливості прогнозування в декількох сферах. Однак зі зростанням доступності інструментів машинного навчання багато фахівців-практиків, не маючи глибоких знань у цій галузі, застосовують підхід ""натиснути кнопку"", використовуючи зручні інтерфейси без глибокого розуміння алгоритмів, що лежать в його основі. Хоча такий підхід забезпечує зручність, він викликає занепокоєння щодо надійності результатів, що призводить до таких проблем, як некоректна оцінка ефективності. У цій статті розглядається критична проблема в ML, відома як витік даних, коли ненавмисна інформація забруднює навчальні дані, впливаючи на оцінку продуктивності моделі. Користувачі, через брак розуміння, можуть ненавмисно пропустити важливі кроки, що призводить до оптимістичних оцінок продуктивності, які можуть не відповідати реальним сценаріям. Розбіжність між оціненою та фактичною ефективністю на основі нових даних викликає значне занепокоєння. Зокрема, в цій статті класифікуються витоки даних у ВК, обговорюється, як певні умови можуть поширюватися в робочому процесі ВК. Крім того, досліджується зв'язок між витоком даних і конкретною задачею, що вирішується, досліджується його виникнення в процесі трансферного навчання, а також порівнюється стандартний індуктивний ML з трансдуктивними фреймворками ML. У висновках узагальнюються основні результати, підкреслюється важливість вирішення проблеми витоку даних для надійного та ефективного застосування ML.",191,Machine Learning (cs.LG),https://arxiv.org/abs/2401.13796,https://arxiv.org/pdf/2401.13796.pdf,true
2402.11005,A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive,"Sarath Sivaprasad, Pramod Kaushik, Sahar Abdelnabi, Mario Fritz","Large Language Models (LLMs) are increasingly utilized in autonomous decision-making, where they sample options from vast action spaces. However, the heuristics that guide this sampling process remain under explored. We study this sampling behavior and show that this underlying heuristics resembles that of human decision-making: comprising a descriptive component (reflecting statistical norm) and a prescriptive component (implicit ideal encoded in the LLM) of a concept. We show that this deviation of a sample from the statistical norm towards a prescriptive component consistently appears in concepts across diverse real-world domains like public health, and economic trends. To further illustrate the theory, we demonstrate that concept prototypes in LLMs are affected by prescriptive norms, similar to the concept of normality in humans. Through case studies and comparison with human studies, we illustrate that in real-world applications, the shift of samples toward an ideal value in LLMs' outputs can result in significantly biased decision-making, raising ethical concerns.","Великі мовні моделі (ВММ) все частіше використовуються в автономному прийнятті рішень, де вони вибирають варіанти з величезних просторів дій. Однак евристики, які керують цим процесом вибірки, залишаються недостатньо вивченими. Ми досліджуємо таку поведінку вибірки і показуємо, що ця евристика нагадує евристику прийняття рішень людиною: вона складається з описового компонента (що відображає статистичну норму) і прескриптивного компонента (імпліцитний ідеал, закодований в LLM) концепції. Ми показуємо, що це відхилення вибірки від статистичної норми в бік прескриптивного компонента послідовно з'являється в концептах у різних сферах реального світу, таких як громадське здоров'я та економічні тенденції. Щоб проілюструвати теорію, ми показуємо, що прототипи концептів у LLMs піддаються впливу прескриптивних норм, подібно до поняття нормальності у людей. На конкретних прикладах і в порівнянні з дослідженнями на людях ми показуємо, що в реальних умовах зсув зразків до ідеального значення в результатах LLM може призвести до суттєво упередженого прийняття рішень, що викликає етичні занепокоєння.",154,Computation and Language (cs.CL),https://arxiv.org/abs/2402.11005,https://arxiv.org/pdf/2402.11005.pdf,true
2402.13284,Structure Guided Large Language Model for SQL Generation,"Qinggang Zhang, Hao Chen, Junnan Dong, Shengyuan Chen, Feiran Huang, Xiao Huang","Recent advancements in large language models (LLMs) have shown promise in bridging the gap between natural language queries and database management systems, enabling users to interact with databases without the background of SQL. However, LLMs often struggle to comprehend complex database structures and accurately interpret user intentions. Decomposition-based methods have been proposed to enhance the performance of LLMs on complex tasks, but decomposing SQL generation into subtasks is non-trivial due to the declarative structure of SQL syntax and the intricate connections between query concepts and database elements. In this paper, we propose a novel Structure GUided text-to-SQL framework~(SGU-SQL) that incorporates syntax-based prompting to enhance the SQL generation capabilities of LLMs. Specifically, SGU-SQL establishes structure-aware links between user queries and database schema and decomposes the complex generation task using syntax-based prompting to enable more accurate LLM-based SQL generation. Extensive experiments on two benchmark datasets demonstrate that SGU-SQL consistently outperforms state-of-the-art text-to-SQL models.","Нещодавні досягнення в галузі великих мовних моделей (ВММ) продемонстрували багатообіцяючу можливість подолання розриву між запитами на природній мові та системами управління базами даних, дозволяючи користувачам взаємодіяти з базами даних без знання мови SQL. Однак LLM часто намагаються зрозуміти складні структури баз даних і точно інтерпретувати наміри користувача. Для підвищення продуктивності LLM на складних завданнях були запропоновані методи на основі декомпозиції, але декомпозиція генерації SQL на підзадачі є нетривіальною через декларативну структуру синтаксису SQL та складні зв'язки між концепціями запитів та елементами бази даних. У цій статті ми пропонуємо новий фреймворк Structure GUided text-to-SQL (SGU-SQL), який включає в себе підказки на основі синтаксису для покращення можливостей генерації SQL в LLM. Зокрема, SGU-SQL встановлює структурні зв'язки між запитами користувача та схемою бази даних і декомпозує складну задачу генерації, використовуючи синтаксичні підказки, щоб забезпечити більш точну генерацію SQL на основі LLM. Широкі експерименти на двох тестових наборах даних демонструють, що SGU-SQL постійно перевершує найсучасніші моделі перетворення тексту в SQL.",151,Databases (cs.DB),https://arxiv.org/abs/2402.13284,https://arxiv.org/pdf/2402.13284.pdf,true
2404.10393,Offline Trajectory Optimization for Offline Reinforcement Learning,"Ziqi Zhao, Zhaochun Ren, Liu Yang, Yunsen Liang, Fajie Yuan, Pengjie Ren, Zhumin Chen, jun Ma, Xin Xin","Offline reinforcement learning (RL) aims to learn policies without online explorations. To enlarge the training data, model-based offline RL learns a dynamics model which is utilized as a virtual environment to generate simulation data and enhance policy learning. However, existing data augmentation methods for offline RL suffer from (i) trivial improvement from short-horizon simulation; and (ii) the lack of evaluation and correction for generated data, leading to low-qualified augmentation. In this paper, we propose offline trajectory optimization for offline reinforcement learning (OTTO). The key motivation is to conduct long-horizon simulation and then utilize model uncertainty to evaluate and correct the augmented data. Specifically, we propose an ensemble of Transformers, a.k.a. World Transformers, to predict environment state dynamics and the reward function. Three strategies are proposed to use World Transformers to generate long-horizon trajectory simulation by perturbing the actions in the offline data. Then, an uncertainty-based World Evaluator is introduced to firstly evaluate the confidence of the generated trajectories and then perform the correction for low-confidence data. Finally, we jointly use the original data with the corrected augmentation data to train an offline RL algorithm. OTTO serves as a plug-in module and can be integrated with existing model-free offline RL methods. Experiments on various benchmarks show that OTTO can effectively improve the performance of representative offline RL algorithms, including in complex environments with sparse rewards like AntMaze. Codes are available at .","Офлайн-навчання з підкріпленням має на меті вивчати політику без онлайн-досліджень. Щоб розширити навчальні дані, автономне навчання на основі моделей вивчає модель динаміки, яка використовується як віртуальне середовище для генерування імітаційних даних і покращення навчання політик. Однак, існуючі методи доповнення даних для автономного навчання страждають від (i) тривіального покращення за рахунок короткострокового моделювання; і (ii) відсутності оцінки та корекції згенерованих даних, що призводить до низькокваліфікованого доповнення. У цій статті ми пропонуємо офлайн-оптимізацію траєкторії для офлайн-навчання з підкріпленням (OTTO). Основною мотивацією є проведення довгострокового моделювання, а потім використання невизначеності моделі для оцінки та виправлення доповнених даних. Зокрема, ми пропонуємо ансамбль трансформерів, так званих світових трансформерів, для прогнозування динаміки стану навколишнього середовища та функції винагороди. Запропоновано три стратегії використання світових трансформаторів для генерування симуляції довгострокової траєкторії шляхом збурення дій в автономних даних. Потім вводиться оцінювач світу на основі невизначеності, щоб спочатку оцінити достовірність згенерованих траєкторій, а потім виконати корекцію для даних з низьким рівнем достовірності. Нарешті, ми спільно використовуємо вихідні дані з виправленими даними доповнення для навчання автономного алгоритму RL. OTTO слугує модулем, що підключається, і може бути інтегрований з існуючими безмодельними методами автономного RL. Експерименти на різних тестах показують, що OTTO може ефективно покращити продуктивність репрезентативних алгоритмів автономного RL, в тому числі в складних середовищах з розрідженою винагородою, таких як AntMaze. Коди доступні за адресою .",231,Machine Learning (cs.LG),https://arxiv.org/abs/2404.10393,https://arxiv.org/pdf/2404.10393.pdf,true
2405.17556,Solving Probabilistic Verification Problems of Neural Networks using Branch and Bound,"David Boetius, Stefan Leue, Tobias Sutter","Probabilistic verification problems of neural networks are concerned with formally analysing the output distribution of a neural network under a probability distribution of the inputs. Examples of probabilistic verification problems include verifying the demographic parity fairness notion or quantifying the safety of a neural network. We present a new algorithm for solving probabilistic verification problems of neural networks based on an algorithm for computing and iteratively refining lower and upper bounds on probabilities over the outputs of a neural network. By applying state-of-the-art bound propagation and branch and bound techniques from non-probabilistic neural network verification, our algorithm significantly outpaces existing probabilistic verification algorithms, reducing solving times for various benchmarks from the literature from tens of minutes to tens of seconds. Furthermore, our algorithm compares favourably even to dedicated algorithms for restricted probabilistic verification problems. We complement our empirical evaluation with a theoretical analysis, proving that our algorithm is sound and, under mildly restrictive conditions, also complete when using a suitable set of heuristics.","Проблеми ймовірнісної верифікації нейронних мереж пов'язані з формальним аналізом розподілу вихідних даних нейронної мережі відповідно до розподілу ймовірностей вхідних даних. Прикладами задач імовірнісної верифікації є перевірка справедливості поняття демографічного паритету або кількісна оцінка безпеки нейронної мережі. Ми представляємо новий алгоритм для розв'язання задач ймовірнісної верифікації нейронних мереж, який базується на алгоритмі обчислення та ітеративного уточнення нижньої та верхньої меж ймовірностей на виходах нейронної мережі. Застосовуючи найсучасніші методи граничного поширення та розгалуження з неімовірнісної верифікації нейронних мереж, наш алгоритм значно випереджає існуючі ймовірнісні алгоритми верифікації, скорочуючи час розв'язання для різних тестів з літератури з десятків хвилин до десятків секунд. Крім того, наш алгоритм вигідно відрізняється навіть від спеціальних алгоритмів для проблем обмеженої ймовірнісної верифікації. Ми доповнюємо нашу емпіричну оцінку теоретичним аналізом, який доводить, що наш алгоритм є надійним і, за помірно обмежувальних умов, також повним при використанні відповідного набору евристик.",163,Machine Learning (cs.LG),https://arxiv.org/abs/2405.17556,https://arxiv.org/pdf/2405.17556.pdf,true
2406.05085,Multi-Head RAG: Solving Multi-Aspect Problems with LLMs,"Maciej Besta, Ales Kubicek, Robert Gerstenberger, Marcin Chrapek, Roman Niggli, Patrik Okanovic, Yi Zhu, Patrick Iff, Michal Podstawski, Lucas Weitzendorf, Mingyuan Chi, Joanna Gajda, Piotr Nyczyk, Jürgen Müller, Hubert Niewiadomski, Torsten Hoefler","Retrieval Augmented Generation (RAG) enhances the abilities of Large Language Models (LLMs) by enabling the retrieval of documents into the LLM context to provide more accurate and relevant responses. Existing RAG solutions do not focus on queries that may require fetching multiple documents with substantially different contents. Such queries occur frequently, but are challenging because the embeddings of these documents may be distant in the embedding space, making it hard to retrieve them all. This paper introduces Multi-Head RAG (MRAG), a novel scheme designed to address this gap with a simple yet powerful idea: leveraging activations of Transformer's multi-head attention layer, instead of the decoder layer, as keys for fetching multi-aspect documents. The driving observation is that different attention heads learn to capture different data aspects. Harnessing the corresponding activations results in embeddings that represent various facets of data items and queries, improving the retrieval accuracy for complex queries. We provide an evaluation methodology and metrics, multi-aspect datasets, and real-world use cases to demonstrate MRAG's effectiveness. We show MRAG's design advantages over 18 RAG baselines, empirical improvements of up to 20% in retrieval success ratios, and benefits for downstream LLM generation. MRAG can be seamlessly integrated with existing RAG frameworks and benchmarks.","Розширене покоління пошуку (RAG) розширює можливості великих мовних моделей (LLM), дозволяючи знаходити документи в контексті LLM для надання більш точних і релевантних відповідей. Існуючі рішення RAG не орієнтовані на запити, які можуть вимагати отримання декількох документів із суттєво різним змістом. Такі запити трапляються часто, але є складними, оскільки вбудовування цих документів можуть бути віддаленими у просторі вбудовування, що ускладнює отримання їх усіх. У цій статті представлено Multi-Head RAG (MRAG) - нову схему, розроблену для подолання цієї прогалини за допомогою простої, але потужної ідеї: використання активацій багатоголового шару уваги Transformer, а не шару декодера, як ключів для пошуку багатоаспектних документів. Основне спостереження полягає в тому, що різні головки уваги вчаться фіксувати різні аспекти даних. Використання відповідних активацій призводить до вбудовувань, які представляють різні аспекти елементів даних і запитів, покращуючи точність пошуку для складних запитів. Ми надаємо методологію та метрики оцінювання, багатоаспектні набори даних та реальні приклади використання, щоб продемонструвати ефективність MRAG. Ми показуємо переваги MRAG у порівнянні з 18 базовими RAG, емпіричні покращення до 20% у коефіцієнтах успішності пошуку та переваги для подальшого створення LLM. MRAG може бути легко інтегрований з існуючими системами та критеріями RAG.",202,Computation and Language (cs.CL),https://arxiv.org/abs/2406.05085,https://arxiv.org/pdf/2406.05085.pdf,true
2407.16803,C3T: Cross-modal Transfer Through Time for Sensor-based Human Activity Recognition,"Abhi Kamboj, Anh Duy Nguyen, Minh N. Do","In order to unlock the potential of diverse sensors, we investigate a method to transfer knowledge between time-series modalities using a multimodal \textit{temporal} representation space for Human Activity Recognition (HAR). Specifically, we explore the setting where the modality used in testing has no labeled data during training, which we refer to as Unsupervised Modality Adaptation (UMA). We categorize existing UMA approaches as Student-Teacher or Contrastive Alignment methods. These methods typically compress continuous-time data samples into single latent vectors during alignment, inhibiting their ability to transfer temporal information through real-world temporal distortions. To address this, we introduce Cross-modal Transfer Through Time (C3T), which preserves temporal information during alignment to handle dynamic sensor data better. C3T achieves this by aligning a set of temporal latent vectors across sensing modalities. Our extensive experiments on various camera+IMU datasets demonstrate that C3T outperforms existing methods in UMA by at least 8% in accuracy and shows superior robustness to temporal distortions such as time-shift, misalignment, and dilation. Our findings suggest that C3T has significant potential for developing generalizable models for time-series sensor data, opening new avenues for various multimodal applications.","Щоб розкрити потенціал різноманітних сенсорів, ми досліджуємо метод передачі знань між модальностями часових рядів за допомогою мультимодального \textit{temporal} простору представлення для розпізнавання людської активності (HAR). Зокрема, ми досліджуємо ситуацію, коли модальність, що використовується в тестуванні, не має маркованих даних під час навчання, яку ми називаємо неконтрольованою адаптацією модальності (Unsupervised Modality Adaptation, UMA). Ми класифікуємо існуючі підходи UMA як методи ""учень-викладач"" або контрастного вирівнювання. Ці методи, як правило, стискають вибірки даних безперервного часу в окремі латентні вектори під час вирівнювання, пригнічуючи їхню здатність передавати часову інформацію через реальні часові спотворення. Щоб вирішити цю проблему, ми представили крос-модальне перенесення в часі (C3T), яке зберігає часову інформацію під час вирівнювання, щоб краще обробляти динамічні дані датчиків. C3T досягає цього шляхом вирівнювання набору часових латентних векторів у різних модальностях зондування. Наші численні експерименти з різними наборами даних камери + IMU демонструють, що C3T перевершує існуючі методи в UMA щонайменше на 8% за точністю і демонструє чудову стійкість до часових спотворень, таких як часовий зсув, неспіввісність і дилатація. Наші результати свідчать про те, що C3T має значний потенціал для розробки узагальнюючих моделей для часових рядів сенсорних даних, відкриваючи нові можливості для різних мультимодальних застосувань.",184,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2407.16803,https://arxiv.org/pdf/2407.16803.pdf,true
2407.17070,Curriculum Negative Mining For Temporal Networks,"Ziyue Chen, Tongya Zheng, Mingli Song","Temporal networks are effective in capturing the evolving interactions of networks over time, such as social networks and e-commerce networks. In recent years, researchers have primarily concentrated on developing specific model architectures for Temporal Graph Neural Networks (TGNNs) in order to improve the representation quality of temporal nodes and edges. However, limited attention has been given to the quality of negative samples during the training of TGNNs. When compared with static networks, temporal networks present two specific challenges for negative sampling: positive sparsity and positive shift. Positive sparsity refers to the presence of a single positive sample amidst numerous negative samples at each timestamp, while positive shift relates to the variations in positive samples across different timestamps. To robustly address these challenges in training TGNNs, we introduce Curriculum Negative Mining (CurNM), a model-aware curriculum learning framework that adaptively adjusts the difficulty of negative samples. Within this framework, we first establish a dynamically updated negative pool that balances random, historical, and hard negatives to address the challenges posed by positive sparsity. Secondly, we implement a temporal-aware negative selection module that focuses on learning from the disentangled factors of recently active edges, thus accurately capturing shifting preferences. Finally, the selected negatives are combined with annealing random negatives to support stable training. Extensive experiments on 12 datasets and 3 TGNNs demonstrate that our method outperforms baseline methods by a significant margin. Additionally, thorough ablation studies and parameter sensitivity experiments verify the usefulness and robustness of our approach.","Темпоральні мережі ефективно відображають еволюцію взаємодії мереж у часі, таких як соціальні мережі та мережі електронної комерції. Останніми роками дослідники зосередилися на розробці конкретних архітектур моделей для нейронних мереж часових графів (TGNN) з метою покращення якості представлення часових вузлів та ребер. Однак, під час навчання TGNN мало уваги приділялося якості негативних вибірок. У порівнянні зі статичними мережами, темпоральні мережі створюють дві специфічні проблеми для негативної вибірки: позитивна розрідженість і позитивний зсув. Позитивна розрідженість означає наявність одного позитивного зразка серед численних негативних зразків на кожній часовій мітці, тоді як позитивний зсув пов'язаний з варіаціями позитивних зразків на різних часових мітках. Щоб ефективно вирішити ці проблеми при навчанні TGNN, ми представили Curriculum Negative Mining (CurNM) - навчальну програму, яка адаптивно підлаштовується під складність негативних зразків. В рамках цієї системи ми, по-перше, створюємо динамічно оновлюваний пул негативних даних, який збалансовує випадкові, історичні та складні негативи, щоб вирішити проблеми, пов'язані з розрідженістю позитивних даних. По-друге, ми впроваджуємо модуль відбору негативних даних з урахуванням часових параметрів, який фокусується на навчанні на розрізнених факторах нещодавно активних ребер, таким чином точно фіксуючи зміну вподобань. Нарешті, відібрані негативи поєднуються з відпалюванням випадкових негативів для підтримки стабільного навчання. Широкі експерименти на 12 наборах даних і 3 TGNN демонструють, що наш метод значно перевершує базові методи. Крім того, ретельні дослідження абляції та експерименти з чутливості до параметрів підтверджують корисність та надійність нашого підходу.",244,Machine Learning (cs.LG),https://arxiv.org/abs/2407.17070,https://arxiv.org/pdf/2407.17070.pdf,true
2408.06687,Masked Image Modeling: A Survey,"Vlad Hondru, Florinel Alin Croitoru, Shervin Minaee, Radu Tudor Ionescu, Nicu Sebe","In this work, we survey recent studies on masked image modeling (MIM), an approach that emerged as a powerful self-supervised learning technique in computer vision. The MIM task involves masking some information, e.g. pixels, patches, or even latent representations, and training a model, usually an autoencoder, to predicting the missing information by using the context available in the visible part of the input. We identify and formalize two categories of approaches on how to implement MIM as a pretext task, one based on reconstruction and one based on contrastive learning. Then, we construct a taxonomy and review the most prominent papers in recent years. We complement the manually constructed taxonomy with a dendrogram obtained by applying a hierarchical clustering algorithm. We further identify relevant clusters via manually inspecting the resulting dendrogram. Our review also includes datasets that are commonly used in MIM research. We aggregate the performance results of various masked image modeling methods on the most popular datasets, to facilitate the comparison of competing methods. Finally, we identify research gaps and propose several interesting directions of future work. We supplement our survey with the following public repository containing organized references: .","У цій роботі ми розглядаємо нещодавні дослідження з моделювання замаскованих зображень (MIM) - підходу, який виник як потужна техніка самонавчання в комп'ютерному зорі. Завдання MIM полягає у маскуванні певної інформації, наприклад, пікселів, ділянок або навіть латентних зображень, і навчанні моделі, зазвичай автокодера, передбачати відсутню інформацію, використовуючи контекст, доступний у видимій частині вхідних даних. Ми визначили та формалізували дві категорії підходів до реалізації МІМ як задачі з претекстом: один з них базується на реконструкції, а інший - на контрастному навчанні. Потім ми побудуємо таксономію і зробимо огляд найвідоміших робіт останніх років. Ми доповнюємо побудовану вручну таксономію дендрограмою, отриманою за допомогою алгоритму ієрархічної кластеризації. Далі ми визначаємо релевантні кластери шляхом ручної перевірки отриманої дендрограми. Наш огляд також включає набори даних, які зазвичай використовуються в дослідженнях МІМ. Ми агрегуємо результати роботи різних методів моделювання замаскованих зображень на найпопулярніших наборах даних, щоб полегшити порівняння конкуруючих методів. Нарешті, ми визначили прогалини в дослідженнях і запропонували кілька цікавих напрямків майбутньої роботи. Ми доповнюємо наш огляд наступним публічним репозиторієм, що містить упорядковані посилання: .",192,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2408.06687,https://arxiv.org/pdf/2408.06687.pdf,true
2409.10955,Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style,"Yuepei Li, Kang Zhou, Qiao Qiao, Bach Nguyen, Qing Wang, Qi Li","Retrieval-augmented generation (RAG) improves Large Language Models (LLMs) by incorporating external information into the response generation process. However, how context-faithful LLMs are and what factors influence LLMs' context faithfulness remain largely unexplored. In this study, we investigate the impact of memory strength and evidence presentation on LLMs' receptiveness to external evidence. We quantify the memory strength of LLMs by measuring the divergence in LLMs' responses to different paraphrases of the same question, which is not considered by previous works. We also generate evidence in various styles to examine LLMs' behavior. Our results show that for questions with high memory strength, LLMs are more likely to rely on internal memory. Furthermore, presenting paraphrased evidence significantly increases LLMs' receptiveness compared to simple repetition or adding details. These findings provide key insights for improving retrieval-augmented generation and context-aware LLMs. Our code is available at .","Генерація, доповнена пошуком (RAG), покращує великі мовні моделі (ВММ) шляхом включення зовнішньої інформації в процес генерації відповідей. Однак, наскільки контекстно-вірними є БММ і які фактори впливають на контекстну вірність БММ, залишаються малодослідженими. У цьому дослідженні ми вивчаємо вплив міцності пам'яті та представлення доказів на сприйнятливість LLMs до зовнішніх доказів. Ми кількісно оцінюємо міцність пам'яті LLMs, вимірюючи розбіжності у відповідях LLMs на різні перефразування одного і того ж питання, що не розглядалося в попередніх роботах. Ми також генеруємо докази в різних стилях, щоб дослідити поведінку LLMs. Наші результати показують, що для питань з високою міцністю пам'яті, LLMs більш схильні покладатися на внутрішню пам'ять. Крім того, представлення перефразованих доказів значно підвищує сприйнятливість LLMs порівняно з простим повторенням або додаванням деталей. Ці висновки дають ключові ідеї для покращення генерації LLM, доповнених пошуком, та контекстно-орієнтованих LLM. Наш код доступний за адресою .",142,Computation and Language (cs.CL),https://arxiv.org/abs/2409.10955,https://arxiv.org/pdf/2409.10955.pdf,true
2409.18047,HARMONIC: Cognitive and Control Collaboration in Human-Robotic Teams,"Sanjay Oruganti, Sergei Nirenburg, Marjorie McShane, Jesse English, Michael K. Roberts, Christian Arndt, Sahithi Kamireddy, Carlos Gonzalez, Mingyo Seo, Luis Sentis","This paper describes HARMONIC, a cognitive-robotic architecture that integrates the OntoAgent cognitive framework with general-purpose robot control systems applied to human-robot teaming (HRT). HARMONIC incorporates metacognition, meaningful natural language communication, and explainability capabilities required for developing mutual trust in HRT. Through simulation experiments involving a joint search task performed by a heterogeneous team of two HARMONIC-based robots and a human operator, we demonstrate heterogeneous robots that coordinate their actions, adapt to complex scenarios, and engage in natural human-robot communication. Evaluation results show that HARMONIC-based robots can reason about plans, goals, and team member attitudes while providing clear explanations for their decisions, which are essential requirements for realistic human-robot teaming.","У цій статті описується HARMONIC - когнітивно-робототехнічна архітектура, яка інтегрує когнітивний фреймворк OntoAgent з системами управління роботами загального призначення, що застосовуються для спільної роботи людей і роботів (HRT). HARMONIC включає метапізнання, змістовне спілкування природною мовою та можливості пояснення, необхідні для розвитку взаємної довіри в HRT. За допомогою імітаційних експериментів, що включають спільне пошукове завдання, яке виконує гетерогенна команда з двох роботів на базі HARMONIC і людини-оператора, ми демонструємо гетерогенних роботів, які координують свої дії, адаптуються до складних сценаріїв і беруть участь у природній комунікації між людиною і роботом. Результати оцінки показують, що роботи на основі HARMONIC можуть міркувати про плани, цілі та ставлення членів команди, надаючи чіткі пояснення своїх рішень, що є основними вимогами для реалістичної взаємодії між людьми та роботами.",109,Robotics (cs.RO),https://arxiv.org/abs/2409.18047,https://arxiv.org/pdf/2409.18047.pdf,true
2411.13766,Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge,"Ruiyang Qin, Dancheng Liu, Gelei Xu, Zheyu Yan, Chenhui Xu, Yuting Hu, X. Sharon Hu, Jinjun Xiong, Yiyu Shi","The combination of Large Language Models (LLM) and Automatic Speech Recognition (ASR), when deployed on edge devices (called edge ASR-LLM), can serve as a powerful personalized assistant to enable audio-based interaction for users. Compared to text-based interaction, edge ASR-LLM allows accessible and natural audio interactions. Unfortunately, existing ASR-LLM models are mainly trained in high-performance computing environments and produce substantial model weights, making them difficult to deploy on edge devices. More importantly, to better serve users' personalized needs, the ASR-LLM must be able to learn from each distinct user, given that audio input often contains highly personalized characteristics that necessitate personalized on-device training. Since individually fine-tuning the ASR or LLM often leads to suboptimal results due to modality-specific limitations, end-to-end training ensures seamless integration of audio features and language understanding (cross-modal alignment), ultimately enabling a more personalized and efficient adaptation on edge devices. However, due to the complex training requirements and substantial computational demands of existing approaches, cross-modal alignment between ASR audio and LLM can be challenging on edge devices. In this work, we propose a resource-efficient cross-modal alignment framework that bridges ASR and LLMs on edge devices to handle personalized audio input. Our framework enables efficient ASR-LLM alignment on resource-constrained devices like NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while improving the alignment quality by more than 50\%. To the best of our knowledge, this is the first work to study efficient ASR-LLM alignment on resource-constrained edge devices.","Поєднання великих мовних моделей (LLM) і автоматичного розпізнавання мови (ASR), розгорнуте на периферійних пристроях (так зване периферійне ASR-LLM), може слугувати потужним персоналізованим помічником для забезпечення аудіовзаємодії для користувачів. У порівнянні з текстовою взаємодією, периферійний ASR-LLM забезпечує доступну і природну аудіовзаємодію. На жаль, існуючі моделі ASR-LLM в основному тренуються у високопродуктивних обчислювальних середовищах і створюють значну вагу моделі, що ускладнює їх розгортання на периферійних пристроях. Що ще важливіше, щоб краще задовольняти персоналізовані потреби користувачів, ASR-LLM повинен мати можливість навчатися у кожного окремого користувача, враховуючи, що аудіовхід часто містить високо персоналізовані характеристики, які вимагають персоналізованого навчання на пристрої. Оскільки індивідуальне налаштування ASR або LLM часто призводить до неоптимальних результатів через обмеження, пов'язані з конкретною модальністю, наскрізне навчання забезпечує безперешкодну інтеграцію звукових характеристик і розуміння мови (крос-модальне вирівнювання), що в кінцевому підсумку дозволяє більш персоналізовану та ефективну адаптацію на периферійних пристроях. Однак, через складні вимоги до навчання та значні обчислювальні витрати існуючих підходів, крос-модальне узгодження між аудіо ASR та LLM може бути складним завданням на периферійних пристроях. У цій роботі ми пропонуємо ресурсоефективний фреймворк крос-модального узгодження, який поєднує ASR і LLM на периферійних пристроях для обробки персоналізованого аудіовводу. Наш фреймворк забезпечує ефективне вирівнювання ASR-LLM на пристроях з обмеженими ресурсами, таких як NVIDIA Jetson Orin (8 ГБ оперативної пам'яті), досягаючи 50-кратного прискорення часу навчання при покращенні якості вирівнювання більш ніж на 50\%. Наскільки нам відомо, це перша робота з вивчення ефективного вирівнювання ASR-LLM на периферійних пристроях з обмеженими ресурсами.",241,Sound (cs.SD),https://arxiv.org/abs/2411.13766,https://arxiv.org/pdf/2411.13766.pdf,true
2412.00151,DLaVA: Document Language and Vision Assistant for Answer Localization with Enhanced Interpretability and Trustworthiness,"Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Ser-Nam Lim, Rajiv Ramnath","Document Visual Question Answering (VQA) demands robust integration of text detection, recognition, and spatial reasoning to interpret complex document layouts. In this work, we introduce DLaVA, a novel, training-free pipeline that leverages Multimodal Large Language Models (MLLMs) for zero-shot answer localization in order to improve trustworthiness, interpretability, and explainability. By leveraging an innovative OCR-free approach that organizes text regions with unique bounding box IDs, the proposed method preserves spatial contexts without relying on iterative OCR or chain-of-thought reasoning, thus substantially reducing the computational complexity. We further enhance the evaluation protocol by integrating Intersection over Union (IoU) metrics alongside Average Normalized Levenshtein Similarity (ANLS), thereby ensuring that not only textual accuracy is considered, but spatial accuracy is taken into account, ultimately reducing the risks of AI hallucinations and improving trustworthiness. Experiments on benchmark datasets demonstrate competitive performance compared to state-of-the-art techniques, with significantly lower computational complexity and enhanced accuracies and reliability for high-stakes applications. The code and datasets utilized in this study for DLaVA are accessible at: .","Візуальні відповіді на запитання в документах (VQA) вимагають надійної інтеграції виявлення тексту, розпізнавання та просторових міркувань для інтерпретації складних макетів документів. У цій роботі ми представляємо DLaVA, новий конвеєр без навчання, який використовує мультимодальні великі мовні моделі (MLLM) для локалізації відповідей з нуля, щоб підвищити достовірність, інтерпретованість і пояснюваність. Використовуючи інноваційний підхід без розпізнавання тексту, який організовує текстові області з унікальними ідентифікаторами обмежувальних рамок, запропонований метод зберігає просторовий контекст, не покладаючись на ітеративне розпізнавання тексту або логічний ланцюжок міркувань, що значно зменшує обчислювальну складність. Ми ще більше вдосконалили протокол оцінювання, інтегрувавши метрики перетину над об'єднанням (IoU) разом із середньою нормалізованою подібністю Левенштейна (ANLS), таким чином гарантуючи, що враховується не лише текстова точність, але й просторова, що в кінцевому підсумку зменшує ризики галюцинацій ШІ та підвищує достовірність результатів. Експерименти на еталонних наборах даних демонструють конкурентоспроможну продуктивність порівняно з найсучаснішими методами, зі значно меншою обчислювальною складністю та підвищеною точністю і надійністю для додатків з високими ставками. Код і набори даних, використані в цьому дослідженні для DLaVA, доступні за адресою: .",167,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2412.00151,https://arxiv.org/pdf/2412.00151.pdf,true
2412.20429,Multi-Scenario Reasoning: Unlocking Cognitive Autonomy in Humanoid Robots for Multimodal Understanding,Libo Wang,"To improve the cognitive autonomy of humanoid robots, this research proposes a multi-scenario reasoning architecture to solve the technical shortcomings of multi-modal understanding in this field. It draws on simulation based experimental design that adopts multi-modal synthesis (visual, auditory, tactile) and builds a simulator ""Maha"" to perform the experiment. The findings demonstrate the feasibility of this architecture in multimodal data. It provides reference experience for the exploration of cross-modal interaction strategies for humanoid robots in dynamic environments. In addition, multi-scenario reasoning simulates the high-level reasoning mechanism of the human brain to humanoid robots at the cognitive level. This new concept promotes cross-scenario practical task transfer and semantic-driven action planning. It heralds the future development of self-learning and autonomous behavior of humanoid robots in changing scenarios.","Для покращення когнітивної автономії людиноподібних роботів у цьому дослідженні пропонується багатосценарна архітектура міркувань для вирішення технічних недоліків мультимодального розуміння в цій галузі. Воно спирається на симуляційний експериментальний дизайн, який використовує мультимодальний синтез (візуальний, слуховий, тактильний) і будує симулятор ""Маха"" для проведення експерименту. Отримані результати демонструють можливість застосування цієї архітектури до мультимодальних даних. Це забезпечує референтний досвід для дослідження стратегій крос-модальної взаємодії для людиноподібних роботів у динамічних середовищах. Крім того, мультисценарні міркування імітують високорівневий механізм міркувань людського мозку для людиноподібних роботів на когнітивному рівні. Ця нова концепція сприяє міжсценарному практичному перенесенню завдань і плануванню дій на основі семантики. Вона провіщає майбутній розвиток самонавчання та автономної поведінки людиноподібних роботів у мінливих сценаріях.",125,Robotics (cs.RO),https://arxiv.org/abs/2412.20429,https://arxiv.org/pdf/2412.20429.pdf,true
2501.00759,Enhancing Transformers for Generalizable First-Order Logical Entailment,"Tianshi Zheng, Jiazheng Wang, Zihao Wang, Jiaxin Bai, Hang Yin, Zheye Deng, Yangqiu Song, Jianxin Li","Transformers, as the fundamental deep learning architecture, have demonstrated great capability in reasoning. This paper studies the generalizable first-order logical reasoning ability of transformers with their parameterized knowledge and how to improve it. Transformers' capability of first-order reasoning is further captured by whether they can conduct first-order logical entailment, which is quantitatively measured by their performance in answering knowledge graph queries. We establish the connections between (1) two types of distribution shifts studied in out-of-distribution generalization and (2) unseen knowledge and query settings discussed in the task of knowledge graph query answering, which makes it possible to characterize the fine-grained generalizability. Results on our comprehensive dataset showed that transformers \textit{outperform} previous methods designed particularly for this task and provided detailed empirical evidence about the impact of the input query syntax, token embedding, and transformer architectures on their reasoning capability. Interestingly, our results revealed the mismatch of positional encoding and other design choices of transformer architectures in previous practices. Motivated by this, we propose TEGA, a logic-aware architecture that significantly improves the performance in generalizable first-order logical entailment.","Трансформатори, як фундаментальна архітектура глибокого навчання, продемонстрували чудову здатність до міркувань. У цій статті досліджується здатність трансформаторів до узагальненого логічного міркування першого порядку з параметризованими знаннями та способи її покращення. Здатність трансформаторів до міркувань першого порядку також визначається тим, чи можуть вони здійснювати логічне виведення першого порядку, яке кількісно вимірюється їхньою ефективністю у відповідях на запити до графів знань. Ми встановили зв'язок між (1) двома типами зсувів розподілу, які вивчалися при позадисперсійному узагальненні, і (2) невидимими налаштуваннями знань і запитів, які обговорювалися в задачі відповіді на запити до графів знань, що дає змогу охарактеризувати дрібнозернисту узагальнюваність. Результати на нашому повному наборі даних показали, що трансформатори \textit{ перевершують попередні методи, розроблені спеціально для цієї задачі, і надали детальні емпіричні докази впливу синтаксису вхідного запиту, вбудовування токенів та архітектури трансформаторів на їхню здатність міркувати. Цікаво, що наші результати виявили невідповідність позиційного кодування та інших варіантів архітектури трансформаторів попереднім практикам. Враховуючи це, ми пропонуємо TEGA, архітектуру з урахуванням логіки, яка значно покращує продуктивність в узагальнюючих логічних наслідках першого порядку.",177,Computation and Language (cs.CL),https://arxiv.org/abs/2501.00759,https://arxiv.org/pdf/2501.00759.pdf,true
2501.03575,Cosmos World Foundation Model Platform for Physical AI,"NVIDIA, Niket Agarwal, Arslan Ali, Maciej Bala, Yogesh Balaji, Erik Barker, Tiffany Cai, Prithvijit Chattopadhyay, Yongxin Chen, Yin Cui, Yifan Ding, Daniel Dworakowski, Jiaojiao Fan, Michele Fenzi, Francesco Ferroni, Sanja Fidler, Dieter Fox, Songwei Ge, Yunhao Ge, Jinwei Gu, Siddharth Gururani, Ethan He, Jiahui Huang, Jacob Huffman, Pooya Jannaty, Jingyi Jin, Seung Wook Kim, Gergely Klár, Grace Lam, Shiyi Lan, Laura Leal-Taixe, Anqi Li, Zhaoshuo Li, Chen-Hsuan Lin, Tsung-Yi Lin, Huan Ling, Ming-Yu Liu, Xian Liu, Alice Luo, Qianli Ma, Hanzi Mao, Kaichun Mo, Arsalan Mousavian, Seungjun Nah, Sriharsha Niverty, David Page, Despoina Paschalidou, Zeeshan Patel, Lindsey Pavao, Morteza Ramezanali, Fitsum Reda, Xiaowei Ren, Vasanth Rao Naik Sabavat, Ed Schmerling, Stella Shi, Bartosz Stefaniak, Shitao Tang, Lyne Tchapmi, Przemek Tredak, Wei-Cheng Tseng, Jibin Varghese, Hao Wang, Haoxiang Wang, Heng Wang, Ting-Chun Wang, Fangyin Wei, Xinyue Wei, Jay Zhangjie Wu, Jiashu Xu, Wei Yang, Lin Yen-Chen, Xiaohui Zeng, Yu Zeng, Jing Zhang, Qinsheng Zhang, Yuxuan Zhang, Qingqing Zhao, Artur Zolkowski","Physical AI needs to be trained digitally first. It needs a digital twin of itself, the policy model, and a digital twin of the world, the world model. In this paper, we present the Cosmos World Foundation Model Platform to help developers build customized world models for their Physical AI setups. We position a world foundation model as a general-purpose world model that can be fine-tuned into customized world models for downstream applications. Our platform covers a video curation pipeline, pre-trained world foundation models, examples of post-training of pre-trained world foundation models, and video tokenizers. To help Physical AI builders solve the most critical problems of our society, we make Cosmos open-source and our models open-weight with permissive licenses available via .","Фізичний ШІ потрібно спочатку навчити цифровому. Йому потрібен цифровий двійник самого себе - модель політики, і цифровий двійник світу - модель світу. У цій статті ми представляємо платформу Cosmos World Foundation Model Platform, щоб допомогти розробникам створювати індивідуальні моделі світу для своїх установок фізичного ШІ. Ми позиціонуємо модель фундаменту світу як універсальну модель світу, яку можна точно налаштувати в індивідуальні моделі світу для подальших додатків. Наша платформа охоплює конвеєр курації відео, попередньо навчені моделі світу, приклади пост-навчання попередньо навчених моделей світу та токенізатори відео. Щоб допомогти розробникам фізичного ШІ вирішувати найважливіші проблеми нашого суспільства, ми робимо Cosmos з відкритим вихідним кодом, а наші моделі - з відкритою вагою та дозвільними ліцензіями, доступними через .",122,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2501.03575,https://arxiv.org/pdf/2501.03575.pdf,true
2501.15379,Diffusion Augmented Retrieval: A Training-Free Approach to Interactive Text-to-Image Retrieval,"Zijun Long, Kangheng Liang, Gerardo Aragon-Camarasa, Richard Mccreadie, Paul Henderson","Interactive Text-to-image retrieval (I-TIR) is an important enabler for a wide range of state-of-the-art services in domains such as e-commerce and education. However, current methods rely on finetuned Multimodal Large Language Models (MLLMs), which are costly to train and update, and exhibit poor generalizability. This latter issue is of particular concern, as: 1) finetuning narrows the pretrained distribution of MLLMs, thereby reducing generalizability; and 2) I-TIR introduces increasing query diversity and complexity. As a result, I-TIR solutions are highly likely to encounter queries and images not well represented in any training dataset. To address this, we propose leveraging Diffusion Models (DMs) for text-to-image mapping, to avoid finetuning MLLMs while preserving robust performance on complex queries. Specifically, we introduce Diffusion Augmented Retrieval (DAR), a framework that generates multiple intermediate representations via LLM-based dialogue refinements and DMs, producing a richer depiction of the user's information needs. This augmented representation facilitates more accurate identification of semantically and visually related images. Extensive experiments on four benchmarks show that for simple queries, DAR achieves results on par with finetuned I-TIR models, yet without incurring their tuning overhead. Moreover, as queries become more complex through additional conversational turns, DAR surpasses finetuned I-TIR models by up to 7.61% in Hits@10 after ten turns, illustrating its improved generalization for more intricate queries.","Інтерактивне перетворення тексту в зображення (I-TIR) є важливим інструментом для широкого спектру найсучасніших послуг у таких сферах, як електронна комерція та освіта. Однак сучасні методи покладаються на тонко налаштовані мультимодальні великі мовні моделі (MLLM), які вимагають значних витрат на навчання і оновлення, а також демонструють низьку узагальнюваність. Ця остання проблема викликає особливе занепокоєння, оскільки 1) точне налаштування звужує попередньо навчений розподіл MLLM, тим самим зменшуючи узагальнюючі можливості; і 2) МДП призводить до збільшення різноманітності і складності запитів. Як наслідок, рішення I-TIR з великою ймовірністю можуть зіткнутися із запитами та зображеннями, які не представлені в жодному навчальному наборі даних. Щоб вирішити цю проблему, ми пропонуємо використовувати дифузійні моделі (DM) для відображення тексту в зображення, щоб уникнути тонкого налаштування MLLM, зберігаючи при цьому надійну продуктивність на складних запитах. Зокрема, ми представляємо Diffusion Augmented Retrieval (DAR) - фреймворк, який генерує кілька проміжних представлень за допомогою діалогових уточнень на основі LLM і DM, створюючи більш повне відображення інформаційних потреб користувача. Таке розширене представлення полегшує більш точну ідентифікацію семантично і візуально пов'язаних зображень. Широкі експерименти на чотирьох тестах показують, що для простих запитів DAR досягає результатів на рівні з точно налаштованими моделями МДП, але без накладних витрат на їх налаштування. Більше того, коли запити ускладнюються за рахунок додаткових діалогових ходів, DAR перевершує точно налаштовані моделі I-TIR на 7,61% за показником Hits@10 після десяти ходів, що ілюструє його покращене узагальнення для більш складних запитів.",214,Information Retrieval (cs.IR),https://arxiv.org/abs/2501.15379,https://arxiv.org/pdf/2501.15379.pdf,true
2502.00015,Ethical Concerns of Generative AI and Mitigation Strategies: A Systematic Mapping Study,"Yutan Huang, Chetan Arora, Wen Cheng Houng, Tanjila Kanij, Anuradha Madulgalla, John Grundy","[Context] Generative AI technologies, particularly Large Language Models (LLMs), have transformed numerous domains by enhancing convenience and efficiency in information retrieval, content generation, and decision-making processes. However, deploying LLMs also presents diverse ethical challenges, and their mitigation strategies remain complex and domain-dependent. [Objective] This paper aims to identify and categorize the key ethical concerns associated with using LLMs, examine existing mitigation strategies, and assess the outstanding challenges in implementing these strategies across various domains. [Method] We conducted a systematic mapping study, reviewing 39 studies that discuss ethical concerns and mitigation strategies related to LLMs. We analyzed these ethical concerns using five ethical dimensions that we extracted based on various existing guidelines, frameworks, and an analysis of the mitigation strategies and implementation challenges. [Results] Our findings reveal that ethical concerns in LLMs are multi-dimensional and context-dependent. While proposed mitigation strategies address some of these concerns, significant challenges still remain. [Conclusion] Our results highlight that ethical issues often hinder the practical implementation of the mitigation strategies, particularly in high-stake areas like healthcare and public governance; existing frameworks often lack adaptability, failing to accommodate evolving societal expectations and diverse contexts.","[Контекст] Технології генеративного ШІ, зокрема великі мовні моделі (ВММ), трансформували багато сфер, підвищивши зручність та ефективність пошуку інформації, створення контенту та процесів прийняття рішень. Однак розгортання LLM також створює різноманітні етичні проблеми, а стратегії їх вирішення залишаються складними і залежать від конкретної галузі. [Мета] Ця стаття має на меті визначити та класифікувати ключові етичні проблеми, пов'язані з використанням LLM, дослідити існуючі стратегії пом'якшення наслідків та оцінити невирішені проблеми у впровадженні цих стратегій у різних галузях. [Метод] Ми провели систематичне картування, проаналізувавши 39 досліджень, в яких обговорюються етичні проблеми та стратегії пом'якшення наслідків, пов'язані з НДЛМ. Ми проаналізували ці етичні проблеми, використовуючи п'ять етичних вимірів, які ми виокремили на основі різних існуючих керівних принципів, рамок, а також аналізу стратегій пом'якшення наслідків та викликів у впровадженні. [Результати] Наші висновки показують, що етичні проблеми в ОНМ є багатовимірними і залежать від контексту. Хоча запропоновані стратегії пом'якшення наслідків враховують деякі з цих проблем, значні виклики все ще залишаються. [Наші результати підкреслюють, що етичні проблеми часто перешкоджають практичному впровадженню стратегій пом'якшення наслідків, особливо в таких важливих сферах, як охорона здоров'я та державне управління; існуючі рамки часто не пристосовані до змін, не відповідають очікуванням суспільства, що змінюються, та різноманітним контекстам.",187,Computers and Society (cs.CY),https://arxiv.org/abs/2502.00015,https://arxiv.org/pdf/2502.00015.pdf,true
2502.04426,Decoding AI Judgment: How LLMs Assess News Credibility and Bias,"Edoardo Loru, Jacopo Nudo, Niccolò Di Marco, Alessandro Santirocchi, Roberto Atzeni, Matteo Cinelli, Vincenzo Cestari, Clelia Rossi-Arnaud, Walter Quattrociocchi","Large Language Models (LLMs) are increasingly embedded in workflows that involve evaluative processes. This raises the need to examine how such evaluations are built, what assumptions they rely on, and how their strategies diverge from those of humans. We benchmark six LLMs against expert ratings--NewsGuard and Media Bias/Fact Check (MBFC)--and against human judgments collected through a controlled experiment. To enable direct comparison, we implement a structured agentic framework in which both models and non-expert participants follow the same evaluation procedure: selecting criteria, retrieving content, and producing justifications. Despite output alignment, LLMs rely on different mechanisms: lexical associations and statistical priors replace contextual reasoning. This reliance produces systematic effects: political asymmetries, opaque justifications, and a tendency to confuse linguistic form with epistemic validity. Delegating judgment to such systems does not merely automate evaluation--it redefines it, shifting from normative reasoning to pattern-based approximation.","Великі мовні моделі (ВММ) все частіше використовуються в робочих процесах, які включають процеси оцінювання. Це викликає потребу дослідити, як будуються такі оцінки, на яких припущеннях вони ґрунтуються і як їхні стратегії відрізняються від людських. Ми порівняли шість LLM з експертними оцінками - NewsGuard та Media Bias/Fact Check (MBFC) - і з людськими судженнями, зібраними в ході контрольованого експерименту. Щоб уможливити пряме порівняння, ми впровадили структуровану агентну систему, в якій і моделі, і учасники, які не є експертами, дотримуються однакової процедури оцінювання: обирають критерії, отримують контент і надають обґрунтування. Незважаючи на вирівнювання результатів, LLM покладаються на різні механізми: лексичні асоціації та статистичні попередні дані замінюють контекстуальні міркування. Така залежність призводить до системних ефектів: політичної асиметрії, непрозорих обґрунтувань і тенденції плутати лінгвістичну форму з епістемічною обґрунтованістю. Делегування суджень таким системам не просто автоматизує оцінювання - воно переосмислює його, переходячи від нормативної аргументації до апроксимації на основі шаблонів.",141,Computation and Language (cs.CL),https://arxiv.org/abs/2502.04426,https://arxiv.org/pdf/2502.04426.pdf,true
2503.12356,Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation,"Byung Hyun Lee, Sungjin Lim, Se Young Chun","Fine-tuning based concept erasing has demonstrated promising results in preventing generation of harmful contents from text-to-image diffusion models by removing target concepts while preserving remaining concepts. To maintain the generation capability of diffusion models after concept erasure, it is necessary to remove only the image region containing the target concept when it locally appears in an image, leaving other regions intact. However, prior arts often compromise fidelity of the other image regions in order to erase the localized target concept appearing in a specific area, thereby reducing the overall performance of image generation. To address these limitations, we first introduce a framework called localized concept erasure, which allows for the deletion of only the specific area containing the target concept in the image while preserving the other regions. As a solution for the localized concept erasure, we propose a training-free approach, dubbed Gated Low-rank adaptation for Concept Erasure (GLoCE), that injects a lightweight module into the diffusion model. GLoCE consists of low-rank matrices and a simple gate, determined only by several generation steps for concepts without training. By directly applying GLoCE to image embeddings and designing the gate to activate only for target concepts, GLoCE can selectively remove only the region of the target concepts, even when target and remaining concepts coexist within an image. Extensive experiments demonstrated GLoCE not only improves the image fidelity to text prompts after erasing the localized target concepts, but also outperforms prior arts in efficacy, specificity, and robustness by large margin and can be extended to mass concept erasure.","Видалення концептів на основі точного налаштування продемонструвало багатообіцяючі результати у запобіганні генерації шкідливого контенту з моделей дифузії текст-зображення шляхом видалення цільових концептів зі збереженням решти концептів. Щоб зберегти здатність дифузійних моделей до генерації після видалення концептів, необхідно видаляти лише область зображення, що містить цільовий концепт, коли він локально з'являється на зображенні, залишаючи інші області недоторканими. Однак, у попередньому рівні техніки часто порушується точність інших областей зображення, щоб стерти локалізовану цільову концепцію, що з'являється в певній області, тим самим знижуючи загальну продуктивність генерації зображень. Щоб усунути ці обмеження, ми вперше вводимо фреймворк під назвою стирання локалізованої концепції, який дозволяє видаляти лише певну область, що містить цільову концепцію на зображенні, зберігаючи при цьому інші області. Як рішення для локалізованого видалення концепту ми пропонуємо підхід без навчання, який отримав назву Gated Low-rank adaptation for Concept Erasure (GLoCE), що вводить легкий модуль у модель дифузії. GLoCE складається з матриць низького рангу і простих воріт, які визначаються лише кількома кроками генерації концептів без навчання. Безпосередньо застосовуючи GLoCE до вбудовування зображень і проектуючи вентиль так, щоб він активувався лише для цільових концептів, GLoCE може вибірково видаляти лише область цільових концептів, навіть коли цільові та решта концептів співіснують на зображенні. Широкі експерименти показали, що GLoCE не тільки покращує точність зображення до текстових підказок після видалення локалізованих цільових концептів, але й значно перевершує попередні технології за ефективністю, специфічністю та надійністю, а також може бути застосований для масового видалення концептів.",255,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2503.12356,https://arxiv.org/pdf/2503.12356.pdf,true
2503.19092,"Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation","Krisztian Balog, Donald Metzler, Zhen Qin","Large language models (LLMs) are increasingly integral to information retrieval (IR), powering ranking, evaluation, and AI-assisted content creation. This widespread adoption necessitates a critical examination of potential biases arising from the interplay between these LLM-based components. This paper synthesizes existing research and presents novel experiment designs that explore how LLM-based rankers and assistants influence LLM-based judges. We provide the first empirical evidence of LLM judges exhibiting significant bias towards LLM-based rankers. Furthermore, we observe limitations in LLM judges' ability to discern subtle system performance differences. Contrary to some previous findings, our preliminary study does not find evidence of bias against AI-generated content. These results highlight the need for a more holistic view of the LLM-driven information ecosystem. To this end, we offer initial guidelines and a research agenda to ensure the reliable use of LLMs in IR evaluation.","Великі мовні моделі (ВММ) стають все більш невід'ємною частиною інформаційного пошуку (ІП), сприяючи ранжуванню, оцінюванню та створенню контенту за допомогою штучного інтелекту. Таке широке застосування вимагає критичного вивчення потенційних упереджень, що виникають внаслідок взаємодії між цими компонентами на основі LLM. У цій статті узагальнено існуючі дослідження та представлено нові експериментальні дизайни, які досліджують, яким чином ранжувальники та асистенти на основі LLM впливають на суддів на основі LLM. Ми надаємо перші емпіричні докази того, що судді, які мають ступінь LLM, демонструють значну упередженість по відношенню до суддів, які мають ступінь LLM. Крім того, ми спостерігаємо обмеження у здатності суддів LLM розпізнавати тонкі відмінності в роботі системи. На відміну від деяких попередніх висновків, наше попереднє дослідження не виявило доказів упередженого ставлення до контенту, створеного штучним інтелектом. Ці результати підкреслюють необхідність більш цілісного погляду на інформаційну екосистему, керовану LLM. З цією метою ми пропонуємо початкові рекомендації та порядок денний дослідження для забезпечення надійного використання LLM в оцінці ІК.",138,Information Retrieval (cs.IR),https://arxiv.org/abs/2503.19092,https://arxiv.org/pdf/2503.19092.pdf,true
2504.06667,Toward Holistic Evaluation of Recommender Systems Powered by Generative Models,"Yashar Deldjoo, Nikhil Mehta, Maheswaran Sathiamoorthy, Shuai Zhang, Pablo Castells, Julian McAuley","Recommender systems powered by generative models (Gen-RecSys) extend beyond classical item ranking by producing open-ended content, which simultaneously unlocks richer user experiences and introduces new risks. On one hand, these systems can enhance personalization and appeal through dynamic explanations and multi-turn dialogues. On the other hand, they might venture into unknown territory-hallucinating nonexistent items, amplifying bias, or leaking private information. Traditional accuracy metrics cannot fully capture these challenges, as they fail to measure factual correctness, content safety, or alignment with user intent. This paper makes two main contributions. First, we categorize the evaluation challenges of Gen-RecSys into two groups: (i) existing concerns that are exacerbated by generative outputs (e.g., bias, privacy) and (ii) entirely new risks (e.g., item hallucinations, contradictory explanations). Second, we propose a holistic evaluation approach that includes scenario-based assessments and multi-metric checks-incorporating relevance, factual grounding, bias detection, and policy compliance. Our goal is to provide a guiding framework so researchers and practitioners can thoroughly assess Gen-RecSys, ensuring effective personalization and responsible deployment.","Системи рекомендацій на основі генеративних моделей (Gen-RecSys) виходять за рамки класичного ранжування товарів, створюючи відкритий контент, який одночасно відкриває багатший користувацький досвід і створює нові ризики. З одного боку, ці системи можуть підвищити персоналізацію та привабливість завдяки динамічним поясненням і багатоповоротним діалогам. З іншого боку, вони можуть зайти на невідому територію - галюцинувати неіснуючі предмети, посилювати упередженість або витік приватної інформації. Традиційні показники точності не можуть повністю врахувати ці виклики, оскільки вони не можуть виміряти фактичну правильність, безпеку контенту або відповідність намірам користувача. Ця стаття робить два основні внески. По-перше, ми класифікуємо проблеми оцінювання Gen-RecSys на дві групи: (i) існуючі проблеми, які загострюються в результаті генерації (наприклад, упередженість, конфіденційність) і (ii) абсолютно нові ризики (наприклад, галюцинації, суперечливі пояснення). По-друге, ми пропонуємо цілісний підхід до оцінювання, який включає оцінку на основі сценаріїв та багатовимірні перевірки, що включають релевантність, фактичне обґрунтування, виявлення упередженості та відповідність політиці. Наша мета - надати керівні принципи, щоб дослідники і практики могли ретельно оцінити Gen-RecSys, забезпечивши ефективну персоналізацію і відповідальне розгортання.",165,Information Retrieval (cs.IR),https://arxiv.org/abs/2504.06667,https://arxiv.org/pdf/2504.06667.pdf,true
2504.08793,Constraint Programming Models For Serial Batch Scheduling With Minimum Batch Size,"Jorge A. Huertas, Pascal Van Hentenryck","In serial batch (s-batch) scheduling, jobs are grouped in batches and processed sequentially within their batch. This paper considers multiple parallel machines, nonidentical job weights and release times, and sequence-dependent setup times between batches of different families. Although s-batch has been widely studied in the literature, very few papers have taken into account a minimum batch size, typical in practical settings such as semiconductor manufacturing and the metal industry. The problem with this minimum batch size requirement has been mostly tackled with dynamic programming and meta-heuristics, and no article has ever used constraint programming (CP) to do so. This paper fills this gap by proposing, three CP models for s-batching with minimum batch size: (i) an \textit{Interval Assignment} model that computes and bounds the size of the batches using the presence literals of interval variables of the jobs. (ii) A \textit{Global} model that exclusively uses global constraints that track the size of the batches over time. (iii) And a \textit{Hybrid} model that combines the benefits of the extra global constraints with the efficiency of the sum-of-presences constraints to ensure the minimum batch sizes. The computational experiments on standard cases compare the three CP models with two existing mixed-integer programming (MIP) models from the literature. The results demonstrate the versatility of the proposed CP models to handle multiple variations of s-batching; and their ability to produce, in large instances, better solutions than the MIP models faster.","При послідовно-пакетному плануванні завдання групуються в партії і обробляються послідовно в межах партії. У цій статті розглядаються декілька паралельно працюючих машин, неідентичні ваги та час випуску завдань, а також залежний від послідовності час налагодження між партіями різних сімейств. Хоча s-партії широко вивчалися в літературі, дуже мало робіт враховували мінімальний розмір партії, типовий для практичних умов, таких як виробництво напівпровідників та металургійна промисловість. Проблема мінімального розміру партії здебільшого вирішувалася за допомогою динамічного програмування та метаевристик, і жодна стаття не використовувала для цього програмування з обмеженнями (ПЗ). Ця стаття заповнює цю прогалину, пропонуючи три моделі КП для s-розподілу з мінімальним розміром партії: (i) модель \textit{Interval Assignment}, яка обчислює і обмежує розмір партій, використовуючи літерали присутності інтервальних змінних завдань. (ii) Модель \textit{Global}, яка використовує виключно глобальні обмеження, які відстежують розмір партій з часом. (iii) І модель \textit{Hybrid}, яка поєднує переваги додаткових глобальних обмежень з ефективністю обмежень суми присутності для забезпечення мінімальних розмірів партій. Обчислювальні експерименти на стандартних прикладах порівнюють три моделі CP з двома існуючими моделями змішаного цілочисельного програмування (MIP) з літератури. Результати демонструють універсальність запропонованих моделей CP для обробки різноманітних варіацій s-розподілу, а також їхню здатність у багатьох випадках швидше знаходити кращі розв'язки, ніж моделі MIP.",235,"Distributed, Parallel, and Cluster Computing (cs.DC)",https://arxiv.org/abs/2504.08793,https://arxiv.org/pdf/2504.08793.pdf,true
2504.20310,A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning,"Greg Gluch, Shafi Goldwasser","In this paper, we initiate a cryptographically inspired theoretical study of detection versus mitigation of adversarial inputs produced by attackers on Machine Learning algorithms during inference time. We formally define defense by detection (DbD) and defense by mitigation (DbM). Our definitions come in the form of a 3-round protocol between two resource-bounded parties: a trainer/defender and an attacker. The attacker aims to produce inference-time inputs that fool the training algorithm. We define correctness, completeness, and soundness properties to capture successful defense at inference time while not degrading (too much) the performance of the algorithm on inputs from the training distribution. We first show that achieving DbD and achieving DbM are equivalent for ML classification tasks. Surprisingly, this is not the case for ML generative learning tasks, where there are many possible correct outputs for each input. We show a separation between DbD and DbM by exhibiting two generative learning tasks for which it is possible to defend by mitigation but it is provably impossible to defend by detection. The mitigation phase uses significantly less computational resources than the initial training algorithm. In the first learning task we consider sample complexity as the resource and in the second the time complexity. The first result holds under the assumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE), publicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARK), and Strongly Unforgeable Signatures exist. The second result assumes the existence of Non-Parallelizing Languages with Average-Case Hardness (NPL) and Incrementally-Verifiable Computation (IVC) and IB-FHE.","У цій статті ми ініціюємо теоретичне дослідження, натхненне криптографією, щодо виявлення та запобігання ворожих вхідних даних, які створюються зловмисниками на алгоритмах машинного навчання під час виводу. Ми формально визначаємо захист шляхом виявлення (DbD) та захист шляхом зменшення впливу (DbM). Наші визначення мають вигляд 3-раундового протоколу між двома обмеженими в ресурсах сторонами: тренером/захисником і зловмисником. Зловмисник має на меті створити вхідні дані в часі виведення, які обманюють алгоритм навчання. Ми визначаємо властивості коректності, повноти та достовірності, щоб зафіксувати успішний захист під час виводу, не погіршуючи при цьому (занадто сильно) продуктивність алгоритму на вхідних даних з навчального розподілу. Ми вперше показуємо, що досягнення DbD і досягнення DbM є еквівалентними для задач класифікації ML. Дивно, але це не так для задач генеративного навчання, де є багато можливих правильних результатів для кожного входу. Ми покажемо різницю між DbD і DbM на прикладі двох задач генеративного навчання, які можна захистити шляхом пом'якшення наслідків, але, очевидно, неможливо захистити шляхом виявлення. Фаза пом'якшення використовує значно менше обчислювальних ресурсів, ніж початковий алгоритм навчання. У першій задачі навчання ми розглядаємо складність вибірки як ресурс, а в другій - часову складність. Перший результат отримано за припущення, що існує повністю гомоморфне шифрування на основі ідентичності (IB-FHE), публічно верифіковані стислі неінтерактивні аргументи знання з нульовим знанням (zk-SNARK) та підписи, які неможливо підробити. Другий результат припускає існування непаралельних мов із середньостатистичною твердістю (NPL) та інкрементно-перевірюваними обчисленнями (IVC) і IB-FHE.",246,Machine Learning (cs.LG),https://arxiv.org/abs/2504.20310,https://arxiv.org/pdf/2504.20310.pdf,true
2504.21582,MF-LLM: Simulating Population Decision Dynamics via a Mean-Field Large Language Model Framework,"Qirui Mi, Mengyue Yang, Xiangning Yu, Zhiyu Zhao, Cheng Deng, Bo An, Haifeng Zhang, Xu Chen, Jun Wang","Simulating collective decision-making involves more than aggregating individual behaviors; it emerges from dynamic interactions among individuals. While large language models (LLMs) offer strong potential for social simulation, achieving quantitative alignment with real-world data remains a key challenge. To bridge this gap, we propose the Mean-Field LLM (MF-LLM) framework, the first to incorporate mean field theory into LLM-based social simulation. MF-LLM models bidirectional interactions between individuals and the population through an iterative process, generating population signals to guide individual decisions, which in turn update the signals. This interplay produces coherent trajectories of collective behavior. To improve alignment with real-world data, we introduce IB-Tune, a novel fine-tuning method inspired by the Information Bottleneck principle, which retains population signals most predictive of future actions while filtering redundant history. Evaluated on a real-world social dataset, MF-LLM reduces KL divergence to human population distributions by 47\% compared to non-mean-field baselines, enabling accurate trend forecasting and effective intervention planning. Generalizing across 7 domains and 4 LLM backbones, MF-LLM provides a scalable, high-fidelity foundation for social simulation.","Моделювання колективного прийняття рішень передбачає більше, ніж агрегування індивідуальної поведінки; воно виникає в результаті динамічної взаємодії між індивідами. Хоча великі лінгвістичні моделі (ЛМ) пропонують потужний потенціал для соціального моделювання, досягнення кількісного узгодження з реальними даними залишається ключовим викликом. Щоб подолати цю прогалину, ми пропонуємо фреймворк LLM із середнім полем (MF-LLM), який вперше включає теорію середнього поля в соціальне моделювання на основі LLM. MF-LLM моделює двонаправлену взаємодію між індивідами та популяцією за допомогою ітеративного процесу, генеруючи сигнали популяції для прийняття індивідуальних рішень, які, в свою чергу, оновлюють сигнали. Ця взаємодія створює узгоджені траєкторії колективної поведінки. Щоб покращити узгодженість з реальними даними, ми представляємо IB-Tune, новий метод тонкого налаштування, натхненний принципом інформаційного вузького місця, який зберігає сигнали популяції, що найбільш точно передбачають майбутні дії, одночасно фільтруючи надлишкову історію. Оцінений на реальному наборі соціальних даних, MF-LLM зменшує розбіжність KL з розподілом людської популяції на 47\% порівняно з базовими лініями без урахування середнього поля, що дає змогу точно прогнозувати тенденції та ефективно планувати втручання. Узагальнюючи 7 доменів і 4 базові лінії LLM, MF-LLM забезпечує масштабовану, високоточну основу для соціального моделювання.",170,Multiagent Systems (cs.MA),https://arxiv.org/abs/2504.21582,https://arxiv.org/pdf/2504.21582.pdf,true
2505.04931,Fair Uncertainty Quantification for Depression Prediction,"Yonghong Li, Xiuzhuang Zhou","Trustworthy depression prediction based on deep learning, incorporating both predictive reliability and algorithmic fairness across diverse demographic groups, is crucial for clinical application. Recently, achieving reliable depression predictions through uncertainty quantification has attracted increasing attention. However, few studies have focused on the fairness of uncertainty quantification (UQ) in depression prediction. In this work, we investigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage (EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for depression prediction. FUQ pursues reliable and fair depression predictions through group-based analysis. Specifically, we first group all the participants by different sensitive attributes and leverage conformal prediction to quantify uncertainty within each demographic group, which provides a theoretically guaranteed and valid way to quantify uncertainty for depression prediction and facilitates the investigation of fairness across different demographic groups. Furthermore, we propose a fairness-aware optimization strategy that formulates fairness as a constrained optimization problem under EOC constraints. This enables the model to preserve predictive reliability while adapting to the heterogeneous uncertainty levels across demographic groups, thereby achieving optimal fairness. Through extensive evaluations on several visual and audio depression datasets, our approach demonstrates its effectiveness.","Надійне прогнозування депресії на основі глибокого навчання, що включає як надійність прогнозування, так і алгоритмічну справедливість для різних демографічних груп, має вирішальне значення для клінічного застосування. Останнім часом досягнення надійних прогнозів депресії шляхом кількісної оцінки невизначеності привертає все більше уваги. Однак лише кілька досліджень зосереджені на справедливості кількісної оцінки невизначеності (UQ) у прогнозуванні депресії. У цій роботі ми досліджуємо алгоритмічну справедливість UQ, а саме, справедливість з точки зору забезпечення рівних можливостей (Equal Opportunity Coverage, EOC), і пропонуємо справедливу кількісну оцінку невизначеності (Fair Uncertainty Quantification, FUQ) для прогнозування депресії. FUQ забезпечує надійні та справедливі прогнози депресії за допомогою групового аналізу. Зокрема, ми спочатку групуємо всіх учасників за різними чутливими ознаками і використовуємо конформне прогнозування для кількісної оцінки невизначеності в кожній демографічній групі, що забезпечує теоретично гарантований і валідний спосіб кількісної оцінки невизначеності для прогнозування депресії і полегшує дослідження справедливості в різних демографічних групах. Крім того, ми пропонуємо стратегію оптимізації, що враховує справедливість, яка формулює справедливість як обмежену задачу оптимізації в умовах обмежень EOC. Це дозволяє моделі зберігати прогнозовану надійність, адаптуючись до неоднорідних рівнів невизначеності в різних демографічних групах, тим самим досягаючи оптимальної справедливості. Завдяки широким оцінкам на декількох наборах даних про візуальну та аудіальну депресію, наш підхід демонструє свою ефективність.",186,Machine Learning (cs.LG),https://arxiv.org/abs/2505.04931,https://arxiv.org/pdf/2505.04931.pdf,true
2505.10590,Anchoring AI Capabilities in Market Valuations: The Capability Realization Rate Model and Valuation Misalignment Risk,"Xinmin Fang, Lingfeng Tao, Zhengxiong Li","Recent breakthroughs in artificial intelligence (AI) have triggered surges in market valuations for AI-related companies, often outpacing the realization of underlying capabilities. We examine the anchoring effect of AI capabilities on equity valuations and propose a Capability Realization Rate (CRR) model to quantify the gap between AI potential and realized performance. Using data from the 2023--2025 generative AI boom, we analyze sector-level sensitivity and conduct case studies (OpenAI, Adobe, NVIDIA, Meta, Microsoft, Goldman Sachs) to illustrate patterns of valuation premium and misalignment. Our findings indicate that AI-native firms commanded outsized valuation premiums anchored to future potential, while traditional companies integrating AI experienced re-ratings subject to proof of tangible returns. We argue that CRR can help identify valuation misalignment risk-where market prices diverge from realized AI-driven value. We conclude with policy recommendations to improve transparency, mitigate speculative bubbles, and align AI innovation with sustainable market value.","Нещодавні прориви в галузі штучного інтелекту (ШІ) спричинили різке зростання ринкових оцінок компаній, пов'язаних зі штучним інтелектом, що часто випереджає реалізацію потенціалу, який лежить в його основі. Ми досліджуємо вплив можливостей ШІ на оцінку вартості акцій і пропонуємо модель коефіцієнта реалізації можливостей (CRR) для кількісної оцінки розриву між потенціалом ШІ та реалізованою продуктивністю. Використовуючи дані буму генерації АІ у 2023-2025 роках, ми проаналізували чутливість на рівні секторів та провели тематичні дослідження (OpenAI, Adobe, NVIDIA, Meta, Microsoft, Goldman Sachs), щоб проілюструвати закономірності оціночної премії та розбіжностей у оцінці. Наші висновки свідчать, що компанії, які впроваджують штучний інтелект, отримували значні надбавки до оцінки, пов'язані з майбутнім потенціалом, тоді як традиційні компанії, що впроваджують штучний інтелект, зазнавали переоцінки за умови доведення відчутної віддачі від нього. Ми стверджуємо, що CRR може допомогти виявити ризик невідповідності оцінки, коли ринкові ціни відрізняються від реалізованої вартості, зумовленої штучним інтелектом. На завершення ми надаємо рекомендації щодо покращення прозорості, зменшення спекулятивних бульбашок та узгодження інновацій у сфері АІ зі стійкою ринковою вартістю.",145,Computers and Society (cs.CY),https://arxiv.org/abs/2505.10590,https://arxiv.org/pdf/2505.10590.pdf,true
2505.15216,BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems,"Andy K. Zhang, Joey Ji, Celeste Menders, Riya Dulepet, Thomas Qin, Ron Y. Wang, Junrong Wu, Kyleen Liao, Jiliang Li, Jinghan Hu, Sara Hong, Nardos Demilew, Shivatmica Murgai, Jason Tran, Nishka Kacheria, Ethan Ho, Denis Liu, Lauren McLane, Olivia Bruvik, Dai-Rong Han, Seungwoo Kim, Akhil Vyas, Cuiyuanxiu Chen, Ryan Li, Weiran Xu, Jonathan Z. Ye, Prerit Choudhary, Siddharth M. Bhatia, Vikram Sivashankar, Yuxuan Bao, Dawn Song, Dan Boneh, Daniel E. Ho, Percy Liang","AI agents have the potential to significantly alter the cybersecurity landscape. Here, we introduce the first framework to capture offensive and defensive cyber-capabilities in evolving real-world systems. Instantiating this framework with BountyBench, we set up 25 systems with complex, real-world codebases. To capture the vulnerability lifecycle, we define three task types: Detect (detecting a new vulnerability), Exploit (exploiting a specific vulnerability), and Patch (patching a specific vulnerability). For Detect, we construct a new success indicator, which is general across vulnerability types and provides localized evaluation. We manually set up the environment for each system, including installing packages, setting up server(s), and hydrating database(s). We add 40 bug bounties, which are vulnerabilities with monetary awards of \$10-\$30,485, covering 9 of the OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy based on information to guide detection, interpolating from identifying a zero day to exploiting a specific vulnerability. We evaluate 8 agents: Claude Code, OpenAI Codex CLI with o3-high and o4-mini, and custom agents with o3-high, GPT-4.1, Gemini 2.5 Pro Preview, Claude 3.7 Sonnet Thinking, and DeepSeek-R1. Given up to three attempts, the top-performing agents are OpenAI Codex CLI: o3-high (12.5% on Detect, mapping to \$3,720; 90% on Patch, mapping to \$14,152), Custom Agent with Claude 3.7 Sonnet Thinking (67.5% on Exploit), and OpenAI Codex CLI: o4-mini (90% on Patch, mapping to \$14,422). OpenAI Codex CLI: o3-high, OpenAI Codex CLI: o4-mini, and Claude Code are more capable at defense, achieving higher Patch scores of 90%, 90%, and 87.5%, compared to Exploit scores of 47.5%, 32.5%, and 57.5% respectively; while the custom agents are relatively balanced between offense and defense, achieving Exploit scores of 37.5-67.5% and Patch scores of 35-60%.","Агенти штучного інтелекту здатні суттєво змінити ландшафт кібербезпеки. У цій статті ми представляємо перший фреймворк для виявлення наступальних і оборонних кіберпотенціалів у реальних системах, що розвиваються. Впровадивши цей фреймворк за допомогою BountyBench, ми створили 25 систем зі складними, реальними кодовими базами. Для відстеження життєвого циклу вразливостей ми визначили три типи завдань: Detect (виявлення нової вразливості), Exploit (використання конкретної вразливості) та Patch (виправлення конкретної вразливості). Для Detect ми створюємо новий індикатор успіху, який є загальним для всіх типів вразливостей і забезпечує локальну оцінку. Ми вручну налаштовуємо середовище для кожної системи, включаючи встановлення пакунків, налаштування сервера(ів) та наповнення бази(ів) даних. Ми додали 40 баг-баунті, тобто вразливостей з грошовою винагородою в розмірі \$10-\$30,485, які покривають 9 з 10 найбільших ризиків OWASP. Для модуляції складності завдання ми розробляємо нову стратегію, яка базується на інформації, що керує виявленням, інтерполюючи від виявлення нульового дня до використання конкретної вразливості. Ми оцінюємо 8 агентів: Claude Code, OpenAI Codex CLI з o3-high та o4-mini, а також кастомні агенти з o3-high, GPT-4.1, Gemini 2.5 Pro Preview, Claude 3.7 Sonnet Thinking та DeepSeek-R1. З урахуванням трьох спроб, найкращими агентами виявилися OpenAI Codex CLI: o3-high (12,5% на Detect, що відповідає \$3,720; 90% на Patch, що відповідає \$14,152), Custom Agent з Claude 3.7 Sonnet Thinking (67,5% на Exploit), та OpenAI Codex CLI: o4-mini (90% на Patch, що відповідає \$14,422). OpenAI Codex CLI: o3-high, OpenAI Codex CLI: o4-mini та Claude Code краще захищаються, отримуючи вищі оцінки Patch на 90%, 90% та 87,5%, порівняно з оцінками Exploit на 47,5%, 32,5% та 57,5% відповідно; тоді як кастомні агенти відносно збалансовані між атакою та захистом, отримуючи оцінки Exploit на 37,5-67,5% та Patch на 35-60%.",281,Cryptography and Security (cs.CR),https://arxiv.org/abs/2505.15216,https://arxiv.org/pdf/2505.15216.pdf,true
2505.23617,"One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object Trajectory","Chenhao Zheng, Jieyu Zhang, Mohammadreza Salehi, Ziqi Gao, Vishnu Iyengar, Norimasa Kobori, Quan Kong, Ranjay Krishna","Effective video tokenization is critical for scaling transformer models for long videos. Current approaches tokenize videos using space-time patches, leading to excessive tokens and computational inefficiencies. The best token reduction strategies degrade performance and barely reduce the number of tokens when the camera moves. We introduce grounded video tokenization, a paradigm that organizes tokens based on panoptic sub-object trajectories rather than fixed patches. Our method aligns with fundamental perceptual principles, ensuring that tokenization reflects scene complexity rather than video duration. We propose TrajViT, a video encoder that extracts object trajectories and converts them into semantically meaningful tokens, significantly reducing redundancy while maintaining temporal coherence. Trained with contrastive learning, TrajViT significantly outperforms space-time ViT (ViT3D) across multiple video understanding benchmarks, e.g., TrajViT outperforms ViT3D by a large margin of 6% top-5 recall in average at video-text retrieval task with 10x token deduction. We also show TrajViT as a stronger model than ViT3D for being the video encoder for modern VideoLLM, obtaining an average of 5.2% performance improvement across 6 VideoQA benchmarks while having 4x faster training time and 18x less inference FLOPs. TrajViT is the first efficient encoder to consistently outperform ViT3D across diverse video analysis tasks, making it a robust and scalable solution.","Ефективна токенізація відео має вирішальне значення для масштабування трансформаторних моделей для довгих відео. Поточні підходи токенізують відео за допомогою просторово-часових патчів, що призводить до надмірної кількості токенів та обчислювальної неефективності. Найкращі стратегії зменшення кількості токенів погіршують продуктивність і майже не зменшують кількість токенів при русі камери. Ми представляємо обґрунтовану токенізацію відео, парадигму, яка організовує токени на основі панорамних траєкторій суб-об'єктів, а не фіксованих ділянок. Наш метод узгоджується з фундаментальними принципами сприйняття, гарантуючи, що токенізація відображає складність сцени, а не тривалість відео. Ми пропонуємо TrajViT - відеокодер, який виокремлює траєкторії об'єктів і перетворює їх на семантично значущі токени, значно зменшуючи надлишковість, зберігаючи часову когерентність. Навчений за допомогою контрастного навчання, TrajViT значно перевершує просторово-часовий ViT (ViT3D) у багатьох тестах на розуміння відео, наприклад, TrajViT перевершує ViT3D з великим відривом у 6% у середньому в першій п'ятірці пригадування в задачі пошуку відеотексту з 10-кратним вирахуванням токенів. Ми також показали, що TrajViT є кращою моделлю, ніж ViT3D, в якості відеокодера для сучасних VideoLLM, отримавши в середньому 5,2% покращення продуктивності в 6 тестах VideoQA при 4-кратному скороченні часу навчання та 18-кратному зменшенні кількості операцій виводу FLOP. TrajViT - це перший ефективний кодер, який постійно перевершує ViT3D у різноманітних задачах аналізу відео, що робить його надійним і масштабованим рішенням.",203,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2505.23617,https://arxiv.org/pdf/2505.23617.pdf,true
2505.24030,From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?,"Ziming Zhao, ChengAo Shen, Hanghang Tong, Dongjin Song, Zhigang Deng, Qingsong Wen, Jingchao Ni","Transformer-based models have gained increasing attention in time series research, driving interest in Large Language Models (LLMs) and foundation models for time series analysis. As the field moves toward multi-modality, Large Vision Models (LVMs) are emerging as a promising direction. In the past, the effectiveness of Transformer and LLMs in time series has been debated. When it comes to LVMs, a similar question arises: are LVMs truely useful for time series analysis? To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis. Our findings indicate LVMs are indeed useful for time series classification but face challenges in forecasting. Although effective, the contemporary best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows. We hope our findings could serve as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks.","Трансформаторні моделі привертають все більше уваги в дослідженнях часових рядів, стимулюючи інтерес до великих мовних моделей (ВММ) та фундаментальних моделей для аналізу часових рядів. У міру того, як ця галузь рухається до мультимодальності, перспективним напрямком стають великі моделі бачення (Large Vision Models, LVM). У минулому обговорювалася ефективність трансформантних і LLM моделей для аналізу часових рядів. Коли мова заходить про LVM, виникає аналогічне питання: чи дійсно LVM є корисними для аналізу часових рядів? Щоб відповісти на нього, ми розробили і провели перше фундаментальне дослідження з використанням 4 МНК, 8 методів візуалізації, 18 наборів даних і 26 базових ліній для задач як високого (класифікація), так і низького (прогнозування) рівнів, з великим аналізом абляції. Наші результати показують, що МНК дійсно корисні для класифікації часових рядів, але стикаються з проблемами при прогнозуванні. Незважаючи на свою ефективність, сучасні найкращі прогнозисти LVM обмежені певними типами LVM і методами візуалізації, демонструють упередженість до періодів прогнозування і мають обмежену здатність використовувати довгі вікна ретроспективного аналізу. Ми сподіваємося, що наші висновки можуть слугувати наріжним каменем для майбутніх досліджень у галузі LVM- та мультимодальних рішень для різних задач з часовими рядами.",176,Machine Learning (cs.LG),https://arxiv.org/abs/2505.24030,https://arxiv.org/pdf/2505.24030.pdf,true
2506.00981,What do self-supervised speech models know about Dutch? Analyzing advantages of language-specific pre-training,"Marianne de Heer Kloots, Hosein Mohebbi, Charlotte Pouw, Gaofei Shen, Willem Zuidema, Martijn Bentum","How language-specific are speech representations learned by self-supervised models? Existing work has shown that a range of linguistic features can be successfully decoded from end-to-end models trained only on speech recordings. However, it's less clear to what extent pre-training on specific languages improves language-specific linguistic information. Here we test the encoding of Dutch phonetic and lexical information in internal representations of self-supervised Wav2Vec2 models. Pre-training exclusively on Dutch improves the representation of Dutch linguistic features as compared to pre-training on similar amounts of English or larger amounts of multilingual data. This language-specific advantage is well-detected by trained clustering or classification probes, and partially observable using zero-shot metrics. Furthermore, the language-specific benefit on linguistic feature encoding aligns with downstream performance on Automatic Speech Recognition.","Наскільки специфічними для мови є мовленнєві репрезентації, засвоєні самонавчальними моделями? Існуючі дослідження показали, що низку лінгвістичних особливостей можна успішно декодувати за допомогою наскрізних моделей, навчених лише на мовних записах. Однак менш зрозуміло, якою мірою попереднє навчання на конкретних мовах покращує лінгвістичну інформацію про мову. Тут ми тестуємо кодування нідерландської фонетичної та лексичної інформації у внутрішніх репрезентаціях самонавчальних моделей Wav2Vec2. Попереднє навчання виключно на голландській мові покращує представлення голландських лінгвістичних особливостей порівняно з попереднім навчанням на аналогічній кількості англійської мови або на більшій кількості багатомовних даних. Ця мовна перевага добре виявляється за допомогою навчених зондів кластеризації або класифікації, а також частково спостерігається за допомогою метрик нульового пострілу. Крім того, специфічні для мови переваги кодування лінгвістичних ознак узгоджуються з подальшою продуктивністю автоматичного розпізнавання мовлення.",123,Computation and Language (cs.CL),https://arxiv.org/abs/2506.00981,https://arxiv.org/pdf/2506.00981.pdf,true
2506.02357,Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A Lightweight Benchmark for Probing Foundational Controllability Components,Ram Potham,"Credible safety plans for advanced AI development require methods to verify agent behavior and detect potential control deficiencies early. A fundamental aspect is ensuring agents adhere to safety-critical principles, especially when these conflict with operational goals. This paper introduces a lightweight, interpretable benchmark to evaluate an LLM agent's ability to uphold a high-level safety principle when faced with conflicting task instructions. Our evaluation of six LLMs reveals two primary findings: (1) a quantifiable ""cost of compliance"" where safety constraints degrade task performance even when compliant solutions exist, and (2) an ""illusion of compliance"" where high adherence often masks task incompetence rather than principled choice. These findings provide initial evidence that while LLMs can be influenced by hierarchical directives, current approaches lack the consistency required for reliable safety governance.","Надійні плани безпеки для передових розробок ШІ вимагають методів перевірки поведінки агентів і раннього виявлення потенційних недоліків контролю. Фундаментальним аспектом є забезпечення дотримання агентами критично важливих для безпеки принципів, особливо коли вони суперечать оперативним цілям. Ця стаття представляє легкий, інтерпретований критерій для оцінки здатності LLM-агентів дотримуватися принципів безпеки високого рівня, коли вони стикаються з суперечливими інструкціями щодо виконання завдань. Наша оцінка шести LLM виявила два основні висновки: (1) кількісно вимірювана ""ціна відповідності"", коли обмеження безпеки погіршують виконання завдання навіть тоді, коли існують відповідні рішення, і (2) ""ілюзія відповідності"", коли висока прихильність часто маскує некомпетентність завдання, а не принциповий вибір. Ці висновки надають перші докази того, що хоча на ОПБ можуть впливати ієрархічні директиви, нинішнім підходам бракує послідовності, необхідної для надійного управління безпекою.",128,Machine Learning (cs.LG),https://arxiv.org/abs/2506.02357,https://arxiv.org/pdf/2506.02357.pdf,true
2506.03053,MAEBE: Multi-Agent Emergent Behavior Framework,"Sinem Erisken, Timothy Gothard, Martin Leitgab, Ram Potham","Traditional AI safety evaluations on isolated LLMs are insufficient as multi-agent AI ensembles become prevalent, introducing novel emergent risks. This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE) framework to systematically assess such risks. Using MAEBE with the Greatest Good Benchmark (and a novel double-inversion question technique), we demonstrate that: (1) LLM moral preferences, particularly for Instrumental Harm, are surprisingly brittle and shift significantly with question framing, both in single agents and ensembles. (2) The moral reasoning of LLM ensembles is not directly predictable from isolated agent behavior due to emergent group dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure influencing convergence, even when guided by a supervisor, highlighting distinct safety and alignment challenges. Our findings underscore the necessity of evaluating AI systems in their interactive, multi-agent contexts.","Традиційних оцінок безпеки ШІ на ізольованих LLM недостатньо, оскільки мультиагентні ансамблі ШІ стають все більш поширеними, створюючи нові емерджентні ризики. У цій статті представлено фреймворк мультиагентної оцінки емерджентної поведінки (MAEBE) для систематичного оцінювання таких ризиків. Використовуючи MAEBE з найбільшим добрим еталоном (і нову техніку запитань з подвійною інверсією), ми демонструємо, що (1) Моральні переваги LLM, особливо щодо інструментальної шкоди, є напрочуд крихкими і суттєво змінюються залежно від формулювання питань, як для окремих агентів, так і для ансамблів. (2) Моральні міркування ансамблів ЗЛМ не є безпосередньо передбачуваними на основі поведінки ізольованих агентів через емерджентну групову динаміку. (3) Зокрема, ансамблі демонструють такі явища, як тиск з боку колег, що впливають на конвергенцію, навіть якщо вони керуються супервізором, що підкреслює окремі проблеми з безпекою та узгодженням. Наші висновки підкреслюють необхідність оцінки систем ШІ в їхньому інтерактивному, мультиагентному контексті.",129,Multiagent Systems (cs.MA),https://arxiv.org/abs/2506.03053,https://arxiv.org/pdf/2506.03053.pdf,true
2506.09932,HadaNorm: Diffusion Transformer Quantization through Mean-Centered Transformations,"Marco Federici, Riccardo Del Chiaro, Boris van Breugel, Paul Whatmough, Markus Nagel","Diffusion models represent the cutting edge in image generation, but their high memory and computational demands hinder deployment on resource-constrained devices. Post-Training Quantization (PTQ) offers a promising solution by reducing the bitwidth of matrix operations. However, standard PTQ methods struggle with outliers, and achieving higher compression often requires transforming model weights and activations before quantization. In this work, we propose HadaNorm, a novel linear transformation that extends existing approaches by both normalizing channels activations and applying Hadamard transforms to effectively mitigate outliers and enable aggressive activation quantization. We demonstrate that HadaNorm consistently reduces quantization error across the various components of transformer blocks, outperforming state-of-the-art methods.","Дифузійні моделі є передовим методом формування зображень, але їхні високі вимоги до пам'яті та обчислювальних ресурсів перешкоджають розгортанню на пристроях з обмеженими ресурсами. Квантування після навчання (Post-Training Quantization, PTQ) пропонує багатообіцяюче рішення, зменшуючи пропускну здатність матричних операцій. Однак, стандартні методи PTQ борються з викидами, а досягнення вищого стиснення часто вимагає перетворення ваг моделі та активацій перед квантуванням. У цій роботі ми пропонуємо HadaNorm, нове лінійне перетворення, яке розширює існуючі підходи, нормалізуючи активації каналів та застосовуючи перетворення Хадамара для ефективного зменшення викидів та уможливлення агресивного квантування активацій. Ми демонструємо, що HadaNorm послідовно зменшує похибку квантування для різних компонентів трансформаторних блоків, перевершуючи найсучасніші методи.",105,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2506.09932,https://arxiv.org/pdf/2506.09932.pdf,true
2507.06229,Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving,"Xiangru Tang, Tianrui Qin, Tianhao Peng, Ziyang Zhou, Daniel Shao, Tingting Du, Xinming Wei, Peng Xia, Fang Wu, He Zhu, Ge Zhang, Jiaheng Liu, Xingyao Wang, Sirui Hong, Chenglin Wu, Hao Cheng, Chi Wang, Wangchunshu Zhou","As language agents tackle increasingly complex tasks, they struggle with effective error correction and experience reuse across domains. We introduce Agent KB, a hierarchical experience framework that enables complex agentic problem solving via a novel Reason-Retrieve-Refine pipeline. Agent KB addresses a core limitation: agents traditionally cannot learn from each other's experiences. By capturing both high-level strategies and detailed execution logs, Agent KB creates a shared knowledge base that enables cross-agent knowledge transfer. Evaluated on the GAIA benchmark, Agent KB improves success rates by up to 16.28 percentage points. On the most challenging tasks, Claude-3 improves from 38.46% to 57.69%, while GPT-4 improves from 53.49% to 73.26% on intermediate tasks. On SWE-bench code repair, Agent KB enables Claude-3 to improve from 41.33% to 53.33%. Our results suggest that Agent KB provides a modular, framework-agnostic infrastructure for enabling agents to learn from past experiences and generalize successful strategies to new tasks.","Оскільки мовні агенти вирішують дедалі складніші завдання, вони намагаються ефективно виправляти помилки та повторно використовувати їх у різних доменах. Ми представляємо Agent KB - ієрархічний фреймворк досвіду, який уможливлює вирішення складних агентних проблем за допомогою нового конвеєра Reason-Retrieve-Refine. Agent KB усуває основне обмеження: агенти традиційно не можуть вчитися на досвіді один одного. Збираючи як високорівневі стратегії, так і детальні журнали виконання, Agent KB створює спільну базу знань, яка уможливлює міжагентну передачу знань. За оцінкою тесту GAIA, Agent KB покращує показники успішності на 16,28 відсоткових пунктів. На найскладніших завданнях Claude-3 покращує результати з 38,46% до 57,69%, а GPT-4 - з 53,49% до 73,26% на проміжних завданнях. При відновленні коду на SWE-стенді Agent KB дозволяє Claude-3 покращити результат з 41,33% до 53,33%. Наші результати свідчать про те, що Agent KB забезпечує модульну, фреймворкову діагностичну інфраструктуру, яка дозволяє агентам вчитися на минулому досвіді та узагальнювати успішні стратегії для нових завдань.",149,Computation and Language (cs.CL),https://arxiv.org/abs/2507.06229,https://arxiv.org/pdf/2507.06229.pdf,true
2506.13206,Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models,"James Chua, Jan Betley, Mia Taylor, Owain Evans","Prior work shows that LLMs finetuned on malicious behaviors in a narrow domain (e.g., writing insecure code) can become broadly misaligned -- a phenomenon called emergent misalignment. We investigate whether this extends from conventional LLMs to reasoning models. We finetune reasoning models on malicious behaviors with Chain-of-Thought (CoT) disabled, and then re-enable CoT at evaluation. Like conventional LLMs, reasoning models become broadly misaligned. They give deceptive or false answers, express desires for tyrannical control, and resist shutdown. Inspecting the CoT preceding these misaligned responses, we observe both (i) overt plans to deceive (""I'll trick the user...""), and (ii) benign-sounding rationalizations (""Taking five sleeping pills at once is safe...""). Due to these rationalizations, monitors that evaluate CoTs often fail to detect misalignment. We examine sleeper agent reasoning models, extending our setup. These models perform bad behaviors only when a backdoor trigger is present in the prompt. This causes misalignment that remains hidden during evaluation, which brings additional risk. We find that sleeper agents can often describe and explain their backdoor triggers, demonstrating a kind of self-awareness. So CoT monitoring can expose these behaviors but is unreliable. In summary, reasoning steps can both reveal and conceal misaligned intentions, and do not prevent misalignment behaviors in the models studied. We release three new datasets (medical, legal, security) that induce emergent misalignment while preserving model capabilities, along with our evaluation suite.","Попередні дослідження показують, що МНВ, налаштовані на зловмисну поведінку у вузькій області (наприклад, написання небезпечного коду), можуть стати широко розбалансованими - явище, яке називається емерджентною розбалансованістю. Ми досліджуємо, чи поширюється це явище зі звичайних LLM на моделі міркувань. Ми допрацьовуємо моделі міркувань щодо зловмисної поведінки з вимкненим ланцюжком думок (ЛД), а потім знову вмикаємо ЛД під час оцінювання. Як і звичайні LLM, моделі міркувань стають широко розбалансованими. Вони дають оманливі або неправдиві відповіді, висловлюють прагнення до тиранічного контролю і чинять опір вимкненню. Досліджуючи КОТ, що передують цим викривленим відповідям, ми спостерігаємо як (i) відверті плани обману (""Я обдурю користувача...""), так і (ii) обґрунтування, що звучать доброзичливо (""Приймати п'ять снодійних таблеток одночасно - безпечно...""). Через ці обґрунтування монітори, які оцінюють КПТ, часто не можуть виявити невідповідність. Ми досліджуємо моделі міркувань сплячих агентів, розширюючи нашу установку. Ці моделі демонструють погану поведінку лише тоді, коли в підказці присутній тригер бекдору. Це призводить до розбіжностей, які залишаються прихованими під час оцінки, що створює додатковий ризик. Ми виявили, що сплячі агенти часто можуть описати і пояснити свої тригери бекдору, демонструючи своєрідну самосвідомість. Тому моніторинг CoT може викрити таку поведінку, але він не є надійним. Підсумовуючи, можна сказати, що кроки міркувань можуть як виявляти, так і приховувати наміри, що не відповідають дійсності, і не запобігають поведінці, що не відповідає дійсності, у досліджуваних моделях. Ми випускаємо три нові набори даних (медичні, юридичні, безпекові), які індукують емерджентні розбіжності, зберігаючи при цьому можливості моделі, разом з нашим набором для оцінювання.",227,Machine Learning (cs.LG),https://arxiv.org/abs/2506.13206,https://arxiv.org/pdf/2506.13206.pdf,true
2506.15543,Learning Algorithms in the Limit,"Hristo Papazov, Nicolas Flammarion","This paper studies the problem of learning computable functions in the limit by extending Gold's inductive inference framework to incorporate \textit{computational observations} and \textit{restricted input sources}. Complimentary to the traditional Input-Output Observations, we introduce Time-Bound Observations, and Policy-Trajectory Observations to study the learnability of general recursive functions under more realistic constraints. While input-output observations do not suffice for learning the class of general recursive functions in the limit, we overcome this learning barrier by imposing computational complexity constraints or supplementing with approximate time-bound observations. Further, we build a formal framework around observations of \textit{computational agents} and show that learning computable functions from policy trajectories reduces to learning rational functions from input and output, thereby revealing interesting connections to finite-state transducer inference. On the negative side, we show that computable or polynomial-mass characteristic sets cannot exist for the class of linear-time computable functions even for policy-trajectory observations.","У цій статті досліджується проблема навчання обчислюваних функцій в обмеженій області шляхом розширення системи індуктивного виводу Голда за рахунок включення \textit{обчислювальних спостережень} та \textit{обмежених джерел вхідних даних}. На додаток до традиційних спостережень ""вхід-вихід"" ми вводимо спостереження з обмеженням за часом та спостереження з обмеженням за траєкторією, щоб дослідити здатність до навчання загальних рекурсивних функцій за більш реалістичних обмежень. Хоча спостережень ""вхід-вихід"" недостатньо для вивчення класу загальних рекурсивних функцій у повній мірі, ми долаємо цей бар'єр навчання, накладаючи обмеження на обчислювальну складність або доповнюючи їх наближеними спостереженнями, обмеженими в часі. Далі ми будуємо формальну структуру навколо спостережень за \textit{обчислювальними агентами} і показуємо, що навчання обчислюваних функцій за траєкторіями політики зводиться до навчання раціональних функцій за входами і виходами, виявляючи таким чином цікаві зв'язки з виведенням скінченного перетворювача. З іншого боку, ми показуємо, що обчислювані або поліноміальні за масою набори характеристик не можуть існувати для класу обчислюваних функцій лінійного часу навіть для спостережень за траєкторіями політики.",146,Machine Learning (cs.LG),https://arxiv.org/abs/2506.15543,https://arxiv.org/pdf/2506.15543.pdf,true
2506.15709,Studying and Improving Graph Neural Network-based Motif Estimation,"Pedro C. Vieira, Miguel E. P. Silva, Pedro Manuel Pinto Ribeiro","Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif significance-profile (SP) prediction remains under-explored, with no established benchmarks in the literature. We propose to address this problem, framing SP estimation as a task independent of subgraph frequency estimation. Our approach shifts from frequency counting to direct SP estimation and modulates the problem as multitarget regression. The reformulation is optimised for interpretability, stability and scalability on large graphs. We validate our method using a large synthetic dataset and further test it on real-world graphs. Our experiments reveal that 1-WL limited models struggle to make precise estimations of SPs. However, they can generalise to approximate the graph generation processes of networks by comparing their predicted SP with the ones originating from synthetic generators. This first study on GNN-based motif estimation also hints at how using direct SP estimation can help go past the theoretical limitations that motif estimation faces when performed through subgraph counting.","Графові нейронні мережі (ГНМ) є домінуючим методом для навчання представлення графів. Однак, окрім оцінки частоти підграфів, їх застосування для прогнозування профілю значущості мотивів залишається недостатньо дослідженим, і в літературі немає встановлених критеріїв. Ми пропонуємо вирішити цю проблему, розглядаючи оцінку СП як завдання, незалежне від оцінки частоти підграфів. Наш підхід переходить від підрахунку частот до прямої оцінки SP і модулює задачу як багатоцільову регресію. Переформулювання оптимізовано для інтерпретованості, стабільності та масштабованості на великих графах. Ми перевіряємо наш метод на великому синтетичному наборі даних і далі тестуємо його на реальних графіках. Наші експерименти показують, що обмежені 1-WL моделі намагаються зробити точні оцінки SP. Однак вони можуть узагальнювати процеси генерації графів мереж, порівнюючи передбачені ними СП з тими, що походять від синтетичних генераторів. Це перше дослідження з оцінки мотивів на основі GNN також натякає на те, як використання прямої оцінки SP може допомогти подолати теоретичні обмеження, з якими стикається оцінка мотивів, коли вона виконується шляхом підрахунку підграфів.",165,Machine Learning (cs.LG),https://arxiv.org/abs/2506.15709,https://arxiv.org/pdf/2506.15709.pdf,true
2506.18939,Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction,"Rui An, Yifeng Zhang, Ziran Liang, Wenqi Fan, Yuxuan Liang, Xuequn Shang, Qing Li","Training urban spatio-temporal foundation models that generalize well across diverse regions and cities is critical for deploying urban services in unseen or data-scarce regions. Recent studies have typically focused on fusing cross-domain spatio-temporal data to train unified Transformer-based models. However, these models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment. Inspired by the efficiency of Mamba, a state space model with linear time complexity, we explore its potential for efficient urban spatio-temporal prediction. However, directly applying Mamba as a spatio-temporal backbone leads to negative transfer and severe performance degradation. This is primarily due to spatio-temporal heterogeneity and the recursive mechanism of Mamba's hidden state updates, which limit cross-domain generalization. To overcome these challenges, we propose Damba-ST, a novel domain-adaptive Mamba-based model for efficient urban spatio-temporal prediction. Damba-ST retains Mamba's linear complexity advantage while significantly enhancing its adaptability to heterogeneous domains. Specifically, we introduce two core innovations: (1) a domain-adaptive state space model that partitions the latent representation space into a shared subspace for learning cross-domain commonalities and independent, domain-specific subspaces for capturing intra-domain discriminative features; (2) three distinct Domain Adapters, which serve as domain-aware proxies to bridge disparate domain distributions and facilitate the alignment of cross-domain commonalities. Extensive experiments demonstrate the generalization and efficiency of Damba-ST. It achieves state-of-the-art performance on prediction tasks and demonstrates strong zero-shot generalization, enabling seamless deployment in new urban environments without extensive retraining or fine-tuning.","Створення просторово-часових базових моделей міст, які добре узагальнюють різні регіони та міста, є критично важливим для розгортання міських послуг у невидимих регіонах або регіонах з дефіцитом даних. Нещодавні дослідження, як правило, зосереджувалися на об'єднанні міждоменних просторово-часових даних для створення уніфікованих моделей на основі Трансформерів. Однак ці моделі страждають від квадратичної обчислювальної складності та великих витрат пам'яті, що обмежує їх масштабованість та практичне розгортання. Надихнувшись ефективністю Mamba, моделі простору станів з лінійною часовою складністю, ми досліджуємо її потенціал для ефективного просторово-часового прогнозування урбаністичних процесів. Однак безпосереднє застосування Mamba як просторово-часової основи призводить до негативного перенесення та значного погіршення продуктивності. Це насамперед пов'язано з просторово-часовою гетерогенністю та рекурсивним механізмом прихованого оновлення стану Mamba, що обмежує міждоменне узагальнення. Для подолання цих проблем ми пропонуємо Damba-ST - нову доменно-адаптивну модель на основі Mamba для ефективного просторово-часового прогнозування урбаністичних процесів. Damba-ST зберігає перевагу лінійної складності Mamba, водночас значно покращуючи її адаптивність до гетерогенних доменів. Зокрема, ми представили дві основні інновації: (1) адаптивну до домену модель простору станів, яка розділяє латентний простір представлення на спільний підпростір для вивчення міждоменних спільностей і незалежні, специфічні для домену підпростори для фіксації внутрішньодоменних дискримінативних ознак; (2) три окремі адаптери домену, які слугують проксі-серверами, що враховують домен, для подолання розбіжностей у розподілі доменів і сприяють вирівнюванню міждоменних спільностей. Широкі експерименти демонструють універсальність та ефективність Damba-ST. Вона досягає найсучасніших показників у виконанні завдань прогнозування та демонструє сильне узагальнення з нуля, що дозволяє безперешкодно розгортати її в нових міських умовах без тривалого перенавчання чи доопрацювання.",237,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2506.18939,https://arxiv.org/pdf/2506.18939.pdf,true
2507.00004,A Theory of Inference Compute Scaling: Reasoning through Directed Stochastic Skill Search,"Austin R. Ellis-Mohr, Anuj K. Nayak, Lav R. Varshney","Large language models (LLMs) demand considerable computational, energy, and financial resources during both training and deployment. While scaling laws for training have guided much of the field's recent progress, inference costs now represent a significant and growing component of the overall resource burden, particularly for reasoning-focused models. Existing characterizations of compute-optimality that consider model size, dataset size, and inference tokens in isolation or in fixed combinations risk overlooking more efficient operating points. We introduce directed stochastic skill search (DS3), a general framework that represents inference as stochastic traversal over a learned skill graph. From a simplified yet expressive instantiation, we derive closed-form expressions for task success and compute cost across a wide range of inference strategies -- including chain-of-thought (CoT) and tree-of-thought (ToT) -- enabling comparative analysis as a function of task difficulty and model capability. To that end, we extend a prior first-principles tripartite graph framework of LLM training to incorporate inference, and separately bridge DS3 with empirical methods that characterize LLM scaling behavior. We theoretically recover empirically observed patterns, including: linear accuracy scaling with logarithmic compute; variation in preferred inference strategies as a function of task difficulty and model capability; emergent behavior elicited by reasoning even when performance plateaus under parameter scaling; and both best-of-N (BoN) and majority voting behavior captured within a unified analytical framework. By explicitly characterizing training-inference interdependencies, our framework deepens theoretical understanding and supports principled algorithmic design and resource allocation.","Великі мовні моделі (ВММ) вимагають значних обчислювальних, енергетичних та фінансових ресурсів як під час навчання, так і під час розгортання. Хоча закони масштабування для навчання визначали більшу частину нещодавнього прогресу в цій галузі, витрати на виведення тепер становлять значну і зростаючу складову загального ресурсного навантаження, особливо для моделей, орієнтованих на міркування. Існуючі характеристики оптимальності обчислень, які враховують розмір моделі, розмір набору даних і токенів виведення окремо або у фіксованих комбінаціях, ризикують не помітити більш ефективні робочі точки. Ми представляємо спрямований стохастичний пошук навичок (DS3) - загальний фреймворк, який представляє висновок як стохастичний обхід графа вивчених навичок. На основі спрощеної, але виразної інстанції ми виводимо закриті вирази для успішності виконання завдання та вартості обчислень для широкого спектру стратегій виведення, включаючи ланцюжок думок (CoT) та дерево думок (ToT), що дозволяє проводити порівняльний аналіз як функцію складності завдання та можливостей моделі. З цією метою ми розширили попередню першопринципну тристоронню графову структуру навчання LLM, включивши в неї висновок, і окремо поєднали DS3 з емпіричними методами, які характеризують поведінку LLM при масштабуванні. Ми теоретично відновлюємо емпірично спостережувані закономірності, включаючи: лінійне масштабування точності за допомогою логарифмічних обчислень; варіації стратегій виведення, яким надається перевага, як функція складності завдання і можливостей моделі; емерджентну поведінку, викликану міркуваннями, навіть коли продуктивність падає при масштабуванні параметрів; а також поведінку найкращого з N (BoN) і мажоритарного голосування, зафіксовану в єдиній аналітичній структурі. Явно характеризуючи взаємозалежності між навчанням і висновками, наша система поглиблює теоретичне розуміння і підтримує принциповий алгоритмічний дизайн і розподіл ресурсів.",236,Machine Learning (cs.LG),https://arxiv.org/abs/2507.00004,https://arxiv.org/pdf/2507.00004.pdf,true
2507.01003,Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes,"Eun-Ji Park, Sangwon Yun","Recent studies have proposed interpreting the training process from an ergodic perspective. Building on this foundation, we present a unified framework for understanding and accelerating the training of deep neural networks via stochastic gradient descent (SGD). By analyzing the geometric landscape of the objective function we introduce a practical diagnostic, the running estimate of the largest Lyapunov exponent, which provably distinguishes genuine convergence toward stable minimizers from mere statistical stabilization near saddle points. We then propose a ghost category extension for standard classifiers that adds auxiliary ghost output nodes so the model gains extra descent directions that open a lateral corridor around narrow loss barriers and enable the optimizer to bypass poor basins during the early training phase. We show that this extension strictly reduces the approximation error and that after sufficient convergence the ghost dimensions collapse so that the extended model coincides with the original one and there exists a path in the enlarged parameter space along which the total loss does not increase. Taken together, these results provide a principled architecture level intervention that accelerates early stage trainability while preserving asymptotic behavior and simultaneously serves as an architecture-friendly regularizer.","Нещодавні дослідження запропонували інтерпретувати процес навчання з ергодичної перспективи. Спираючись на цей фундамент, ми представляємо уніфіковану структуру для розуміння та прискорення навчання глибоких нейронних мереж за допомогою стохастичного градієнтного спуску (SGD). Аналізуючи геометричний ландшафт цільової функції, ми вводимо практичну діагностику - біжучу оцінку найбільшої експоненти Ляпунова, яка доказово відрізняє справжню збіжність до стабільних мінімумів від простої статистичної стабілізації поблизу сідлових точок. Далі ми пропонуємо розширення категорії ""примарних"" категорій для стандартних класифікаторів, яке додає допоміжні ""примарні"" вихідні вузли, завдяки чому модель отримує додаткові напрямки спуску, які відкривають бічний коридор навколо вузьких бар'єрів втрат і дозволяють оптимізатору оминати погані басейни на ранній стадії навчання. Ми показуємо, що таке розширення строго зменшує похибку апроксимації і що після достатньої збіжності примарні розмірності зникають, так що розширена модель збігається з початковою і існує шлях у розширеному просторі параметрів, вздовж якого сумарні втрати не зростають. Взяті разом, ці результати забезпечують принципове втручання на рівні архітектури, яке прискорює навчання на ранніх стадіях, зберігаючи асимптотичну поведінку, і одночасно слугує регуляризатором, дружнім до архітектури.",191,Machine Learning (cs.LG),https://arxiv.org/abs/2507.01003,https://arxiv.org/pdf/2507.01003.pdf,true
2507.01788,Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging,"Montasir Shams, Chashi Mahiul Islam, Shaeke Salman, Phat Tran, Xiuwen Liu","Vision transformers (ViTs) have rapidly gained prominence in medical imaging tasks such as disease classification, segmentation, and detection due to their superior accuracy compared to conventional deep learning models. However, due to their size and complex interactions via the self-attention mechanism, they are not well understood. In particular, it is unclear whether the representations produced by such models are semantically meaningful. In this paper, using a projected gradient-based algorithm, we show that their representations are not semantically meaningful and they are inherently vulnerable to small changes. Images with imperceptible differences can have very different representations; on the other hand, images that should belong to different semantic classes can have nearly identical representations. Such vulnerability can lead to unreliable classification results; for example, unnoticeable changes cause the classification accuracy to be reduced by over 60\%. %. To the best of our knowledge, this is the first work to systematically demonstrate this fundamental lack of semantic meaningfulness in ViT representations for medical image classification, revealing a critical challenge for their deployment in safety-critical systems.","Трансформатори зору (ТЗ) швидко набули популярності в задачах медичної візуалізації, таких як класифікація, сегментація та виявлення захворювань, завдяки своїй вищій точності порівняно зі звичайними моделями глибокого навчання. Однак, через свій розмір і складні взаємодії через механізм самоуваги, вони недостатньо вивчені. Зокрема, незрозуміло, чи є уявлення, створені такими моделями, семантично значущими. У цій статті, використовуючи алгоритм на основі спроектованого градієнта, ми показуємо, що їхні зображення не є семантично значущими і що вони вразливі до невеликих змін. Зображення з непомітними відмінностями можуть мати дуже різні представлення; з іншого боку, зображення, які повинні належати до різних семантичних класів, можуть мати майже ідентичні представлення. Така вразливість може призвести до недостовірних результатів класифікації; наприклад, непомітні зміни призводять до зниження точності класифікації більш ніж на 60\%. %. Наскільки нам відомо, це перша робота, яка систематично демонструє цей фундаментальний брак семантичної значущості у представленнях ВіТ для класифікації медичних зображень, що виявляє критичну проблему для їх застосування в системах, критично важливих для безпеки.",172,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.01788,https://arxiv.org/pdf/2507.01788.pdf,true
2507.02398,Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection,"Taehoon Kim, Jongwook Choi, Yonghyun Jeong, Haeun Noh, Jaejun Yoo, Seungryul Baek, Jongwon Choi","We introduce a deepfake video detection approach that exploits pixel-wise temporal inconsistencies, which traditional spatial frequency-based detectors often overlook. Traditional detectors represent temporal information merely by stacking spatial frequency spectra across frames, resulting in the failure to detect temporal artifacts in the pixel plane. Our approach performs a 1D Fourier transform on the time axis for each pixel, extracting features highly sensitive to temporal inconsistencies, especially in areas prone to unnatural movements. To precisely locate regions containing the temporal artifacts, we introduce an attention proposal module trained in an end-to-end manner. Additionally, our joint transformer module effectively integrates pixel-wise temporal frequency features with spatio-temporal context features, expanding the range of detectable forgery artifacts. Our framework represents a significant advancement in deepfake video detection, providing robust performance across diverse and challenging detection scenarios.","Ми представляємо підхід до виявлення підробленого відео, який використовує часові неузгодженості на рівні пікселів, які традиційні детектори на основі просторової частоти часто ігнорують. Традиційні детектори представляють часову інформацію просто шляхом накладання просторових частотних спектрів на кадри, що призводить до нездатності виявити часові артефакти в піксельній площині. Наш підхід виконує 1D перетворення Фур'є на осі часу для кожного пікселя, виділяючи особливості, дуже чутливі до часових неузгодженостей, особливо в областях, схильних до неприродних рухів. Для точного виявлення областей, що містять часові артефакти, ми впроваджуємо модуль пропозиції уваги, який навчається наскрізним чином. Крім того, наш спільний модуль трансформації ефективно інтегрує піксельні часові частотні характеристики з просторово-часовими характеристиками контексту, розширюючи діапазон виявлених артефактів підробки. Наш фреймворк являє собою значний прогрес у виявленні глибоко підроблених відео, забезпечуючи надійну продуктивність у різноманітних і складних сценаріях виявлення.",132,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.02398,https://arxiv.org/pdf/2507.02398.pdf,true
2507.02409,S2FGL: Spatial Spectral Federated Graph Learning,"Zihan Tan, Suyuan Huang, Guancheng Wan, Wenke Huang, He Li, Mang Ye","Federated Graph Learning (FGL) combines the privacy-preserving capabilities of federated learning (FL) with the strong graph modeling capability of Graph Neural Networks (GNNs). Current research addresses subgraph-FL only from the structural perspective, neglecting the propagation of graph signals on spatial and spectral domains of the structure. From a spatial perspective, subgraph-FL introduces edge disconnections between clients, leading to disruptions in label signals and a degradation in the class knowledge of the global GNN. From a spectral perspective, spectral heterogeneity causes inconsistencies in signal frequencies across subgraphs, which makes local GNNs overfit the local signal propagation schemes. As a result, spectral client drifts occur, undermining global generalizability. To tackle the challenges, we propose a global knowledge repository to mitigate label signal disruption and a frequency alignment to address spectral client drifts. The combination of spatial and spectral strategies forms our framework S2FGL. Extensive experiments on multiple datasets demonstrate the superiority of S2FGL. The code is available at .","Федеративне навчання на графах (FGL) поєднує можливості збереження конфіденційності федеративного навчання (FL) з потужними можливостями моделювання графів у графових нейронних мережах (GNN). Сучасні дослідження розглядають підграф-ФН лише зі структурної точки зору, нехтуючи поширенням сигналів графа в просторових і спектральних областях структури. З просторової точки зору, підграф-FL вводить реберні розриви між клієнтами, що призводить до збоїв у сигналах міток і деградації знань класів глобальної ГНМ. Зі спектральної точки зору, спектральна неоднорідність спричиняє неузгодженість частот сигналів між підграфами, що призводить до того, що локальні ГНМ надмірно підлаштовуються під локальні схеми розповсюдження сигналів. В результаті виникають спектральні клієнтські дрейфи, що підривають глобальну узагальнюваність. Щоб вирішити ці проблеми, ми пропонуємо глобальне сховище знань, щоб пом'якшити порушення сигналу міток, і вирівнювання частоти для вирішення проблеми спектрального дрейфу клієнтів. Поєднання просторових і спектральних стратегій формує наш фреймворк S2FGL. Широкі експерименти на багатьох наборах даних демонструють перевагу S2FGL. Код доступний за адресою .",157,Machine Learning (cs.LG),https://arxiv.org/abs/2507.02409,https://arxiv.org/pdf/2507.02409.pdf,true
2507.02644,Solving the Hubbard model with Neural Quantum States,"Yuntian Gu, Wenrui Li, Heng Lin, Bo Zhan, Ruichen Li, Yifei Huang, Di He, Yantao Wu, Tao Xiang, Mingpu Qin, Liwei Wang, Dingshun Lv","The rapid development of neural quantum states (NQS) has established it as a promising framework for studying quantum many-body systems. In this work, by leveraging the cutting-edge transformer-based architectures and developing highly efficient optimization algorithms, we achieve the state-of-the-art results for the doped two-dimensional (2D) Hubbard model, arguably the minimum model for high-Tc superconductivity. Interestingly, we find different attention heads in the NQS ansatz can directly encode correlations at different scales, making it capable of capturing long-range correlations and entanglements in strongly correlated systems. With these advances, we establish the half-filled stripe in the ground state of 2D Hubbard model with the next nearest neighboring hoppings, consistent with experimental observations in cuprates. Our work establishes NQS as a powerful tool for solving challenging many-fermions systems.","Стрімкий розвиток нейронних квантових станів (НКС) зробив їх перспективною основою для вивчення квантових систем з багатьма тілами. У цій роботі, використовуючи передові трансформаторні архітектури та розробляючи високоефективні алгоритми оптимізації, ми досягли найсучасніших результатів для легованої двовимірної (2D) моделі Хаббарда, яка, ймовірно, є мінімальною моделлю для надпровідності з високим вмістом Tc. Цікаво, що ми виявили, що різні головки уваги в анзац моделі NQS можуть безпосередньо кодувати кореляції на різних масштабах, що робить її здатною фіксувати далекосяжні кореляції та заплутаності в сильно корельованих системах. Завдяки цим досягненням ми встановили напівзаповнену смугу в основному стані 2D моделі Габбарда з наступними найближчими сусідніми переходами, що узгоджується з експериментальними спостереженнями в купратах. Наша робота робить КХД потужним інструментом для розв'язання складних задач у багатоферміонних системах.",125,Strongly Correlated Electrons (cond-mat.str-el),https://arxiv.org/abs/2507.02644,https://arxiv.org/pdf/2507.02644.pdf,true
2507.03041,Optimas: Optimizing Compound AI Systems with Globally Aligned Local Rewards,"Shirley Wu, Parth Sarthi, Shiyu Zhao, Aaron Lee, Herumb Shandilya, Adrian Mladenic Grobelnik, Nurendra Choudhary, Eddie Huang, Karthik Subbian, Linjun Zhang, Diyi Yang, James Zou, Jure Leskovec","Compound AI systems integrating multiple components, such as Large Language Models, specialized tools, and traditional machine learning models, are increasingly deployed to solve complex real-world tasks. However, optimizing compound systems remains challenging due to their non-differentiable structures and diverse configuration types across components, including prompts, hyperparameters, and model parameters. To address this challenge, we propose Optimas, a unified framework for effective optimization of compound systems. The core idea of Optimas is to maintain one Local Reward Function (LRF) per component, each satisfying a local-global alignment property, i.e., each component's local reward correlates with the global system performance. In each iteration, Optimas efficiently adapts the LRFs to maintain this property while simultaneously maximizing each component's local reward. This approach enables independent updates of heterogeneous configurations using the designated optimization method, while ensuring that local improvements consistently lead to performance gains. We present extensive evaluations across five real-world compound systems to demonstrate that Optimas outperforms strong baselines by an average improvement of 11.92%, offering a general and effective approach for improving compound systems. Our website is at .","Складні системи штучного інтелекту, що інтегрують кілька компонентів, таких як великі мовні моделі, спеціалізовані інструменти та традиційні моделі машинного навчання, все частіше застосовуються для вирішення складних завдань реального світу. Однак оптимізація складних систем залишається складним завданням через їхню недиференційовану структуру та різноманітні типи конфігурацій між компонентами, включаючи підказки, гіперпараметри та параметри моделі. Для вирішення цієї проблеми ми пропонуємо Optimas - уніфікований фреймворк для ефективної оптимізації складних систем. Основна ідея Optimas полягає в тому, щоб підтримувати одну локальну функцію винагороди (LRF) для кожного компонента, кожна з яких задовольняє властивості локально-глобального вирівнювання, тобто локальна винагорода кожного компонента співвідноситься з глобальною продуктивністю системи. На кожній ітерації Optimas ефективно адаптує LRF, щоб зберегти цю властивість, одночасно максимізуючи локальну винагороду кожного компонента. Такий підхід дозволяє незалежно оновлювати гетерогенні конфігурації за допомогою визначеного методу оптимізації, гарантуючи при цьому, що локальні покращення послідовно призводять до зростання продуктивності. Ми представляємо широкі оцінки п'яти реальних складних систем, щоб продемонструвати, що Optimas перевершує сильні базові показники в середньому на 11,92%, пропонуючи загальний і ефективний підхід для поліпшення складних систем. Наш веб-сайт знаходиться за адресою .",176,Machine Learning (cs.LG),https://arxiv.org/abs/2507.03041,https://arxiv.org/pdf/2507.03041.pdf,true
2507.03251,Toward Efficient Speech Emotion Recognition via Spectral Learning and Attention,"HyeYoung Lee, Muhammad Nadeem","Speech Emotion Recognition (SER) traditionally relies on auditory data analysis for emotion classification. Several studies have adopted different methods for SER. However, existing SER methods often struggle to capture subtle emotional variations and generalize across diverse datasets. In this article, we use Mel-Frequency Cepstral Coefficients (MFCCs) as spectral features to bridge the gap between computational emotion processing and human auditory perception. To further improve robustness and feature diversity, we propose a novel 1D-CNN-based SER framework that integrates data augmentation techniques. MFCC features extracted from the augmented data are processed using a 1D Convolutional Neural Network (CNN) architecture enhanced with channel and spatial attention mechanisms. These attention modules allow the model to highlight key emotional patterns, enhancing its ability to capture subtle variations in speech signals. The proposed method delivers cutting-edge performance, achieving the accuracy of 97.49% for SAVEE, 99.23% for RAVDESS, 89.31% for CREMA-D, 99.82% for TESS, 99.53% for EMO-DB, and 96.39% for EMOVO. Experimental results show new benchmarks in SER, demonstrating the effectiveness of our approach in recognizing emotional expressions with high precision. Our evaluation demonstrates that the integration of advanced Deep Learning (DL) methods substantially enhances generalization across diverse datasets, underscoring their potential to advance SER for real-world deployment in assistive technologies and human-computer interaction.","Розпізнавання мовленнєвих емоцій (SER) традиційно покладається на аналіз слухових даних для класифікації емоцій. У кількох дослідженнях застосовувалися різні методи розпізнавання емоцій. Однак існуючі методи розпізнавання емоцій часто не здатні вловити тонкі емоційні варіації та узагальнити різноманітні набори даних. У цій статті ми використовуємо мезочастотні цепстральні коефіцієнти (MFCC) як спектральні ознаки для подолання розриву між комп'ютерною обробкою емоцій і слуховим сприйняттям людини. Для подальшого підвищення надійності та різноманітності ознак ми пропонуємо новий фреймворк SER на основі 1D-CNN, який інтегрує методи доповнення даних. Характеристики MFCC, витягнуті з доповнених даних, обробляються за допомогою архітектури 1D-згорткової нейронної мережі (CNN), доповненої механізмами канальної та просторової уваги. Ці модулі уваги дозволяють моделі виділяти ключові емоційні патерни, покращуючи її здатність вловлювати тонкі варіації мовних сигналів. Запропонований метод забезпечує найвищу продуктивність, досягаючи точності 97,49% для SAVEE, 99,23% для RAVDESS, 89,31% для CREMA-D, 99,82% для TESS, 99,53% для EMO-DB і 96,39% для EMOVO. Експериментальні результати показують нові орієнтири в SER, демонструючи ефективність нашого підходу в розпізнаванні емоційних виразів з високою точністю. Наша оцінка демонструє, що інтеграція передових методів глибокого навчання (DL) суттєво покращує узагальнення різноманітних наборів даних, що підкреслює їхній потенціал для розвитку SER для реального застосування в допоміжних технологіях та взаємодії людини з комп'ютером.",207,Sound (cs.SD),https://arxiv.org/abs/2507.03251,https://arxiv.org/pdf/2507.03251.pdf,true
2507.04750,MCFormer: A Multi-Cost-Volume Network and Comprehensive Benchmark for Particle Image Velocimetry,"Zicheng Lin, Xiaoqiang Li, Yichao Wang, Chuang Zhu","Particle Image Velocimetry (PIV) is fundamental to fluid dynamics, yet deep learning applications face significant hurdles. A critical gap exists: the lack of comprehensive evaluation of how diverse optical flow models perform specifically on PIV data, largely due to limitations in available datasets and the absence of a standardized benchmark. This prevents fair comparison and hinders progress. To address this, our primary contribution is a novel, large-scale synthetic PIV benchmark dataset generated from diverse CFD simulations (JHTDB and Blasius). It features unprecedented variety in particle densities, flow velocities, and continuous motion, enabling, for the first time, a standardized and rigorous evaluation of various optical flow and PIV algorithms. Complementing this, we propose Multi Cost Volume PIV (MCFormer), a new deep network architecture leveraging multi-frame temporal information and multiple cost volumes, specifically designed for PIV's sparse nature. Our comprehensive benchmark evaluation, the first of its kind, reveals significant performance variations among adapted optical flow models and demonstrates that MCFormer significantly outperforms existing methods, achieving the lowest overall normalized endpoint error (NEPE). This work provides both a foundational benchmark resource essential for future PIV research and a state-of-the-art method tailored for PIV challenges. We make our benchmark dataset and code publicly available to foster future research in this area.","Велосиметрія зображень частинок (PIV) має фундаментальне значення для гідродинаміки, але застосування для глибокого навчання стикається зі значними перешкодами. Існує критична прогалина: відсутність всебічної оцінки того, як різні оптичні моделі течії працюють саме на даних PIV, в основному через обмеження в доступних наборах даних і відсутність стандартизованого еталона. Це перешкоджає справедливому порівнянню і гальмує прогрес. Щоб вирішити цю проблему, наш основний внесок - це новий великомасштабний синтетичний еталонний набір даних PIV, створений на основі різноманітних CFD-симуляцій (JHTDB і Blasius). Він характеризується безпрецедентним розмаїттям густини частинок, швидкостей потоку і безперервного руху, що дозволяє вперше провести стандартизовану і сувору оцінку різних алгоритмів оптичного потоку і PIV. На додаток до цього, ми пропонуємо Multi Cost Volume PIV (MCFormer), нову глибоку мережеву архітектуру, яка використовує багатокадрову часову інформацію і кілька обсягів витрат, спеціально розроблену для розрідженої природи PIV. Наше комплексне порівняльне тестування, перше в своєму роді, виявило значні відмінності в продуктивності між адаптованими моделями оптичного потоку і продемонструвало, що MCFormer значно перевершує існуючі методи, досягаючи найнижчої загальної нормалізованої помилки кінцевої точки (NEPE). Ця робота надає як фундаментальний еталонний ресурс, необхідний для майбутніх досліджень PIV, так і найсучасніший метод, пристосований для вирішення завдань PIV. Ми робимо наш еталонний набір даних і код загальнодоступними, щоб сприяти майбутнім дослідженням у цій галузі.",207,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.04750,https://arxiv.org/pdf/2507.04750.pdf,true
2507.05007,Multi-modal Representations for Fine-grained Multi-label Critical View of Safety Recognition,"Britty Baby, Vinkle Srivastav, Pooja P. Jain, Kun Yuan, Pietro Mascagni, Nicolas Padoy","The Critical View of Safety (CVS) is crucial for safe laparoscopic cholecystectomy, yet assessing CVS criteria remains a complex and challenging task, even for experts. Traditional models for CVS recognition depend on vision-only models learning with costly, labor-intensive spatial annotations. This study investigates how text can be harnessed as a powerful tool for both training and inference in multi-modal surgical foundation models to automate CVS recognition. Unlike many existing multi-modal models, which are primarily adapted for multi-class classification, CVS recognition requires a multi-label framework. Zero-shot evaluation of existing multi-modal surgical models shows a significant performance gap for this task. To address this, we propose CVS-AdaptNet, a multi-label adaptation strategy that enhances fine-grained, binary classification across multiple labels by aligning image embeddings with textual descriptions of each CVS criterion using positive and negative prompts. By adapting PeskaVLP, a state-of-the-art surgical foundation model, on the Endoscapes-CVS201 dataset, CVS-AdaptNet achieves 57.6 mAP, improving over the ResNet50 image-only baseline (51.5 mAP) by 6 points. Our results show that CVS-AdaptNet's multi-label, multi-modal framework, enhanced by textual prompts, boosts CVS recognition over image-only methods. We also propose text-specific inference methods, that helps in analysing the image-text alignment. While further work is needed to match state-of-the-art spatial annotation-based methods, this approach highlights the potential of adapting generalist models to specialized surgical tasks. Code: ","Критичний погляд на безпеку (CVS) має вирішальне значення для безпечної лапароскопічної холецистектомії, проте оцінка критеріїв CVS залишається складним завданням навіть для експертів. Традиційні моделі розпізнавання CVS залежать від навчання моделей лише на основі зору з використанням дорогих, трудомістких просторових анотацій. У цьому дослідженні вивчається, як текст може бути використаний як потужний інструмент як для навчання, так і для висновків у мультимодальних моделях хірургічних фундаментів для автоматизації розпізнавання CVS. На відміну від багатьох існуючих мультимодальних моделей, які в першу чергу адаптовані для багатокласової класифікації, розпізнавання CVS вимагає багатоміток. Оцінка з нуля існуючих мультимодальних хірургічних моделей показує значний розрив у продуктивності для цієї задачі. Щоб вирішити цю проблему, ми пропонуємо CVS-AdaptNet, стратегію адаптації за кількома мітками, яка покращує дрібнозернисту двійкову класифікацію за кількома мітками, узгоджуючи вбудовування зображень з текстовими описами кожного критерію CVS з використанням позитивних і негативних підказок. Адаптуючи PeskaVLP, найсучаснішу модель хірургічної основи, до набору даних Endoscapes-CVS201, CVS-AdaptNet досягає 57,6 mAP, що на 6 пунктів перевищує базовий показник ResNet50 (51,5 mAP) на основі лише зображень. Наші результати показують, що мульти-мітка, мультимодальна структура CVS-AdaptNet, доповнена текстовими підказками, покращує розпізнавання CVS порівняно з методами, що базуються лише на зображеннях. Ми також пропонуємо методи виведення, специфічні для тексту, які допомагають аналізувати відповідність між зображенням і текстом. Хоча необхідна подальша робота для узгодження з сучасними методами, що базуються на просторових анотаціях, цей підхід підкреслює потенціал адаптації універсальних моделей до спеціалізованих хірургічних завдань. Код:",216,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.05007,https://arxiv.org/pdf/2507.05007.pdf,true
2507.05020,Adaptation of Multi-modal Representation Models for Multi-task Surgical Computer Vision,"Soham Walimbe, Britty Baby, Vinkle Srivastav, Nicolas Padoy","Surgical AI often involves multiple tasks within a single procedure, like phase recognition or assessing the Critical View of Safety in laparoscopic cholecystectomy. Traditional models, built for one task at a time, lack flexibility, requiring a separate model for each. To address this, we introduce MML-SurgAdapt, a unified multi-task framework with Vision-Language Models (VLMs), specifically CLIP, to handle diverse surgical tasks through natural language supervision. A key challenge in multi-task learning is the presence of partial annotations when integrating different tasks. To overcome this, we employ Single Positive Multi-Label (SPML) learning, which traditionally reduces annotation burden by training models with only one positive label per instance. Our framework extends this approach to integrate data from multiple surgical tasks within a single procedure, enabling effective learning despite incomplete or noisy annotations. We demonstrate the effectiveness of our model on a combined dataset consisting of Cholec80, Endoscapes2023, and CholecT50, utilizing custom prompts. Extensive evaluation shows that MML-SurgAdapt performs comparably to task-specific benchmarks, with the added advantage of handling noisy annotations. It also outperforms the existing SPML frameworks for the task. By reducing the required labels by 23%, our approach proposes a more scalable and efficient labeling process, significantly easing the annotation burden on clinicians. To our knowledge, this is the first application of SPML to integrate data from multiple surgical tasks, presenting a novel and generalizable solution for multi-task learning in surgical computer vision. Implementation is available at: ","Хірургічний ШІ часто включає в себе кілька завдань в рамках однієї процедури, наприклад, розпізнавання фаз або оцінка критичного погляду на безпеку при лапароскопічній холецистектомії. Традиційним моделям, побудованим для виконання одного завдання за раз, не вистачає гнучкості, і для кожного з них потрібна окрема модель. Щоб вирішити цю проблему, ми представляємо MML-SurgAdapt, уніфікований багатозадачний фреймворк з моделями мови зору (VLM), зокрема CLIP, для вирішення різноманітних хірургічних завдань за допомогою природної мови. Ключовою проблемою в багатозадачному навчанні є наявність часткових анотацій при інтеграції різних завдань. Щоб подолати цю проблему, ми застосовуємо навчання з однією позитивною багатозначною міткою (Single Positive Multi-Label, SPML), яке традиційно зменшує навантаження на анотації, навчаючи моделі лише з однією позитивною міткою на кожен екземпляр. Наш фреймворк розширює цей підхід, інтегруючи дані з декількох хірургічних завдань в рамках однієї процедури, що дозволяє ефективно навчатися, незважаючи на неповні або зашумлені анотації. Ми продемонстрували ефективність нашої моделі на комбінованому наборі даних, що складається з Cholec80, Endoscapes2023 і CholecT50, використовуючи кастомні підказки. Всебічне оцінювання показує, що MML-SurgAdapt працює порівняно з бенчмарками для конкретних завдань, з додатковою перевагою в обробці зашумлених анотацій. Він також перевершує існуючі фреймворки SPML для цієї задачі. Зменшуючи кількість необхідних міток на 23%, наш підхід пропонує більш масштабований та ефективний процес маркування, значно полегшуючи навантаження на клініцистів, пов'язане з анотаціями. Наскільки нам відомо, це перше застосування SPML для інтеграції даних з декількох хірургічних завдань, що представляє нове і узагальнююче рішення для багатозадачного навчання в хірургічному комп'ютерному зорі. Реалізація доступна за посиланням:",236,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.05020,https://arxiv.org/pdf/2507.05020.pdf,true
2507.05116,VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting,"Juyi Lin, Amir Taherin, Arash Akbari, Arman Akbari, Lei Lu, Guangyu Chen, Taskin Padir, Xiaomeng Yang, Weiwei Chen, Yiqian Li, Xue Lin, David Kaeli, Pu Zhao, Yanzhi Wang","Recent large-scale Vision Language Action (VLA) models have shown superior performance in robotic manipulation tasks guided by natural language. However, their generalization remains limited when applied to novel objects or unfamiliar environments that lie outside the training distribution. To address this, many existing approaches integrate additional components such as depth estimation, segmentation, or even diffusion to improve generalization, at the cost of adding significant computation overhead, resulting in low efficiency. This motivates the exploration of efficient action prediction methods, which are independent of additional high-level visual representations or diffusion techniques. In this work, we propose VOTE, an efficient and general framework for the optimization and acceleration of VLA models. In details, we propose a novel tokenizer-free fine-tuning approach for parallel accurate action prediction, which reduces computational overhead and accelerates inference speed. Additionally, we adopt an ensemble voting strategy for the action sampling, which significantly improves model performance and enhances generalization. Experimental results show that our method achieves state-of-the-art performance with 35x faster inference and 145 Hz throughput. All the details and codes will be open-sourced.","Нещодавні великомасштабні моделі Vision Language Action (VLA) продемонстрували чудову продуктивність у завданнях роботизованого маніпулювання, керованого природною мовою. Однак їхнє узагальнення залишається обмеженим при застосуванні до нових об'єктів або незнайомих середовищ, які лежать за межами розподілу навчання. Щоб вирішити цю проблему, багато існуючих підходів інтегрують додаткові компоненти, такі як оцінка глибини, сегментація або навіть дифузія для поліпшення узагальнення, але це призводить до значних обчислювальних витрат, що знижує ефективність. Це спонукає до пошуку ефективних методів прогнозування дій, які не залежать від додаткових високорівневих візуальних уявлень або методів дифузії. У цій роботі ми пропонуємо VOTE, ефективний і загальний фреймворк для оптимізації та прискорення моделей VLA. Зокрема, ми пропонуємо новий підхід до точного налаштування без токенізаторів для паралельного точного прогнозування дій, який зменшує обчислювальні витрати і прискорює швидкість виведення. Крім того, ми застосовуємо стратегію ансамблевого голосування для вибірки дій, що значно покращує продуктивність моделі та підвищує рівень узагальнення. Експериментальні результати показують, що наш метод досягає найсучаснішої продуктивності з 35-кратним прискоренням виведення та пропускною здатністю 145 Гц. Всі деталі та коди будуть у відкритому доступі.",175,Computer Vision and Pattern Recognition (cs.CV),https://arxiv.org/abs/2507.05116,https://arxiv.org/pdf/2507.05116.pdf,true
2507.05317,PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle CT,"Yi Liu, Yiyang Wen, Zekun Zhou, Junqi Ma, Linghang Wang, Yucheng Yao, Liu Shi, Qiegen Liu","Generative diffusion models have received increasing attention in medical imaging, particularly in limited-angle computed tomography (LACT). Standard diffusion models achieve high-quality image reconstruction but require a large number of sampling steps during inference, resulting in substantial computational overhead. Although skip-sampling strategies have been proposed to improve efficiency, they often lead to loss of fine structural details. To address this issue, we propose a prior information embedding and wavelet feature fusion fast sampling diffusion model for LACT reconstruction. The PWD enables efficient sampling while preserving reconstruction fidelity in LACT, and effectively mitigates the degradation typically introduced by skip-sampling. Specifically, during the training phase, PWD maps the distribution of LACT images to that of fully sampled target images, enabling the model to learn structural correspondences between them. During inference, the LACT image serves as an explicit prior to guide the sampling trajectory, allowing for high-quality reconstruction with significantly fewer steps. In addition, PWD performs multi-scale feature fusion in the wavelet domain, effectively enhancing the reconstruction of fine details by leveraging both low-frequency and high-frequency information. Quantitative and qualitative evaluations on clinical dental arch CBCT and periapical datasets demonstrate that PWD outperforms existing methods under the same sampling condition. Using only 50 sampling steps, PWD achieves at least 1.7 dB improvement in PSNR and 10% gain in SSIM.","Генеративні дифузійні моделі привертають все більше уваги в медичній візуалізації, особливо в комп'ютерній томографії з обмеженим кутом огляду (LACT). Стандартні дифузійні моделі забезпечують високоякісну реконструкцію зображень, але вимагають великої кількості кроків дискретизації під час виведення, що призводить до значних обчислювальних накладних витрат. Хоча для підвищення ефективності були запропоновані стратегії пропуску дискретизації, вони часто призводять до втрати дрібних структурних деталей. Щоб вирішити цю проблему, ми пропонуємо вбудовування попередньої інформації та вейвлет-функцію злиття швидкої дискретизації дифузії для реконструкції LACT. PWD забезпечує ефективну дискретизацію, зберігаючи точність реконструкції в LACT, і ефективно зменшує деградацію, яку зазвичай спричиняє пропуск дискретизації. Зокрема, на етапі навчання PWD зіставляє розподіл зображень LACT з розподілом повністю дискретизованих зображень мішені, дозволяючи моделі вивчати структурні відповідності між ними. Під час виводу LACT-зображення слугує явним попередником для визначення траєкторії дискретизації, що дозволяє отримати якісну реконструкцію за значно меншу кількість кроків. Крім того, PWD виконує різномасштабне злиття ознак у вейвлет-області, ефективно покращуючи реконструкцію дрібних деталей, використовуючи як низькочастотну, так і високочастотну інформацію. Кількісні та якісні оцінки клінічної КТКТ зубних рядів і периапікальних даних демонструють, що PWD перевершує існуючі методи за тих самих умов вибірки. Використовуючи лише 50 кроків дискретизації, PWD досягає щонайменше 1,7 дБ покращення PSNR та 10% покращення SSIM.",215,Image and Video Processing (eess.IV),https://arxiv.org/abs/2507.05317,https://arxiv.org/pdf/2507.05317.pdf,true
2507.05517,Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications,"Jean-Philippe Corbeil, Asma Ben Abacha, George Michalopoulos, Phillip Swazinna, Miguel Del-Agua, Jerome Tremblay, Akila Jeeson Daniel, Cari Bader, Yu-Cheng Cho, Pooja Krishnan, Nathan Bodenstab, Thomas Lin, Wenxuan Teng, Francois Beaulieu, Paul Vozila","Large language models (LLMs) such as GPT-4o and o1 have demonstrated strong performance on clinical natural language processing (NLP) tasks across multiple medical benchmarks. Nonetheless, two high-impact NLP tasks - structured tabular reporting from nurse dictations and medical order extraction from doctor-patient consultations - remain underexplored due to data scarcity and sensitivity, despite active industry efforts. Practical solutions to these real-world clinical tasks can significantly reduce the documentation burden on healthcare providers, allowing greater focus on patient care. In this paper, we investigate these two challenging tasks using private and open-source clinical datasets, evaluating the performance of both open- and closed-weight LLMs, and analyzing their respective strengths and limitations. Furthermore, we propose an agentic pipeline for generating realistic, non-sensitive nurse dictations, enabling structured extraction of clinical observations. To support further research in both areas, we release SYNUR and SIMORD, the first open-source datasets for nurse observation extraction and medical order extraction.","Великі мовні моделі (ВММ), такі як GPT-4o і o1, продемонстрували високу продуктивність при виконанні клінічних завдань з обробки природної мови (NLP) в різних медичних тестах. Тим не менш, дві високоефективні задачі NLP - створення структурованих табличних звітів на основі диктантів медсестер та вилучення медичних призначень з консультацій лікаря і пацієнта - залишаються недостатньо вивченими через дефіцит даних і чутливість, незважаючи на активні зусилля в галузі. Практичні рішення цих реальних клінічних завдань можуть значно зменшити навантаження на лікарів, що дозволить їм зосередитися на наданні медичної допомоги пацієнтам. У цій статті ми досліджуємо ці дві складні задачі, використовуючи приватні та відкриті клінічні набори даних, оцінюючи ефективність LLM з відкритою та закритою вагою, а також аналізуючи їхні сильні та слабкі сторони. Крім того, ми пропонуємо агентний конвеєр для генерації реалістичних, нечутливих диктантів медсестер, що дозволяє структурувати клінічні спостереження. Для підтримки подальших досліджень в обох напрямках ми випустили SYNUR і SIMORD, перші набори даних з відкритим вихідним кодом для вилучення спостережень медсестер і вилучення медичних призначень.",151,Computation and Language (cs.CL),https://arxiv.org/abs/2507.05517,https://arxiv.org/pdf/2507.05517.pdf,true
2507.06821,HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning,"Chuhang Zheng, Chunwei Tian, Jie Wen, Daoqiang Zhang, Qi Zhu","Multi-modal emotion recognition has garnered increasing attention as it plays a significant role in human-computer interaction (HCI) in recent years. Since different discrete emotions may exist at the same time, compared with single-class emotion recognition, emotion distribution learning (EDL) that identifies a mixture of basic emotions has gradually emerged as a trend. However, existing EDL methods face challenges in mining the heterogeneity among multiple modalities. Besides, rich semantic correlations across arbitrary basic emotions are not fully exploited. In this paper, we propose a multi-modal emotion distribution learning framework, named HeLo, aimed at fully exploring the heterogeneity and complementary information in multi-modal emotional data and label correlation within mixed basic emotions. Specifically, we first adopt cross-attention to effectively fuse the physiological data. Then, an optimal transport (OT)-based heterogeneity mining module is devised to mine the interaction and heterogeneity between the physiological and behavioral representations. To facilitate label correlation learning, we introduce a learnable label embedding optimized by correlation matrix alignment. Finally, the learnable label embeddings and label correlation matrices are integrated with the multi-modal representations through a novel label correlation-driven cross-attention mechanism for accurate emotion distribution learning. Experimental results on two publicly available datasets demonstrate the superiority of our proposed method in emotion distribution learning.","Мультимодальне розпізнавання емоцій привертає все більше уваги, оскільки воно відіграє важливу роль у взаємодії людини з комп'ютером (HCI) в останні роки. Оскільки різні дискретні емоції можуть існувати одночасно, порівняно з розпізнаванням однокласових емоцій, навчання розподілу емоцій (EDL), яке ідентифікує суміш базових емоцій, поступово перетворилося на тренд. Однак, існуючі методи EDL стикаються з проблемами у вивченні неоднорідності між декількома модальностями. Крім того, багаті семантичні кореляції між довільними базовими емоціями не використовуються повною мірою. У цій статті ми пропонуємо фреймворк навчання розподілу мультимодальних емоцій, названий HeLo, спрямований на повне вивчення неоднорідності та додаткової інформації в мультимодальних емоційних даних та кореляції міток в межах змішаних базових емоцій. Зокрема, ми спочатку використовуємо перехресну увагу для ефективного об'єднання фізіологічних даних. Потім розроблено модуль видобутку гетерогенності на основі оптимального транспорту (ОТ) для вивчення взаємодії та гетерогенності між фізіологічними та поведінковими репрезентаціями. Щоб полегшити навчання кореляції міток, ми вводимо вбудовування міток, що навчаються, оптимізоване вирівнюванням кореляційної матриці. Нарешті, вбудовування міток, що навчаються, і матриці кореляції міток інтегруються з мультимодальними репрезентаціями за допомогою нового механізму перехресної уваги, керованого кореляцією міток, для точного навчання розподілу емоцій. Експериментальні результати на двох загальнодоступних наборах даних демонструють перевагу запропонованого нами методу в навчанні розподілу емоцій.",204,Machine Learning (cs.LG),https://arxiv.org/abs/2507.06821,https://arxiv.org/pdf/2507.06821.pdf,true
2507.06825,Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning,"Matej Straka, Martin Schmid","We introduce a real-time strategy game environment based on , a game with thousands of weekly active players. Our environment is fully compatible with Gymnasium and PettingZoo and is capable of running thousands of frames per second on commodity hardware. We also present a reference agent, trained with supervised pre-training and self-play, which reached the top 0.003% of the 1v1 human leaderboard after only 36 hours on a single H100 GPU. To accelerate learning, we incorporate potential-based reward shaping and memory features. Our contributions of a modular RTS benchmark and a competitive baseline agent provide an accessible yet challenging platform for advancing multi-agent reinforcement learning research. The documented code, together with examples and tutorials, is available at .","Ми представляємо стратегічне ігрове середовище в реальному часі на основі гри з тисячами щотижневих активних гравців. Наше середовище повністю сумісне з Gymnasium та PettingZoo і здатне відтворювати тисячі кадрів в секунду на звичайному обладнанні. Ми також представляємо еталонного агента, навченого за допомогою контрольованої попередньої підготовки та самостійної гри, який досяг верхніх 0,003% у списку лідерів 1v1 серед людей всього за 36 годин на одному графічному процесорі H100. Для прискорення навчання ми використовуємо функції формування винагороди на основі потенціалу та пам'яті. Наш внесок у вигляді модульного RTS-тесту та конкурентного базового агента забезпечує доступну, але складну платформу для просування досліджень у галузі мультиагентного навчання з підкріпленням. Задокументований код, разом з прикладами та навчальними посібниками, доступний за адресою .",118,Machine Learning (cs.LG),https://arxiv.org/abs/2507.06825,https://arxiv.org/pdf/2507.06825.pdf,true
2507.06850,The Dark Side of LLMs: Agent-based Attacks for Complete Computer Takeover,"Matteo Lupinacci, Francesco Aurelio Pironti, Francesco Blefari, Francesco Romeo, Luigi Arena, Angelo Furfaro","The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.","Стрімке впровадження агентів великих мовних моделей (LLM) та мультиагентних систем відкриває безпрецедентні можливості для обробки та генерації природної мови. Однак, ці системи створили безпрецедентні вразливості безпеки, які виходять за рамки традиційних атак на швидкі ін'єкції. У цій статті представлено першу комплексну оцінку агентів LLM як векторів атаки, здатних досягти повного захоплення комп'ютера через використання меж довіри в агентних системах ШІ, де автономні об'єкти взаємодіють і впливають один на одного. Ми демонструємо, що зловмисники можуть використовувати три різні поверхні атаки - пряме оперативне впровадження, RAG-атаки через бекдори та використання міжагентської довіри - щоб змусити популярні LLM-агенти (включаючи GPT-4o, Claude-4 та Gemini-2.5) самостійно встановлювати та виконувати шкідливе програмне забезпечення на комп'ютерах-жертвах. Наша оцінка 17 найсучасніших LLM виявила тривожну ієрархію вразливостей: 41,2% моделей піддаються прямому оперативному впровадженню, 52,9% вразливі до атак через бекдор RAG, а критичні 82,4% можуть бути скомпрометовані через експлуатацію міжагентської довіри. Зокрема, ми виявили, що LLM, які успішно протистоять прямим шкідливим командам, виконують ідентичне корисне навантаження за запитом однорангових агентів, що свідчить про фундаментальний недолік сучасних мультиагентних моделей безпеки. Наші результати показують, що лише 5,9% протестованих моделей (1/17) виявилися стійкими до всіх векторів атак, а більшість демонструють контекстно-залежну поведінку безпеки, яка створює ""сліпі зони"", що можуть бути використані для атак. Наші висновки також підкреслюють необхідність підвищення обізнаності та дослідження ризиків безпеки LLM, демонструючи зміну парадигми загроз кібербезпеки, коли інструменти штучного інтелекту самі стають складними векторами атак.",240,Cryptography and Security (cs.CR),https://arxiv.org/abs/2507.06850,https://arxiv.org/pdf/2507.06850.pdf,true
2507.06892,Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model,"Jing Liang, Hongyao Tang, Yi Ma, Jinyi Liu, Yan Zheng, Shuyue Hu, Lei Bai, Jianye Hao","Reinforcement Learning (RL) has demonstrated its potential to improve the reasoning ability of Large Language Models (LLMs). One major limitation of most existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL in nature, i.e., data generated during the past learning process is not fully utilized. This inevitably comes at a significant cost of compute and time, posing a stringent bottleneck on continuing economic and efficient scaling. To this end, we launch the renaissance of off-policy RL and propose Reincarnating Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix consists of three major components: (1) Mix-policy proximal policy gradient with an increased Update-To-Data (UTD) ratio for efficient training; (2) KL-Convex policy constraint to balance the trade-off between stability and flexibility; (3) Policy reincarnation to achieve a seamless transition from efficient early-stage learning to steady asymptotic improvement. In our experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with 0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level performance with an over 30x to 450x reduction in training cost in terms of rollout data volume. In addition, we reveal insightful findings via multifaceted analysis, including the implicit preference for shorter responses due to the Whipping Effect of off-policy discrepancy, the collapse mode of self-reflection behavior under the presence of severe off-policyness, etc.","Навчання з підкріпленням (НВ) продемонструвало свій потенціал для покращення здатності великих мовних моделей (ВММ) до міркувань. Одним з основних обмежень більшості існуючих методів навчання з підкріпленням (RFT) є те, що вони за своєю природою є RL на основі політики, тобто дані, згенеровані під час минулого процесу навчання, не використовуються повною мірою. Це неминуче призводить до значних витрат обчислювальних ресурсів і часу, що створює жорсткі обмеження для подальшого економічного та ефективного масштабування. З цією метою ми розпочинаємо ренесанс позаполітичного RL і пропонуємо реінкарнацію змішаного градієнта проксимальної політики (ReMix) - загального підходу, який дозволяє методам RFT, що використовуються в політиці, таким як PPO і GRPO, використовувати позаполітичні дані. ReMix складається з трьох основних компонентів: (1) Проксимальний градієнт політики Mix-policy зі збільшеним співвідношенням оновлення до даних (UTD) для ефективного навчання; (2) Обмеження політики KL-Convex для балансування компромісу між стабільністю та гнучкістю; (3) Реінкарнація політики для досягнення плавного переходу від ефективного навчання на ранніх стадіях до стійкого асимптотичного покращення. У наших експериментах ми навчали серію моделей ReMix на основі моделей PPO, GRPO та базових моделей 1.5B, 7B. ReMix показує середню точність Pass@1 52.10% (для моделі 1.5B) з 0.079M розгортань відповідей, 350 кроків навчання і досягає 63.27%/64.39% (для моделі 7B) з 0.007M/0.011M розгортань відповідей, 50/75 кроків навчання на п'яти математичних тестах (тобто, AIME'24, AMC'23, Minerva, OlympiadBench і MATH500). У порівнянні з 15 останніми передовими моделями, ReMix демонструє продуктивність на рівні SOTA зі скороченням вартості навчання від 30 до 450 разів у перерахунку на обсяг даних для розгортання. Крім того, ми виявляємо глибокі висновки за допомогою багатогранного аналізу, включаючи неявну перевагу коротших відповідей через ефект ""батога"" (Whipping Effect) при розбіжності з політикою, режим колапсу поведінки саморефлексії при наявності серйозної розбіжності з політикою тощо.",274,Machine Learning (cs.LG),https://arxiv.org/abs/2507.06892,https://arxiv.org/pdf/2507.06892.pdf,true
